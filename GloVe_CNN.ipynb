{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GloVe-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqadDtayEy3IR0h8PLQNRP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/GloVe_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzJBpZfBPvmv",
        "colab_type": "code",
        "outputId": "67053b3f-b062-4ddd-ecdd-b204b38be4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im_WEC03Oufr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMXK0Ih3O5ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive'\n",
        "\n",
        "DATA_PATH = Path(file_path + '/datasets/SemEval')\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', \n",
        "                  lower = True, \n",
        "                  include_lengths = True,\n",
        "                  batch_first = True)\n",
        "LABEL = data.LabelField(sequential=False,\n",
        "                        use_vocab = False,\n",
        "                        pad_token = None,\n",
        "                        unk_token = None, \n",
        "                        dtype = torch.float)\n",
        "\n",
        "dataFields = {\"Tweet\": (\"Tweet\", TEXT),\n",
        "              'anger': (\"anger\", LABEL),\n",
        "              'anticipation': (\"anticipation\", LABEL),\n",
        "              'disgust': (\"disgust\", LABEL),\n",
        "              'fear': (\"fear\", LABEL),\n",
        "              'joy': (\"joy\", LABEL),\n",
        "              'love': (\"love\", LABEL),\n",
        "              'optimism': (\"optimism\", LABEL),\n",
        "              'pessimism': (\"pessimism\", LABEL),\n",
        "              'sadness': (\"sadness\", LABEL),\n",
        "              'surprise': (\"surprise\", LABEL),\n",
        "              'trust': (\"trust\", LABEL)}\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path = DATA_PATH,\n",
        "    train = 'train.csv',\n",
        "    validation = 'val.csv',\n",
        "    test = 'test.csv',\n",
        "    format = 'csv',\n",
        "    fields = dataFields\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcnihZHRPHnT",
        "colab_type": "code",
        "outputId": "85691ecf-3502-4e62-dcfb-5a256a810b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "MAX_VOCAB_SIZE = 10000\n",
        "\n",
        "TEXT.build_vocab(train_data,\n",
        "                 max_size=MAX_VOCAB_SIZE,\n",
        "                 vectors=\"glove.6B.300d\",\n",
        "                 unk_init=torch.Tensor.normal_)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:26, 2.23MB/s]                           \n",
            "100%|█████████▉| 399685/400000 [00:37<00:00, 10709.20it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0l5JMgYQhTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    sort_key = lambda x: len(x.Tweet),\n",
        "    sort_within_batch = True,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVyLy4G9V8wB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLS = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
        "              'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "iaux = 0 \n",
        "\n",
        "for batch in valid_iterator:\n",
        "  iaux += 1\n",
        "  aux = batch\n",
        "  aux2 = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "  if iaux == 20: break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvsS9Jx6bQMO",
        "colab_type": "code",
        "outputId": "f4fda8ce-97dc-443b-8ec4-b7050f2b8293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "torch.transpose(torch.stack([getattr(aux, label) for label in LABEL_COLS]),0,1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.],\n",
              "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
              "        [0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U2ORv8PTEVd",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66MqX9JmTDBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfruRnTTTLjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, n_filters, \n",
        "               filter_sizes, output_dim, dropout, pad_idx):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    self.convs = nn.ModuleList([\n",
        "                                nn.Conv2d(in_channels = 1,\n",
        "                                          out_channels = n_filters,\n",
        "                                          kernel_size = (fs, embedding_dim)) \n",
        "                                for fs in filter_sizes])\n",
        "    self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text)\n",
        "    embedded = embedded.unsqueeze(1)\n",
        "    conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "    cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "    return self.fc(cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmKMJ0uhUHRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [3,3,1]\n",
        "OUTPUT_DIM = 11\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, \n",
        "            FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYja9aLjUfNQ",
        "colab_type": "code",
        "outputId": "97d28f22-c2e4-4b81-97f2-f0926f25eab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embedding): Embedding(10002, 300)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
              "    (1): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
              "    (2): Conv2d(1, 100, kernel_size=(1, 300), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=300, out_features=11, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyf-rPUdUhvr",
        "colab_type": "code",
        "outputId": "21236ef4-dcf3-40df-d0bb-8c419ac5e18e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,214,211 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynQYeBc8UsK9",
        "colab_type": "code",
        "outputId": "5bca09b6-e122-4ae1-ac79-3115d31ace20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ..., -1.4447,  0.8402, -0.8668],\n",
              "        [ 0.1032, -1.6268,  0.5729,  ...,  0.3180, -0.1626, -0.0417],\n",
              "        [ 0.0690, -0.0789,  0.5624,  ..., -0.1015,  0.4912,  0.5452],\n",
              "        ...,\n",
              "        [-0.2811, -0.4945, -0.6650,  ...,  1.9416,  0.4497, -0.6541],\n",
              "        [ 0.0784, -1.2126, -0.6455,  ...,  1.6466, -0.1657, -1.7905],\n",
              "        [ 1.0856,  0.0307, -1.5112,  ..., -0.3839, -1.4490,  0.0600]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFbYJEWcUzas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICIyhxWgVB-V",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caKIAxbdU_QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRkj-Y8eVI1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYA7wCoscQT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNVgTZxJWqwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def roc_auc(preds, y):\n",
        "  global var_y\n",
        "  global var_preds \n",
        "  var_y = y\n",
        "  var_preds = preds\n",
        "  acc = roc_auc_score(y, preds)\n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFuk-XggVQJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    tweet, tweet_lengths = batch.Tweet\n",
        "\n",
        "    predictions = model(tweet).squeeze(1)\n",
        "\n",
        "    batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "    batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "    loss = criterion(predictions, batch_labels)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "    labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "    epoch_loss += loss.item() \n",
        "  \n",
        "  return epoch_loss / len(iterator), roc_auc(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CICSuvlnY6tA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "  epoch_acc = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "      tweet, tweet_lengths = batch.Tweet\n",
        "\n",
        "      predictions = model(tweet).squeeze(1)\n",
        "\n",
        "      batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "      batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "      loss = criterion(predictions, batch_labels)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "      labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "  return epoch_loss / len(iterator), roc_auc(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uApg451dAk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlTIjKFNdDn4",
        "colab_type": "code",
        "outputId": "204a9150-1efc-4c17-d91d-d384783e84b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_history = []\n",
        "valid_history = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    train_history.append(train_acc)\n",
        "    valid_history.append(valid_acc)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.468 | Train Acc: 58.17%\n",
            "\t Val. Loss: 0.408 |  Val. Acc: 74.17%\n",
            "Epoch: 02 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.374 | Train Acc: 76.72%\n",
            "\t Val. Loss: 0.357 |  Val. Acc: 79.73%\n",
            "Epoch: 03 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.325 | Train Acc: 83.21%\n",
            "\t Val. Loss: 0.346 |  Val. Acc: 80.97%\n",
            "Epoch: 04 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.293 | Train Acc: 86.75%\n",
            "\t Val. Loss: 0.341 |  Val. Acc: 81.76%\n",
            "Epoch: 05 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.267 | Train Acc: 89.35%\n",
            "\t Val. Loss: 0.346 |  Val. Acc: 82.07%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE2uh9bRdHD6",
        "colab_type": "code",
        "outputId": "a896f48c-dc28-4acf-b6ee-1924dd10f6a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_history)\n",
        "plt.plot(valid_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f645d206be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL4fQ_UtkuA8",
        "colab_type": "code",
        "outputId": "f6458f3c-11da-49dc-e106-fe5d21d7e04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_state_dict(torch.load('tut4-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.343 | Test Acc: 80.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYMJGkyjle-d",
        "colab_type": "text"
      },
      "source": [
        "# User Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh-AsvgclbW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "tweet = 'I am quite scared of the future, not gonna lie'\n",
        "tokenized = [tok.text for tok in nlp.tokenizer(tweet)]\n",
        "indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "tensor = torch.LongTensor(indexed).to(device)\n",
        "tensor = tensor.unsqueeze(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY1XD42mosOf",
        "colab_type": "code",
        "outputId": "699c57c9-c856-4c6a-c3f1-b70efb5c8aa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tensor.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 12])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIY16TTooqlN",
        "colab_type": "code",
        "outputId": "7a3ff0a4-cd05-4e28-dcb7-cab2ef46da86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "  \n",
        "  tweet = tensor\n",
        "  predictions = model(tweet)\n",
        "  preds += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "preds"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.18244646, 0.07211389, 0.28668654, 0.9859676 , 0.01275938,\n",
              "         0.00412598, 0.03200175, 0.2871398 , 0.7002643 , 0.02227796,\n",
              "         0.00792685]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_db5-1PmBaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}