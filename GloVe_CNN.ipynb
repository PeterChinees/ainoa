{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GloVe-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZd3XpbeOISeIGZI8y9bqz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/GloVe_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzJBpZfBPvmv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "f3ba5e8f-1720-4f17-b2ea-14e669dc0d80"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im_WEC03Oufr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMXK0Ih3O5ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive'\n",
        "\n",
        "DATA_PATH = Path(file_path + '/datasets/SemEval')\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy', \n",
        "                  lower = True, \n",
        "                  include_lengths = True)\n",
        "LABEL = data.LabelField(sequential=False,\n",
        "                        use_vocab = False,\n",
        "                        pad_token = None,\n",
        "                        unk_token = None, \n",
        "                        dtype = torch.float)\n",
        "\n",
        "dataFields = {\"Tweet\": (\"Tweet\", TEXT),\n",
        "              'anger': (\"anger\", LABEL),\n",
        "              'anticipation': (\"anticipation\", LABEL),\n",
        "              'disgust': (\"disgust\", LABEL),\n",
        "              'fear': (\"fear\", LABEL),\n",
        "              'joy': (\"joy\", LABEL),\n",
        "              'love': (\"love\", LABEL),\n",
        "              'optimism': (\"optimism\", LABEL),\n",
        "              'pessimism': (\"pessimism\", LABEL),\n",
        "              'sadness': (\"sadness\", LABEL),\n",
        "              'surprise': (\"surprise\", LABEL),\n",
        "              'trust': (\"trust\", LABEL)}\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path = DATA_PATH,\n",
        "    train = 'train.csv',\n",
        "    validation = 'val.csv',\n",
        "    test = 'test.csv',\n",
        "    format = 'csv',\n",
        "    fields = dataFields\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcnihZHRPHnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 10000\n",
        "\n",
        "TEXT.build_vocab(train_data,\n",
        "                 max_size=MAX_VOCAB_SIZE,\n",
        "                 vectors=\"glove.6B.100d\",\n",
        "                 unk_init=torch.Tensor.normal_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0l5JMgYQhTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    sort_key = lambda x: len(x.Tweet),\n",
        "    sort_within_batch = True,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVyLy4G9V8wB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLS = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
        "              'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "iaux = 0 \n",
        "\n",
        "for batch in valid_iterator:\n",
        "  iaux += 1\n",
        "  aux = batch\n",
        "  aux2 = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "  if iaux == 20: break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvsS9Jx6bQMO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "f8fb8829-b397-4c89-fb0c-2fe0b40af860"
      },
      "source": [
        "torch.transpose(torch.stack([getattr(aux, label) for label in LABEL_COLS]),0,1)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.],\n",
              "        [1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
              "        [0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
              "        [0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U2ORv8PTEVd",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66MqX9JmTDBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfruRnTTTLjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, n_filters, \n",
        "               filter_sizes, output_dim, dropout, pad_idx):\n",
        "    \n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    self.convs = nn.ModuleList([\n",
        "                                nn.Conv2d(in_channels = 1,\n",
        "                                          out_channels = n_filters,\n",
        "                                          kernel_size = (fs, embedding_dim)) \n",
        "                                for fs in filter_sizes])\n",
        "    self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    text = text.permute(1,0)\n",
        "    embedded = self.embedding(text)\n",
        "    embedded = embedded.unsqueeze(1)\n",
        "    conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "    cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "    return self.fc(cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmKMJ0uhUHRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [3,3,1]\n",
        "OUTPUT_DIM = 11\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, \n",
        "            FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYja9aLjUfNQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "6c97ebe5-9fb9-45a6-d96c-15741f7a8b0e"
      },
      "source": [
        "model"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embedding): Embedding(10002, 100)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
              "    (1): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
              "    (2): Conv2d(1, 100, kernel_size=(1, 100), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=300, out_features=11, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyf-rPUdUhvr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "608afc2a-8d58-44f7-d4aa-a9d31c9842d7"
      },
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,073,811 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynQYeBc8UsK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "ea3e203f-d5ae-43c7-9c17-1d6a9d2da17d"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
              "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
              "        [-0.6610, -0.0730,  0.9238,  ..., -0.2256,  0.8148, -0.4405],\n",
              "        ...,\n",
              "        [ 0.2501, -0.5645,  1.1328,  ..., -0.4779,  1.1052, -0.0475],\n",
              "        [ 0.0917,  1.1856, -0.0562,  ..., -0.8436,  1.2962,  0.5990],\n",
              "        [ 0.4041,  1.6816,  1.3186,  ..., -0.3370,  0.5296, -0.3987]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFbYJEWcUzas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICIyhxWgVB-V",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caKIAxbdU_QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRkj-Y8eVI1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYA7wCoscQT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNVgTZxJWqwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def roc_auc(preds, y):\n",
        "  global var_y\n",
        "  global var_preds \n",
        "  var_y = y\n",
        "  var_preds = preds\n",
        "  acc = roc_auc_score(y, preds)\n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFuk-XggVQJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    tweet, tweet_lengths = batch.Tweet\n",
        "\n",
        "    predictions = model(tweet).squeeze(1)\n",
        "\n",
        "    batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "    batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "    loss = criterion(predictions, batch_labels)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "    labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "    epoch_loss += loss.item() \n",
        "  \n",
        "  return epoch_loss / len(iterator), roc_auc(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CICSuvlnY6tA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "  epoch_acc = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "      tweet, tweet_lengths = batch.Tweet\n",
        "\n",
        "      predictions = model(tweet).squeeze(1)\n",
        "\n",
        "      batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "      batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "      loss = criterion(predictions, batch_labels)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "      labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "  return epoch_loss / len(iterator), roc_auc(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uApg451dAk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlTIjKFNdDn4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "d9d41583-1d02-413e-c1e3-5ec392629691"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_history = []\n",
        "valid_history = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    train_history.append(train_acc)\n",
        "    valid_history.append(valid_acc)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.479 | Train Acc: 53.90%\n",
            "\t Val. Loss: 0.450 |  Val. Acc: 68.08%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.416 | Train Acc: 69.69%\n",
            "\t Val. Loss: 0.378 |  Val. Acc: 76.42%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.367 | Train Acc: 77.24%\n",
            "\t Val. Loss: 0.360 |  Val. Acc: 79.20%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.340 | Train Acc: 81.22%\n",
            "\t Val. Loss: 0.351 |  Val. Acc: 80.46%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.317 | Train Acc: 83.90%\n",
            "\t Val. Loss: 0.347 |  Val. Acc: 81.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE2uh9bRdHD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "8d431bee-0f58-497f-e652-158cb8166155"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_history)\n",
        "plt.plot(valid_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'])"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0c9d6aa8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEICAYAAABF82P+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGVxFHITQLgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL4fQ_UtkuA8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eec135a4-6e18-49f2-bbdd-eb7b623c9a3d"
      },
      "source": [
        "model.load_state_dict(torch.load('tut4-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.348 | Test Acc: 80.02%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYMJGkyjle-d",
        "colab_type": "text"
      },
      "source": [
        "# User Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh-AsvgclbW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "tweet = 'I am quite scared of the future, not gonna lie'\n",
        "tokenized = [tok.text for tok in nlp.tokenizer(tweet)]\n",
        "indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "tensor = torch.LongTensor(indexed).to(device)\n",
        "tensor = tensor.unsqueeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY1XD42mosOf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2bd6fcd-ab5b-406d-af56-f82e7d9670ad"
      },
      "source": [
        "tensor.shape"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIY16TTooqlN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "93f27dff-fa2c-4d81-b283-db6e9230f0f3"
      },
      "source": [
        "preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "  \n",
        "  tweet = tensor\n",
        "  predictions = model(tweet)\n",
        "  preds += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "preds"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.2194942 , 0.09275133, 0.34991264, 0.9399863 , 0.01192236,\n",
              "         0.0037441 , 0.03727771, 0.2728653 , 0.6673346 , 0.02698256,\n",
              "         0.01149845]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_db5-1PmBaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}