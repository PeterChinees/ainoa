{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKM3aorCt9vfIzLa3z+Zz7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/BERT_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owG-IxGmt6PT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjzXVnDxtlRF",
        "colab_type": "code",
        "outputId": "76962739-b44a-4d42-d259-2419c4402512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N2UGYjytpuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import transformers\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from pathlib import Path\n",
        "from torchtext import data\n",
        "from transformers import BertTokenizer, BertModel, DistilBertTokenizer, DistilBertModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3-e1jPqoJnc",
        "colab_type": "text"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0j_RCS0oLhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    \"bert_tokenizer\": \"bert-base-uncased\",\n",
        "    \"bert_pretrained_model\": \"bert-base-uncased\",\n",
        "    \"distilbert_tokenizer\": \"distilbert-base-uncased\",\n",
        "    \"distilbert_pretrained_model\": \"distilbert-base-uncased\",\n",
        "    \"seed\": 1234,\n",
        "    \"batch_size\": 512,\n",
        "    \"num_filters\": 100,\n",
        "    \"filter_sizes\": [3,4,5],\n",
        "    \"output_dim\": 11,\n",
        "    \"dropout\": 0.5,\n",
        "    \"epochs\": 5\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTPBR-lIovsI",
        "colab_type": "text"
      },
      "source": [
        "# Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRR5RJneu1sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained(args['bert_tokenizer'])\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(args['distilbert_tokenizer'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro_0OHbpu8G9",
        "colab_type": "code",
        "outputId": "e21009be-5a76-466a-e5c7-1f56ae0ab4df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tokenizer.vocab)"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 370
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeyvkR7XAqH4",
        "colab_type": "code",
        "outputId": "f13a0309-b9bb-4514-aaf0-91fd40acd7ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEEo_OG7v4IN",
        "colab_type": "code",
        "outputId": "9e3a9809-14da-4736-8899-fff26732edd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yUzVdafvcpC",
        "colab_type": "code",
        "outputId": "3c4782ff-0ac8-41a9-b662-82fd7099f541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes[args['distilbert_tokenizer']]\n",
        "\n",
        "print(max_input_length)"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jx93Gzou92U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_and_cut(tweet):\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdXOgr6bo_si",
        "colab_type": "text"
      },
      "source": [
        "# Load & Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwTeWoXTukDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive'\n",
        "\n",
        "DATA_PATH = Path(file_path + '/datasets/SemEval')\n",
        "\n",
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = tokenize_and_cut,\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "LABEL = data.LabelField(sequential = False,\n",
        "                        use_vocab = False,\n",
        "                        pad_token= None,\n",
        "                        unk_token = None, \n",
        "                        dtype = torch.float)\n",
        "\n",
        "dataFields = {\"Tweet\": (\"Tweet\", TEXT),\n",
        "              'anger': (\"anger\", LABEL),\n",
        "              'anticipation': (\"anticipation\", LABEL),\n",
        "              'disgust': (\"disgust\", LABEL),\n",
        "              'fear': (\"fear\", LABEL),\n",
        "              'joy': (\"joy\", LABEL),\n",
        "              'love': (\"love\", LABEL),\n",
        "              'optimism': (\"optimism\", LABEL),\n",
        "              'pessimism': (\"pessimism\", LABEL),\n",
        "              'sadness': (\"sadness\", LABEL),\n",
        "              'surprise': (\"surprise\", LABEL),\n",
        "              'trust': (\"trust\", LABEL)}\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path = DATA_PATH,\n",
        "    train = 'train.csv',\n",
        "    validation = 'val.csv',\n",
        "    test = 'test.csv',\n",
        "    format = 'csv',\n",
        "    fields = dataFields\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0HXAS8EwK7z",
        "colab_type": "code",
        "outputId": "51c169aa-cd11-4815-ef57-5a9f825a9a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data)}\")\n",
        "print(f\"Number of testing examples: {len(test_data)}\")"
      ],
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 6838\n",
            "Number of validation examples: 886\n",
            "Number of testing examples: 3259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz15EhbHwlTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    sort_key = lambda x: len(x.Tweet),\n",
        "    sort_within_batch = True,\n",
        "    batch_size = args['batch_size'],\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf0eDnfJxEmF",
        "colab_type": "text"
      },
      "source": [
        "# Build Vocab for Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J749TkJ-Hth_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLS = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
        "              'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "iaux = 0\n",
        "\n",
        "for batch in valid_iterator:\n",
        "  iaux += 1\n",
        "  aux = batch\n",
        "  aux2 = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "  if aux == 20: break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdVG6iO5xYSL",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Os2Jg6dxcHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bert = BertModel.from_pretrained(args['bert_pretrained_model'])\n",
        "bert = DistilBertModel.from_pretrained(args['distilbert_pretrained_model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ispEw6-G5PHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "66eab063-cf4b-4083-f54a-ab20ca803956"
      },
      "source": [
        "bert.embeddings"
      ],
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embeddings(\n",
              "  (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "  (position_embeddings): Embedding(512, 768)\n",
              "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 380
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe2-uC23xxhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertCNN(nn.Module):\n",
        "  def __init__(self, bert, n_filters, filter_sizes, output_dim, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    self.bert = bert \n",
        "\n",
        "    embedding_dim = 768\n",
        "\n",
        "    self.convs = nn.ModuleList([\n",
        "                                nn.Conv2d(in_channels = 1,\n",
        "                                          out_channels = n_filters,\n",
        "                                          kernel_size = (fs, embedding_dim)) \n",
        "                                for fs in filter_sizes])\n",
        "    \n",
        "    self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    with torch.no_grad():\n",
        "      embedded = self.bert(text)[0]\n",
        "    \n",
        "    embedded = embedded.unsqueeze(1)\n",
        "    \n",
        "    conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "    \n",
        "    cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "    \n",
        "    return self.fc(cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BjxJgdC0umb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertCNN(bert=bert, \n",
        "                n_filters=args['num_filters'], \n",
        "                filter_sizes=args['filter_sizes'], \n",
        "                output_dim=args['output_dim'], \n",
        "                dropout=args['dropout'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKP5_3J30-qX",
        "colab_type": "code",
        "outputId": "b3c58d05-d0bb-4430-d87d-083509ef50c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 383,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertCNN(\n",
              "  (bert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 100, kernel_size=(3, 768), stride=(1, 1))\n",
              "    (1): Conv2d(1, 100, kernel_size=(4, 768), stride=(1, 1))\n",
              "    (2): Conv2d(1, 100, kernel_size=(5, 768), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=300, out_features=11, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 383
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXDfpNUN0_Ns",
        "colab_type": "code",
        "outputId": "7683c4bf-191d-43be-866e-8c2e08f8246c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 384,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 67,288,091 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJmHEDeR1IUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMEjhKzy1MpT",
        "colab_type": "code",
        "outputId": "99e1668a-86e2-4bfe-ea53-e156ee4cd523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 386,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 925,211 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vMffCB91RYi",
        "colab_type": "code",
        "outputId": "00ae6869-f226-4b3a-f47c-e2a8bb71a732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convs.0.weight\n",
            "convs.0.bias\n",
            "convs.1.weight\n",
            "convs.1.bias\n",
            "convs.2.weight\n",
            "convs.2.bias\n",
            "fc.weight\n",
            "fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TVLrvFb1Zch",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46iK1uys1Wmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQWnKk5m1eUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss() \n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63IKcBC31rMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBCzL0Z-1vN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metricize(preds, y):\n",
        "  global var_y\n",
        "  global var_preds\n",
        "  var_y = y\n",
        "  var_preds = preds\n",
        "  f1_macro = f1_score(y, preds.round(), average='macro')\n",
        "  f1_micro = f1_score(y, preds.round(), average='micro')\n",
        "  acc = roc_auc_score(y, preds)\n",
        "\n",
        "  return {\n",
        "      'f1_macro': f1_macro,\n",
        "      'f1_micro': f1_micro,\n",
        "      'acc': acc\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vtKoYNR1xbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    predictions = model(batch.Tweet).squeeze(1)\n",
        "\n",
        "    batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "    batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "    loss = criterion(predictions, batch_labels)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "    labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  \n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nthY6Knv14uC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "      predictions = model(batch.Tweet).squeeze(1)\n",
        "\n",
        "      batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "      batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "      loss = criterion(predictions, batch_labels)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "      labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrqsUMQY17tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJRKTout1_BJ",
        "colab_type": "code",
        "outputId": "800d65ee-b3a7-4310-d60d-ec58de0c379f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_history = []\n",
        "valid_history = []\n",
        "\n",
        "for epoch in range(args['epochs']):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_metrics = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_metrics = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    train_history.append(train_loss)\n",
        "    valid_history.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'bert-cnn-model.pt')\n",
        "\n",
        "    train_acc = train_metrics['acc']\n",
        "    train_micro = train_metrics['f1_micro']\n",
        "    train_macro = train_metrics['f1_macro']\n",
        "\n",
        "    valid_acc = valid_metrics['acc']\n",
        "    valid_micro = valid_metrics['f1_micro']\n",
        "    valid_macro = valid_metrics['f1_macro']\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train F1 Micro: {train_micro*100:.2f}% | Train F1 Macro: {train_macro*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%  | Val. F1 Micro: {valid_micro*100:.2f}%  | Val. F1 Macro: {valid_macro*100:.2f}%')"
      ],
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.379  | Train Acc: 76.17% | Train F1 Micro: 51.06% | Train F1 Macro: 30.70%\n",
            "\t Val. Loss: 0.373  | Val. Acc: 78.54%  | Val. F1 Micro: 50.44%  | Val. F1 Macro: 28.92%\n",
            "Epoch: 02 | Epoch Time: 0m 8s\n",
            "\tTrain Loss: 0.365  | Train Acc: 78.69% | Train F1 Micro: 54.14% | Train F1 Macro: 34.16%\n",
            "\t Val. Loss: 0.362  | Val. Acc: 80.07%  | Val. F1 Micro: 54.26%  | Val. F1 Macro: 33.11%\n",
            "Epoch: 03 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.354  | Train Acc: 80.32% | Train F1 Micro: 57.09% | Train F1 Macro: 36.93%\n",
            "\t Val. Loss: 0.358  | Val. Acc: 81.03%  | Val. F1 Micro: 54.14%  | Val. F1 Macro: 33.16%\n",
            "Epoch: 04 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.342  | Train Acc: 82.10% | Train F1 Micro: 58.66% | Train F1 Macro: 38.70%\n",
            "\t Val. Loss: 0.351  | Val. Acc: 81.59%  | Val. F1 Micro: 56.62%  | Val. F1 Macro: 35.42%\n",
            "Epoch: 05 | Epoch Time: 0m 9s\n",
            "\tTrain Loss: 0.336  | Train Acc: 82.79% | Train F1 Micro: 60.16% | Train F1 Macro: 40.36%\n",
            "\t Val. Loss: 0.349  | Val. Acc: 82.04%  | Val. F1 Micro: 56.64%  | Val. F1 Macro: 36.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_Y6H4Bg_H02",
        "colab_type": "text"
      },
      "source": [
        "# Plot Training & Validation History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xApekxv62E2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYvkc4ylPU2H",
        "colab_type": "code",
        "outputId": "d1b51cd1-d143-45d6-99a3-38dfe6eb357d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "plt.plot(train_history)\n",
        "plt.plot(valid_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training', 'Validation'])"
      ],
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f8e5c8e2c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 400
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndmlAKKWUsuv/AfIY6guX/Q5vAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR5X3c8r_W1m",
        "colab_type": "text"
      },
      "source": [
        "# Model results on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI8O3g5_PY1l",
        "colab_type": "code",
        "outputId": "2a699026-d4d4-4800-99c0-daf5bf72af69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_state_dict(torch.load('bert-cnn-model.pt'))\n",
        "\n",
        "test_loss, test_metrics = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "test_acc = test_metrics['acc']\n",
        "test_micro = test_metrics['f1_micro']\n",
        "test_macro = test_metrics['f1_macro']\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test F1 Micro: {test_micro*100:.2f}% | Test F1 Macro: {test_macro*100:.2f}%')"
      ],
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.337 | Test Acc: 82.27% | Test F1 Micro: 60.45% | Test F1 Macro: 40.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWvYzUzo73i4",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ldd6LfSYRJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_emotion(model, tokenizer, tweet):\n",
        "  preds = []\n",
        "  model.eval()\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  predictions = model(tensor)\n",
        "  preds.append(torch.sigmoid(predictions).detach().cpu().numpy())\n",
        "  #preds += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "  return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0htQkUGZKmS",
        "colab_type": "code",
        "outputId": "b82cbae2-fd6a-4fff-f218-a97c7273c934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "LABEL_COLS"
      ],
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['anger',\n",
              " 'anticipation',\n",
              " 'disgust',\n",
              " 'fear',\n",
              " 'joy',\n",
              " 'love',\n",
              " 'optimism',\n",
              " 'pessimism',\n",
              " 'sadness',\n",
              " 'surprise',\n",
              " 'trust']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 408
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRlr-s2DY8Df",
        "colab_type": "code",
        "outputId": "a69da309-4a6f-4498-9519-0726aa009430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "preds = predict_emotion(model, tokenizer, \"Do you think humans have the sense for recognizing impending doom?\")\n",
        "\n",
        "vals = []\n",
        "for p in preds[0]:\n",
        "  for val in p:\n",
        "    vals.append(val)\n",
        "\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "  print(f\"{label.upper()}: {vals[i]}\")"
      ],
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANGER: 0.11157804727554321\n",
            "ANTICIPATION: 0.4258352220058441\n",
            "DISGUST: 0.17862333357334137\n",
            "FEAR: 0.6842926144599915\n",
            "JOY: 0.07043831795454025\n",
            "LOVE: 0.022232012823224068\n",
            "OPTIMISM: 0.21292801201343536\n",
            "PESSIMISM: 0.2066025733947754\n",
            "SADNESS: 0.19770075380802155\n",
            "SURPRISE: 0.06492235511541367\n",
            "TRUST: 0.060219865292310715\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}