{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1lZJpqv-38jmP7zCizHdy8mSu-IMlHlCZ",
      "authorship_tag": "ABX9TyMJCsHdL/uJdGjAX2kn9h1/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/GloVe%20Attention%20BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWaTkjkKu9TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLFhbGO8C4gJ",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xU5Pc6mvbY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import random\n",
        "import spacy\n",
        "import transformers\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from pathlib import Path\n",
        "from torchtext import data\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "nlp = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZYWV6HMDEm6",
        "colab_type": "text"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FczMGWp1vM_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    \"bert_tokenizer\": \"bert-base-uncased\",\n",
        "    \"bert_pretrained_model\": \"bert-base-uncased\",\n",
        "    \"seed\": 1234,\n",
        "    \"bert_embedding_dim\": 768,\n",
        "    \"use_glove\": True,\n",
        "    \"glove_embedding_dim\": 300,\n",
        "    \"max_vocab_size\": 20000,\n",
        "    \"batch_size\": 64,\n",
        "    \"output_dim\": 11,\n",
        "    \"hidden_size\": 768,\n",
        "    \"num_layers\": 2,\n",
        "    \"dropout\": 0.5,\n",
        "    \"fc_dropout\": 0.5,\n",
        "    \"embed_dropout\": 0.2,\n",
        "    \"weight_decay\": 1e-5,\n",
        "    \"lr\": 0.001,\n",
        "    \"epochs\": 10\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QizRI-q1DPf1",
        "colab_type": "text"
      },
      "source": [
        "# Setup Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4nYNxu4vV9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(args['bert_tokenizer'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBv0eC2xvss-",
        "colab_type": "code",
        "outputId": "69076022-0e7c-419b-a021-39b71e154bfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes[args['bert_tokenizer']]\n",
        "\n",
        "print(max_input_length)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMBjmcymvlY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(tweet):\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFFnMbqQDbJC",
        "colab_type": "text"
      },
      "source": [
        "# Load and Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYj3qsDpvmwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive'\n",
        "\n",
        "DATA_PATH = Path(file_path + '/datasets/SemEval')\n",
        "\n",
        "GLOVE_DIR = Path(file_path + '/glove/glove.6B.300d.txt')\n",
        "\n",
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "if args['use_glove']:\n",
        "  TEXT = data.Field(batch_first=True,\n",
        "                    tokenize='spacy',\n",
        "                    use_vocab=True,\n",
        "                    sequential=True)\n",
        "else:\n",
        "  TEXT = data.Field(batch_first = True,\n",
        "                use_vocab = False,\n",
        "                tokenize = tokenize,\n",
        "                preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                init_token = tokenizer.cls_token_id,\n",
        "                eos_token = tokenizer.sep_token_id,\n",
        "                pad_token = tokenizer.pad_token_id,\n",
        "                unk_token = tokenizer.unk_token_id)\n",
        "  \n",
        "LABEL = data.LabelField(sequential = False,\n",
        "                        use_vocab = False,\n",
        "                        pad_token= None,\n",
        "                        unk_token = None, \n",
        "                        dtype = torch.float)\n",
        "\n",
        "dataFields = {\"Tweet\": (\"Tweet\", TEXT),\n",
        "              'anger': (\"anger\", LABEL),\n",
        "              'anticipation': (\"anticipation\", LABEL),\n",
        "              'disgust': (\"disgust\", LABEL),\n",
        "              'fear': (\"fear\", LABEL),\n",
        "              'joy': (\"joy\", LABEL),\n",
        "              'love': (\"love\", LABEL),\n",
        "              'optimism': (\"optimism\", LABEL),\n",
        "              'pessimism': (\"pessimism\", LABEL),\n",
        "              'sadness': (\"sadness\", LABEL),\n",
        "              'surprise': (\"surprise\", LABEL),\n",
        "              'trust': (\"trust\", LABEL)}\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path = DATA_PATH,\n",
        "    train = 'train.csv',\n",
        "    validation = 'val.csv',\n",
        "    test = 'test.csv',\n",
        "    format = 'csv',\n",
        "    fields = dataFields\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYMezWxUvyxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    sort_key = lambda x: len(x.Tweet),\n",
        "    sort_within_batch = True,\n",
        "    batch_size = args['batch_size'],\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRmJtf4xPHxE",
        "colab_type": "code",
        "outputId": "12805641-1fbb-4f1e-8207-a497c75d8cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if args['use_glove']:\n",
        "  TEXT.build_vocab(train_data, vectors=torchtext.vocab.Vectors(GLOVE_DIR), \n",
        "                   max_size=args['max_vocab_size'])\n",
        "  \n",
        "  print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 18651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dgYzwnpDhrO",
        "colab_type": "text"
      },
      "source": [
        "# Batch Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZCExSovoy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLS = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
        "              'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "iaux = 0\n",
        "\n",
        "for batch in valid_iterator:\n",
        "  iaux += 1\n",
        "  aux = batch\n",
        "  aux2 = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "  if aux == 20: break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyMA1ST4DlLN",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77GLQlKxDnAx",
        "colab_type": "text"
      },
      "source": [
        "Load the pretrained bert model from the HuggingFace transformers library.\n",
        "\n",
        "https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRiJ1llOvvxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = BertModel.from_pretrained(args['bert_pretrained_model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toQo8u76tf3I",
        "colab_type": "text"
      },
      "source": [
        "Setup the model architecture proposed at: https://www.aclweb.org/anthology/P16-2034/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD1MiUiwv29n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(Attention, self).__init__()\n",
        "\n",
        "    self.attention = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, H):\n",
        "    M = torch.tanh(H)\n",
        "    M = self.attention(M).squeeze(2)\n",
        "    alpha = F.softmax(M, dim=1).unsqueeze(1)\n",
        "    return alpha\n",
        "\n",
        "class AttentionBiLSTM(nn.Module):\n",
        "  def __init__(self, hidden_size, num_layers, dropout, fc_dropout, \n",
        "               emb_layer_dropout, num_classes, use_glove=True):\n",
        "    super(AttentionBiLSTM, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.use_glove = use_glove\n",
        "    \n",
        "    if use_glove:\n",
        "      embedding_dim = args['glove_embedding_dim']\n",
        "      self.embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
        "    else:\n",
        "      self.bert = bert\n",
        "      embedding_dim = args['bert_embedding_dim']\n",
        "    \n",
        "    # embedding layer dropout\n",
        "    self.emb_layer_dropout = nn.Dropout(emb_layer_dropout)\n",
        "\n",
        "    # lstm layer\n",
        "    self.lstm = nn.LSTM(embedding_dim, \n",
        "                        hidden_size, \n",
        "                        num_layers, \n",
        "                        dropout=(0 if num_layers==1 else dropout),\n",
        "                        bidirectional=True,\n",
        "                        batch_first=True)\n",
        "    \n",
        "    # penultimate layer\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    self.fc_dropout = nn.Dropout(fc_dropout)\n",
        "    \n",
        "    self.attention = Attention(hidden_size)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    if self.use_glove:\n",
        "      embedded = self.embedding(text)\n",
        "    else:\n",
        "      embedded = self.bert(text)[0]\n",
        "\n",
        "    embedded = self.emb_layer_dropout(embedded)\n",
        "    y, _ = self.lstm(embedded)\n",
        "    y = y[:,:,:self.hidden_size] + y[:,:,self.hidden_size:]\n",
        "    alpha = self.attention(y)\n",
        "    r = alpha.bmm(y).squeeze(1)\n",
        "    h = torch.tanh(r)\n",
        "    logits = self.fc(h)\n",
        "    logits = self.fc_dropout(logits)\n",
        "    return logits, alpha "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukvWtx9gxE1d",
        "colab_type": "code",
        "outputId": "434d3eb5-9a87-4f9d-83d2-d324ad238694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "model = AttentionBiLSTM(\n",
        "    hidden_size=args['hidden_size'],\n",
        "    num_layers=args['num_layers'],\n",
        "    dropout=args['dropout'],\n",
        "    fc_dropout=args['fc_dropout'],\n",
        "    emb_layer_dropout=args['embed_dropout'],\n",
        "    num_classes=args['output_dim'],\n",
        ")\n",
        "\n",
        "model"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttentionBiLSTM(\n",
              "  (embedding): Embedding(18651, 300)\n",
              "  (emb_layer_dropout): Dropout(p=0.2, inplace=False)\n",
              "  (lstm): LSTM(300, 768, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "  (fc): Linear(in_features=768, out_features=11, bias=True)\n",
              "  (fc_dropout): Dropout(p=0.5, inplace=False)\n",
              "  (attention): Attention(\n",
              "    (attention): Linear(in_features=768, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HIm_dK8EbZ2",
        "colab_type": "text"
      },
      "source": [
        "Freeze the parameters which are a part of the Bert Transformers model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4i0FWYtxQ0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if args['use_glove'] is False:\n",
        "  for name, param in model.named_parameters():                \n",
        "      if name.startswith('bert'):\n",
        "          param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC9ZocNzEoDZ",
        "colab_type": "text"
      },
      "source": [
        "Show the trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1af7wW5xYk_",
        "colab_type": "code",
        "outputId": "221a71c5-4160-4689-92fe-02864795894b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding.weight\n",
            "lstm.weight_ih_l0\n",
            "lstm.weight_hh_l0\n",
            "lstm.bias_ih_l0\n",
            "lstm.bias_hh_l0\n",
            "lstm.weight_ih_l0_reverse\n",
            "lstm.weight_hh_l0_reverse\n",
            "lstm.bias_ih_l0_reverse\n",
            "lstm.bias_hh_l0_reverse\n",
            "lstm.weight_ih_l1\n",
            "lstm.weight_hh_l1\n",
            "lstm.bias_ih_l1\n",
            "lstm.bias_hh_l1\n",
            "lstm.weight_ih_l1_reverse\n",
            "lstm.weight_hh_l1_reverse\n",
            "lstm.bias_ih_l1_reverse\n",
            "lstm.bias_hh_l1_reverse\n",
            "fc.weight\n",
            "fc.bias\n",
            "attention.attention.weight\n",
            "attention.attention.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLuzW7f4EyrX",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1CpxbIDxcb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwZIAAQmxfxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), weight_decay=args['weight_decay'])\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amV2jA0oE2Rx",
        "colab_type": "text"
      },
      "source": [
        "We evaluate using the Jaccard index and the macro and micro F1's as there are more suitable for multi-label text classification problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxF1sRahxmwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score, jaccard_similarity_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YydgwAqkxolz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metricize(preds, y):\n",
        "  f1_macro = f1_score(y, preds.round(), average='macro')\n",
        "  f1_micro = f1_score(y, preds.round(), average='micro')\n",
        "  #acc = roc_auc_score(y, preds)\n",
        "  acc = jaccard_similarity_score(y, preds.round())\n",
        "\n",
        "  return {\n",
        "      'f1_macro': f1_macro,\n",
        "      'f1_micro': f1_micro,\n",
        "      'acc': acc\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLL3mSPZxpkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions, _ = model(batch.Tweet)\n",
        "\n",
        "    batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "    batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "    loss = criterion(predictions, batch_labels)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "    labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  \n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoLaQBVvxrla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "      predictions, _ = model(batch.Tweet)\n",
        "\n",
        "      batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "      batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "      loss = criterion(predictions, batch_labels)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "      labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO9vUx_1xtXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqaePMLEFP7e",
        "colab_type": "text"
      },
      "source": [
        "We train the model for 10 epochs and record the training and validation loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSBSFoBOxwJn",
        "colab_type": "code",
        "outputId": "574c018a-4d4c-4b1c-c43f-b04225916b30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_history = []\n",
        "valid_history = []\n",
        "\n",
        "for epoch in range(args['epochs']):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_metrics = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_metrics = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    train_history.append(train_loss)\n",
        "    valid_history.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        if args['use_glove']:\n",
        "          torch.save(model.state_dict(), 'glove-lstm-model.pt')\n",
        "        else:\n",
        "          torch.save(model.state_dict(), 'bert-lstm-model.pt')\n",
        "        \n",
        "\n",
        "    train_acc = train_metrics['acc']\n",
        "    train_micro = train_metrics['f1_micro']\n",
        "    train_macro = train_metrics['f1_macro']\n",
        "\n",
        "    valid_acc = valid_metrics['acc']\n",
        "    valid_micro = valid_metrics['f1_micro']\n",
        "    valid_macro = valid_metrics['f1_macro']\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train F1 Micro: {train_micro*100:.2f}% | Train F1 Macro: {train_macro*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%  | Val. F1 Micro: {valid_micro*100:.2f}%  | Val. F1 Macro: {valid_macro*100:.2f}%')"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.585 | Train Acc: 7.14% | Train F1 Micro: 9.29% | Train F1 Macro: 5.87%\n",
            "\t Val. Loss: 0.505 | Val. Acc: 16.43%  | Val. F1 Micro: 25.01%  | Val. F1 Macro: 12.31%\n",
            "Epoch: 02 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.554 | Train Acc: 16.09% | Train F1 Micro: 23.29% | Train F1 Macro: 15.52%\n",
            "\t Val. Loss: 0.464 | Val. Acc: 27.39%  | Val. F1 Micro: 40.70%  | Val. F1 Macro: 28.97%\n",
            "Epoch: 03 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.535 | Train Acc: 21.08% | Train F1 Micro: 31.05% | Train F1 Macro: 22.08%\n",
            "\t Val. Loss: 0.452 | Val. Acc: 35.29%  | Val. F1 Micro: 48.18%  | Val. F1 Macro: 35.32%\n",
            "Epoch: 04 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.525 | Train Acc: 23.87% | Train F1 Micro: 35.02% | Train F1 Macro: 25.29%\n",
            "\t Val. Loss: 0.439 | Val. Acc: 36.44%  | Val. F1 Micro: 49.28%  | Val. F1 Macro: 35.51%\n",
            "Epoch: 05 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.515 | Train Acc: 26.06% | Train F1 Micro: 37.54% | Train F1 Macro: 26.93%\n",
            "\t Val. Loss: 0.434 | Val. Acc: 42.02%  | Val. F1 Micro: 54.08%  | Val. F1 Macro: 39.05%\n",
            "Epoch: 06 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.506 | Train Acc: 27.71% | Train F1 Micro: 39.78% | Train F1 Macro: 29.49%\n",
            "\t Val. Loss: 0.434 | Val. Acc: 42.45%  | Val. F1 Micro: 54.91%  | Val. F1 Macro: 39.06%\n",
            "Epoch: 07 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.500 | Train Acc: 29.34% | Train F1 Micro: 41.84% | Train F1 Macro: 31.43%\n",
            "\t Val. Loss: 0.432 | Val. Acc: 43.24%  | Val. F1 Micro: 55.00%  | Val. F1 Macro: 39.54%\n",
            "Epoch: 08 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.490 | Train Acc: 30.65% | Train F1 Micro: 43.71% | Train F1 Macro: 33.14%\n",
            "\t Val. Loss: 0.411 | Val. Acc: 43.82%  | Val. F1 Micro: 56.32%  | Val. F1 Macro: 40.97%\n",
            "Epoch: 09 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.485 | Train Acc: 31.70% | Train F1 Micro: 44.80% | Train F1 Macro: 34.91%\n",
            "\t Val. Loss: 0.401 | Val. Acc: 45.24%  | Val. F1 Micro: 57.59%  | Val. F1 Macro: 42.36%\n",
            "Epoch: 10 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.482 | Train Acc: 32.96% | Train F1 Micro: 46.11% | Train F1 Macro: 35.94%\n",
            "\t Val. Loss: 0.405 | Val. Acc: 45.19%  | Val. F1 Micro: 57.28%  | Val. F1 Macro: 41.51%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqXexw71GcWj",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the training and validation loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CePfv7_0An7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgUKd4HR6Tg-",
        "colab_type": "code",
        "outputId": "dc5fed97-4070-458b-b637-5de1fc5c1f35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plt.plot(train_history)\n",
        "plt.plot(valid_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training', 'Validation'])"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0e9fd37fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtOPAqB1GkB5",
        "colab_type": "text"
      },
      "source": [
        "# Assess model performance on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TxQGreq6Vgm",
        "colab_type": "code",
        "outputId": "2b8328ea-051c-4a65-b6d5-17ee698653fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "model.load_state_dict(torch.load('bert-lstm-model.pt'))\n",
        "\n",
        "test_loss, test_metrics = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "test_acc = test_metrics['acc']\n",
        "test_micro = test_metrics['f1_micro']\n",
        "test_macro = test_metrics['f1_macro']\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test F1 Micro: {test_micro*100:.2f}% | Test F1 Macro: {test_macro*100:.2f}%')"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.394 | Test Acc: 44.21% | Test F1 Micro: 56.40% | Test F1 Macro: 42.86%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaJzLdwb6exr",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ6W1Xpq6aO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_emotion(model, tokenizer, tweet):\n",
        "  preds = []\n",
        "  model.eval()\n",
        "\n",
        "  if args['use_glove']:\n",
        "    tokenized = [token.text for token in nlp.tokenizer(tweet)]\n",
        "    indexed = [TEXT.vocab.stoi[token] for token in tokenized]\n",
        "  else:\n",
        "    tokens = tokenizer.tokenize(tweet)\n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    indexed = [tokenizer.cls_token_id] + tokenizer.convert_tokens_to_ids(tokens) + [tokenizer.sep_token_id]\n",
        "\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  predictions, attn_weights = model(tensor)\n",
        "  preds.append(torch.sigmoid(predictions).detach().cpu().numpy())\n",
        "\n",
        "  if args['use_glove']:\n",
        "    return preds, attn_weights, tokenized\n",
        "  else:\n",
        "    return preds, attn_weights, tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL9EtxTrG7My",
        "colab_type": "text"
      },
      "source": [
        "Lets test the model on our own input and save the attention weights and tokens for visualization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eecw3IVA6lVH",
        "colab_type": "code",
        "outputId": "98a38ef9-a33a-4247-b1f8-42bd40e9848e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "preds, attn_weights, tokens = predict_emotion(model, tokenizer, \n",
        "                                              \"Good music, I love that shit.\")\n",
        "\n",
        "vals = []\n",
        "for p in preds[0]:\n",
        "  for val in p:\n",
        "    vals.append(val)\n",
        "\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "  print(f\"{label.upper()}: {vals[i]}\")"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANGER: 0.36156991124153137\n",
            "ANTICIPATION: 0.07494013756513596\n",
            "DISGUST: 0.16500993072986603\n",
            "FEAR: 0.028195548802614212\n",
            "JOY: 0.6829113364219666\n",
            "LOVE: 0.6023874878883362\n",
            "OPTIMISM: 0.5907031297683716\n",
            "PESSIMISM: 0.16902360320091248\n",
            "SADNESS: 0.09706634283065796\n",
            "SURPRISE: 0.019714193418622017\n",
            "TRUST: 0.07191360741853714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jeDWh8KHbEG",
        "colab_type": "text"
      },
      "source": [
        "Here we format the attention weights and store the results in a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q71LaaAn6oBA",
        "colab_type": "code",
        "outputId": "5f24f0f0-1398-4817-89bc-663d601123ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "aws = []\n",
        "for a in attn_weights[0]:\n",
        "  for v in a:\n",
        "    aws.append(v.detach().cpu().numpy())\n",
        "\n",
        "if args['use_glove']:\n",
        "  aws = np.array(aws)\n",
        "else:\n",
        "  aws = aws[1:-1]\n",
        "  aws = np.array(aws)\n",
        "\n",
        "aws"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01084767, 0.01741131, 0.01671189, 0.00490526, 0.25329673,\n",
              "       0.17155471, 0.5092904 , 0.01598205], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnrDFOGy9DLx",
        "colab_type": "code",
        "outputId": "58dc7f8d-612e-4727-e5c5-56d1a960f05d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attn_dict = {}\n",
        "for i in range(len(aws)):\n",
        "  attn_dict[tokens[i]] = aws[i]\n",
        "\n",
        "print(attn_dict)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Good': 0.010847674, 'music': 0.017411307, ',': 0.016711894, 'I': 0.0049052625, 'love': 0.25329673, 'that': 0.17155471, 'shit': 0.5092904, '.': 0.01598205}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tomju0TvHp8z",
        "colab_type": "text"
      },
      "source": [
        "Lets return the top 3 words that the model focused on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skdcPb0g-nQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LqBqNKVCqan",
        "colab_type": "code",
        "outputId": "4f11cb86-c783-4ae7-86c5-ecac9e7f0b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Counter(attn_dict).most_common(3)"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('shit', 0.5092904), ('love', 0.25329673), ('that', 0.17155471)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    }
  ]
}