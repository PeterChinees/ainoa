{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1lZJpqv-38jmP7zCizHdy8mSu-IMlHlCZ",
      "authorship_tag": "ABX9TyOgbKgqiLR3Lb5QSzmjDW/3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e055157d3c20403bb1fbb85716f93485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_87114a1740b144bb9cc437a2637be5da",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd973c2c3a3b40f3ba94f89bf56b0193",
              "IPY_MODEL_2a1f1c87a74a4f71a3edd34544c2f866"
            ]
          }
        },
        "87114a1740b144bb9cc437a2637be5da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd973c2c3a3b40f3ba94f89bf56b0193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3ffb627c3a544a35b7427bfffb12b799",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_31e64fe1df19455b9a4fe9ddba9fcfba"
          }
        },
        "2a1f1c87a74a4f71a3edd34544c2f866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3367bdb1f93d4f98a0a5893e4bf62e4a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.52MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f76401564e18471fa12eba93cf1b2705"
          }
        },
        "3ffb627c3a544a35b7427bfffb12b799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "31e64fe1df19455b9a4fe9ddba9fcfba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3367bdb1f93d4f98a0a5893e4bf62e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f76401564e18471fa12eba93cf1b2705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "779003e739c24700a4ca6a801c6aaefe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7b57696d1eed4d5987297dafbd026f74",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bbbb9c74b0a8434b8a69532d952103d3",
              "IPY_MODEL_8344606052a44564a4bafa5f2b0fbc55"
            ]
          }
        },
        "7b57696d1eed4d5987297dafbd026f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bbbb9c74b0a8434b8a69532d952103d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af2cee49064e49e0a7905a94eba33ff6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d466c83e5924430a90a4f6cc7ef7f18"
          }
        },
        "8344606052a44564a4bafa5f2b0fbc55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_402dda97913f4bc8a880a7291f7283ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:50&lt;00:00, 8.58B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_758c1eac1e3a4e88955d11d02abd58eb"
          }
        },
        "af2cee49064e49e0a7905a94eba33ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d466c83e5924430a90a4f6cc7ef7f18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "402dda97913f4bc8a880a7291f7283ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "758c1eac1e3a4e88955d11d02abd58eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2d9f1de89db4081aafa60fe84648709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_64430abe4ead4de78aa621eaee16b97f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f0fe3662674148678ffa846e0449ea6a",
              "IPY_MODEL_ee32ea9fdbd94f5883ea55e239588bf0"
            ]
          }
        },
        "64430abe4ead4de78aa621eaee16b97f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0fe3662674148678ffa846e0449ea6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5d81552f1be04c389e40cc363eb0a531",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5c4cbd3f0716464491fba6ab0d70950f"
          }
        },
        "ee32ea9fdbd94f5883ea55e239588bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f6549716cf7844499f0fac9dcd4b6e56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:11&lt;00:00, 40.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d97e96551894a439d614d32fd86bb4c"
          }
        },
        "5d81552f1be04c389e40cc363eb0a531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5c4cbd3f0716464491fba6ab0d70950f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6549716cf7844499f0fac9dcd4b6e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d97e96551894a439d614d32fd86bb4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/ainoa/blob/master/Attention_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWaTkjkKu9TB",
        "colab_type": "code",
        "outputId": "e56121c4-9bb6-4d1b-ea03-f38cad416bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/97/7db72a0beef1825f82188a4b923e62a146271ac2ced7928baa4d47ef2467/transformers-2.9.1-py3-none-any.whl (641kB)\n",
            "\r\u001b[K     |▌                               | 10kB 17.7MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 1.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 2.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 2.9MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 3.3MB/s eta 0:00:01\r\u001b[K     |████                            | 81kB 3.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 4.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 102kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 133kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 153kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 163kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 184kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 194kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 204kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 215kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 225kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 235kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 245kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 256kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 266kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 276kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 286kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 296kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 307kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 317kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 327kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 337kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 348kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 358kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 368kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 389kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 399kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 409kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 419kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 430kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 440kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 450kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 460kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 471kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 481kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 491kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 501kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 512kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 522kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 532kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 542kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 552kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 563kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 573kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 583kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 593kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 604kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 614kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 624kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 634kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 38.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 34.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 22.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=4d650f5d3ec42258471b66ce6995b0208ce6b6ece65ddee944c9f394a1f9e97a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.90 tokenizers-0.7.0 transformers-2.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLFhbGO8C4gJ",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xU5Pc6mvbY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import random\n",
        "import re\n",
        "import transformers\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from pathlib import Path\n",
        "from torchtext import data\n",
        "from torchtext.vocab import GloVe\n",
        "from transformers import BertTokenizer, BertModel, DistilBertTokenizer, DistilBertModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzgKR2a8UeXi",
        "colab_type": "code",
        "outputId": "02c678a5-eaca-4f1f-b038-14fff7f69015",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(torch.__version__)\n",
        "print(transformers.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0+cu101\n",
            "2.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZYWV6HMDEm6",
        "colab_type": "text"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FczMGWp1vM_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    \"bert_tokenizer\": \"bert-base-uncased\",\n",
        "    \"bert_pretrained_model\": \"bert-base-uncased\",\n",
        "    \"distilbert_tokenizer\": \"distilbert-base-uncased\",\n",
        "    \"distilbert_pretrained_model\": \"distilbert-base-uncased\",\n",
        "    \"seed\": 1234,\n",
        "    \"bert_embedding_dim\": 768,\n",
        "    \"use_glove\": False,\n",
        "    \"glove_embedding_dim\": 300,\n",
        "    \"max_vocab_size\": 20000,\n",
        "    \"batch_size\": 10,\n",
        "    \"output_dim\": 11,\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 2,\n",
        "    \"dropout\": 0.3,\n",
        "    \"fc_dropout\": 0.5,\n",
        "    \"embed_dropout\": 0.3,\n",
        "    \"weight_decay\": 1e-5,\n",
        "    \"lr\": 0.001,\n",
        "    \"epochs\": 10\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLH3fXNGcq1L",
        "colab_type": "text"
      },
      "source": [
        "# Text pre-processor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m57bXVOPcs0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessor(text):\n",
        "  text = re.sub('<[^>]*>', '', text)\n",
        "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "  text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
        "          ' '.join(emoticons).replace('-', '')) \n",
        "  return text.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s6Jmte7LiVS",
        "colab_type": "code",
        "outputId": "e2bc1818-6f8d-461c-b714-be85ccc023cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "og_text = '#Good music I love that #shit.'\n",
        "processed = preprocessor(og_text)\n",
        "processed"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good', 'music', 'i', 'love', 'that', 'shit']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QizRI-q1DPf1",
        "colab_type": "text"
      },
      "source": [
        "# Setup Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4nYNxu4vV9X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e055157d3c20403bb1fbb85716f93485",
            "87114a1740b144bb9cc437a2637be5da",
            "bd973c2c3a3b40f3ba94f89bf56b0193",
            "2a1f1c87a74a4f71a3edd34544c2f866",
            "3ffb627c3a544a35b7427bfffb12b799",
            "31e64fe1df19455b9a4fe9ddba9fcfba",
            "3367bdb1f93d4f98a0a5893e4bf62e4a",
            "f76401564e18471fa12eba93cf1b2705"
          ]
        },
        "outputId": "8e436c8f-2320-4cb8-d680-80ccdfc0267a"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(args['bert_tokenizer'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e055157d3c20403bb1fbb85716f93485",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBv0eC2xvss-",
        "colab_type": "code",
        "outputId": "87807e1f-6e62-405b-9822-77c05814ee12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes[args['bert_tokenizer']]\n",
        "\n",
        "print(max_input_length)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMBjmcymvlY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(tweet):\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFFnMbqQDbJC",
        "colab_type": "text"
      },
      "source": [
        "# Load and Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYj3qsDpvmwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive'\n",
        "\n",
        "DATA_PATH = Path(file_path + '/datasets/SemEval')\n",
        "\n",
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "if args['use_glove']:\n",
        "  TEXT = data.Field(batch_first=True,\n",
        "                    tokenize=preprocessor,\n",
        "                    use_vocab=True,\n",
        "                    sequential=True)\n",
        "else:\n",
        "  TEXT = data.Field(batch_first = True,\n",
        "                use_vocab = False,\n",
        "                tokenize = tokenize,\n",
        "                preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                init_token = tokenizer.cls_token_id,\n",
        "                eos_token = tokenizer.sep_token_id,\n",
        "                pad_token = tokenizer.pad_token_id,\n",
        "                unk_token = tokenizer.unk_token_id)\n",
        "  \n",
        "LABEL = data.LabelField(sequential = False,\n",
        "                        use_vocab = False,\n",
        "                        pad_token= None,\n",
        "                        unk_token = None, \n",
        "                        dtype = torch.float)\n",
        "\n",
        "dataFields = {\"Tweet\": (\"Tweet\", TEXT),\n",
        "              'anger': (\"anger\", LABEL),\n",
        "              'anticipation': (\"anticipation\", LABEL),\n",
        "              'disgust': (\"disgust\", LABEL),\n",
        "              'fear': (\"fear\", LABEL),\n",
        "              'joy': (\"joy\", LABEL),\n",
        "              'love': (\"love\", LABEL),\n",
        "              'optimism': (\"optimism\", LABEL),\n",
        "              'pessimism': (\"pessimism\", LABEL),\n",
        "              'sadness': (\"sadness\", LABEL),\n",
        "              'surprise': (\"surprise\", LABEL),\n",
        "              'trust': (\"trust\", LABEL)}\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path = DATA_PATH,\n",
        "    train = 'train.csv',\n",
        "    validation = 'val.csv',\n",
        "    test = 'test.csv',\n",
        "    format = 'csv',\n",
        "    fields = dataFields\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYMezWxUvyxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    sort_key = lambda x: len(x.Tweet),\n",
        "    sort_within_batch = True,\n",
        "    batch_size = args['batch_size'],\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRmJtf4xPHxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if args['use_glove']:\n",
        "  TEXT.build_vocab(train_data, vectors=GloVe(name='6B', dim=300), \n",
        "                   max_size=args['max_vocab_size'])\n",
        "  print(f\"\\nUnique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dgYzwnpDhrO",
        "colab_type": "text"
      },
      "source": [
        "# Batch Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZCExSovoy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLS = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
        "              'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "iaux = 0\n",
        "\n",
        "for batch in valid_iterator:\n",
        "  iaux += 1\n",
        "  aux = batch\n",
        "  aux2 = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "  if aux == 20: break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyMA1ST4DlLN",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77GLQlKxDnAx",
        "colab_type": "text"
      },
      "source": [
        "Load the pretrained bert model from the HuggingFace transformers library.\n",
        "\n",
        "https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRiJ1llOvvxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "779003e739c24700a4ca6a801c6aaefe",
            "7b57696d1eed4d5987297dafbd026f74",
            "bbbb9c74b0a8434b8a69532d952103d3",
            "8344606052a44564a4bafa5f2b0fbc55",
            "af2cee49064e49e0a7905a94eba33ff6",
            "6d466c83e5924430a90a4f6cc7ef7f18",
            "402dda97913f4bc8a880a7291f7283ab",
            "758c1eac1e3a4e88955d11d02abd58eb",
            "e2d9f1de89db4081aafa60fe84648709",
            "64430abe4ead4de78aa621eaee16b97f",
            "f0fe3662674148678ffa846e0449ea6a",
            "ee32ea9fdbd94f5883ea55e239588bf0",
            "5d81552f1be04c389e40cc363eb0a531",
            "5c4cbd3f0716464491fba6ab0d70950f",
            "f6549716cf7844499f0fac9dcd4b6e56",
            "8d97e96551894a439d614d32fd86bb4c"
          ]
        },
        "outputId": "5cb2311b-50cf-49ec-e68d-a0838b6a49a0"
      },
      "source": [
        "bert = BertModel.from_pretrained(args['bert_pretrained_model'])\n",
        "# bert = BertModel.from_pretrained(args['distilbert_pretrained_model'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "779003e739c24700a4ca6a801c6aaefe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2d9f1de89db4081aafa60fe84648709",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toQo8u76tf3I",
        "colab_type": "text"
      },
      "source": [
        "Use model architecture proposed at: https://www.aclweb.org/anthology/P16-2034/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD1MiUiwv29n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(Attention, self).__init__()\n",
        "\n",
        "    self.attention = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, H):\n",
        "    M = torch.tanh(H)\n",
        "    M = self.attention(M).squeeze(2)\n",
        "    alpha = F.softmax(M, dim=1).unsqueeze(1)\n",
        "    return alpha\n",
        "\n",
        "class AttentionBiLSTM(nn.Module):\n",
        "  def __init__(self, hidden_size, num_layers, dropout, fc_dropout, \n",
        "               emb_layer_dropout, num_classes):\n",
        "    super(AttentionBiLSTM, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    if args['use_glove']:\n",
        "      embedding_dim = args['glove_embedding_dim']\n",
        "      self.embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
        "    else:\n",
        "      self.bert = bert\n",
        "      embedding_dim = args['bert_embedding_dim']\n",
        "    \n",
        "    # embedding layer dropout\n",
        "    self.emb_layer_dropout = nn.Dropout(emb_layer_dropout)\n",
        "\n",
        "    # lstm layer\n",
        "    self.lstm = nn.LSTM(embedding_dim, \n",
        "                        hidden_size, \n",
        "                        num_layers, \n",
        "                        dropout=(0 if num_layers==1 else dropout),\n",
        "                        bidirectional=True,\n",
        "                        batch_first=True)\n",
        "    \n",
        "    # penultimate layer\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    self.fc_dropout = nn.Dropout(fc_dropout)\n",
        "    \n",
        "    self.attention = Attention(hidden_size)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    if args['use_glove']:\n",
        "      embedded = self.embedding(text)\n",
        "    else:\n",
        "      with torch.no_grad():\n",
        "        embedded = self.bert(text)[0]\n",
        "\n",
        "    embedded = self.emb_layer_dropout(embedded)\n",
        "    y, _ = self.lstm(embedded)\n",
        "    y = y[:,:,:self.hidden_size] + y[:,:,self.hidden_size:]\n",
        "    alpha = self.attention(y)\n",
        "    r = alpha.bmm(y).squeeze(1)\n",
        "    h = torch.tanh(r)\n",
        "    logits = self.fc(h)\n",
        "    logits = self.fc_dropout(logits)\n",
        "    return logits, alpha "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukvWtx9gxE1d",
        "colab_type": "code",
        "outputId": "a188d3d1-d2ac-4da2-e09e-c4662a2e2e6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = AttentionBiLSTM(\n",
        "    hidden_size=args['hidden_size'],\n",
        "    num_layers=args['num_layers'],\n",
        "    dropout=args['dropout'],\n",
        "    fc_dropout=args['fc_dropout'],\n",
        "    emb_layer_dropout=args['embed_dropout'],\n",
        "    num_classes=args['output_dim'],\n",
        ")\n",
        "\n",
        "\n",
        "model"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttentionBiLSTM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (emb_layer_dropout): Dropout(p=0.3, inplace=False)\n",
              "  (lstm): LSTM(768, 256, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=11, bias=True)\n",
              "  (fc_dropout): Dropout(p=0.5, inplace=False)\n",
              "  (attention): Attention(\n",
              "    (attention): Linear(in_features=256, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HIm_dK8EbZ2",
        "colab_type": "text"
      },
      "source": [
        "Freeze the parameters which are a part of the Bert Transformers model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4i0FWYtxQ0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if args['use_glove'] is False:\n",
        "  for name, param in model.named_parameters():                \n",
        "      if name.startswith('bert'):\n",
        "          param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC9ZocNzEoDZ",
        "colab_type": "text"
      },
      "source": [
        "Show the trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1af7wW5xYk_",
        "colab_type": "code",
        "outputId": "49357106-3b47-4893-c0d2-da4fcabc0023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lstm.weight_ih_l0\n",
            "lstm.weight_hh_l0\n",
            "lstm.bias_ih_l0\n",
            "lstm.bias_hh_l0\n",
            "lstm.weight_ih_l0_reverse\n",
            "lstm.weight_hh_l0_reverse\n",
            "lstm.bias_ih_l0_reverse\n",
            "lstm.bias_hh_l0_reverse\n",
            "lstm.weight_ih_l1\n",
            "lstm.weight_hh_l1\n",
            "lstm.bias_ih_l1\n",
            "lstm.bias_hh_l1\n",
            "lstm.weight_ih_l1_reverse\n",
            "lstm.weight_hh_l1_reverse\n",
            "lstm.bias_ih_l1_reverse\n",
            "lstm.bias_hh_l1_reverse\n",
            "fc.weight\n",
            "fc.bias\n",
            "attention.attention.weight\n",
            "attention.attention.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLuzW7f4EyrX",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1CpxbIDxcb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwZIAAQmxfxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), weight_decay=args['weight_decay'])\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amV2jA0oE2Rx",
        "colab_type": "text"
      },
      "source": [
        "We evaluate using the Jaccard index and the macro and micro F1's as there are more suitable for multi-label text classification problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxF1sRahxmwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score, jaccard_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YydgwAqkxolz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metricize(preds, y):\n",
        "  f1_macro = f1_score(y, preds.round(), average='macro')\n",
        "  f1_micro = f1_score(y, preds.round(), average='micro')\n",
        "  jaccard = jaccard_score(y, preds.round(), average='samples')\n",
        "\n",
        "  return {\n",
        "      'f1_macro': f1_macro,\n",
        "      'f1_micro': f1_micro,\n",
        "      'jaccard': jaccard,\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLL3mSPZxpkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions, _ = model(batch.Tweet)\n",
        "\n",
        "    batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "    batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "    loss = criterion(predictions, batch_labels)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "    labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  \n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoLaQBVvxrla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "      predictions, _ = model(batch.Tweet)\n",
        "     \n",
        "      batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "      batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "      loss = criterion(predictions, batch_labels)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "      labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list)), preds_list, labels_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO9vUx_1xtXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqaePMLEFP7e",
        "colab_type": "text"
      },
      "source": [
        "We train the model for 10 epochs and record the training and validation loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSBSFoBOxwJn",
        "colab_type": "code",
        "outputId": "c139462d-1b14-43eb-98e6-23c5efef0ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "train_acc = []\n",
        "valid_acc = []\n",
        "\n",
        "for epoch in range(args['epochs']):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_metrics = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_metrics, _, _, = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        if args['use_glove']:\n",
        "          torch.save(model.state_dict(), 'glove-lstm-model.pt')\n",
        "        else:\n",
        "          torch.save(model.state_dict(), 'bert-lstm-model.pt')\n",
        "        \n",
        "    train_jaccard = train_metrics['jaccard']\n",
        "    train_micro = train_metrics['f1_micro']\n",
        "    train_macro = train_metrics['f1_macro']\n",
        "\n",
        "    valid_jaccard = valid_metrics['jaccard']\n",
        "    valid_micro = valid_metrics['f1_micro']\n",
        "    valid_macro = valid_metrics['f1_macro']\n",
        "\n",
        "    train_acc.append(train_jaccard)\n",
        "    valid_acc.append(valid_jaccard)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Jaccard: {train_jaccard*100:.2f}% | Train F1 Micro: {train_micro*100:.2f}% | Train F1 Macro: {train_macro*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} | Val. Jaccard: {valid_jaccard*100:.2f}%  | Val. F1 Micro: {valid_micro*100:.2f}%  | Val. F1 Macro: {valid_macro*100:.2f}%')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 58s\n",
            "\tTrain Loss: 0.549 | Train Jaccard: 17.59% | Train F1 Micro: 28.97% | Train F1 Macro: 17.64%\n",
            "\t Val. Loss: 0.410 | Val. Jaccard: 44.58%  | Val. F1 Micro: 58.50%  | Val. F1 Macro: 35.40%\n",
            "Epoch: 02 | Epoch Time: 0m 58s\n",
            "\tTrain Loss: 0.519 | Train Jaccard: 24.03% | Train F1 Micro: 37.21% | Train F1 Macro: 25.59%\n",
            "\t Val. Loss: 0.384 | Val. Jaccard: 51.01%  | Val. F1 Micro: 63.18%  | Val. F1 Macro: 41.96%\n",
            "Epoch: 03 | Epoch Time: 0m 58s\n",
            "\tTrain Loss: 0.511 | Train Jaccard: 25.93% | Train F1 Micro: 39.52% | Train F1 Macro: 27.91%\n",
            "\t Val. Loss: 0.380 | Val. Jaccard: 51.48%  | Val. F1 Micro: 64.77%  | Val. F1 Macro: 46.24%\n",
            "Epoch: 04 | Epoch Time: 0m 58s\n",
            "\tTrain Loss: 0.508 | Train Jaccard: 26.35% | Train F1 Micro: 40.13% | Train F1 Macro: 29.02%\n",
            "\t Val. Loss: 0.378 | Val. Jaccard: 50.21%  | Val. F1 Micro: 63.50%  | Val. F1 Macro: 45.75%\n",
            "Epoch: 05 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.503 | Train Jaccard: 26.73% | Train F1 Micro: 40.85% | Train F1 Macro: 29.17%\n",
            "\t Val. Loss: 0.368 | Val. Jaccard: 54.00%  | Val. F1 Micro: 66.14%  | Val. F1 Macro: 47.09%\n",
            "Epoch: 06 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.501 | Train Jaccard: 27.72% | Train F1 Micro: 41.60% | Train F1 Macro: 30.76%\n",
            "\t Val. Loss: 0.371 | Val. Jaccard: 54.46%  | Val. F1 Micro: 67.40%  | Val. F1 Macro: 49.47%\n",
            "Epoch: 07 | Epoch Time: 0m 58s\n",
            "\tTrain Loss: 0.502 | Train Jaccard: 27.64% | Train F1 Micro: 41.74% | Train F1 Macro: 30.74%\n",
            "\t Val. Loss: 0.356 | Val. Jaccard: 53.06%  | Val. F1 Micro: 66.14%  | Val. F1 Macro: 48.13%\n",
            "Epoch: 08 | Epoch Time: 0m 59s\n",
            "\tTrain Loss: 0.494 | Train Jaccard: 28.65% | Train F1 Micro: 42.73% | Train F1 Macro: 32.13%\n",
            "\t Val. Loss: 0.356 | Val. Jaccard: 55.03%  | Val. F1 Micro: 67.67%  | Val. F1 Macro: 49.43%\n",
            "Epoch: 09 | Epoch Time: 0m 58s\n",
            "\tTrain Loss: 0.492 | Train Jaccard: 28.19% | Train F1 Micro: 42.56% | Train F1 Macro: 32.12%\n",
            "\t Val. Loss: 0.353 | Val. Jaccard: 54.89%  | Val. F1 Micro: 66.68%  | Val. F1 Macro: 51.03%\n",
            "Epoch: 10 | Epoch Time: 0m 58s\n",
            "\tTrain Loss: 0.491 | Train Jaccard: 28.35% | Train F1 Micro: 42.74% | Train F1 Macro: 31.86%\n",
            "\t Val. Loss: 0.363 | Val. Jaccard: 52.84%  | Val. F1 Micro: 65.48%  | Val. F1 Macro: 48.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqXexw71GcWj",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the training and validation loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CePfv7_0An7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgUKd4HR6Tg-",
        "colab_type": "code",
        "outputId": "5c7f247e-9b7d-4912-db79-a5f21cffa2f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plt.plot(train_losses)\n",
        "plt.plot(valid_losses)\n",
        "# plt.title('Attention LSTM (GloVe) Training & Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training', 'Validation'])\n",
        "\n",
        "# plt.savefig('attn-lstm-glove', dpi=300)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f42930a37b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSlSdy6ALwj4",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the training and validation jaccard accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qDGgLbPL29w",
        "colab_type": "code",
        "outputId": "059b6cd6-0bb8-4452-a11d-124eaa02c7b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plt.plot(train_acc)\n",
        "plt.plot(valid_acc)\n",
        "# plt.title('Attention LSTM (GloVe) Training & Validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Jaccard')\n",
        "plt.legend(['Training', 'Validation'])\n",
        "# plt.savefig('attn-lstm-acc-glove', dpi=300)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f42923540b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de3xV5Zn3/8+Vc0g4J/FAQAIieAaJSOUZrWfUFp5O7QiOHRhHUR8drdZpbWtbijq1an3aaa1TPHR8WkvaTjv+oNJaRVFbFRMUD5wUIkIQJZxCQhJyun5/rJVkJ+yEAHtn5/B9v177tfc67X1lK+u7132vdS9zd0RERNpLSnQBIiLSMykgREQkKgWEiIhEpYAQEZGoFBAiIhJVSqILiJWcnBwfPXp0ossQEelVVq5cucPdc6Mt6zMBMXr0aEpKShJdhohIr2JmH3W0TE1MIiISlQJCRESiUkCIiEhUCggREYlKASEiIlHFNSDMbLqZrTezDWZ2Z5Tlc82s3MxWhY9rI5Y1RsxfHM86RUTkQHE7zdXMkoGHgYuAMqDYzBa7+5p2q/7G3W+O8hY17j4xXvWJiEjn4nkdxBRgg7uXAphZETATaB8QIiJd01AHH/0VthSDGSSnQlIqJKdBckrwnJQazE8O5yeF85vntazffjpi+6Tk4P37uXgGxAhgS8R0GXBWlPW+aGbnAO8Dt7l78zYZZlYCNAD3ufvT7Tc0s3nAPIBRo0bFsnYR6Slq9sCG52HdM8Hz/r3d8KHWhYBJgaw8GD8dJnwOBh7dDXV1r0RfSb0EWOTu+83seuBJ4Pxw2XHuvtXMxgAvmNm77r4xcmN3XwgsBCgsLNSdj0T6ij2bYf2fglD46G/Q1ABZuXDSTJhwORScG+ykG+ugqR4amx91wbqNda3zmupbpztc1nDo79VYD7s2wjNfhWfugJFT4MTPB2ExrCDR32BMxDMgtgIjI6bzw3kt3H1nxORjwP0Ry7aGz6VmthyYBLQJCJE+pbEBaiugZhfU7Ibq8LlmVzB/8EjIPxNyToCkPnYCojtsWwXrlgbB8Om7wfyc8XD2v8L4y2BE4YF/d3KCf+O6Q/l6WLsE1i6Gv9wVPI46NQiLEz8PeSf22uYqi9ctR80shaDZ6AKCYCgGrnL31RHrHOPu28LXXwC+7u5TzWwoUB0eWeQArwEzo3RwtygsLHSNxSQ9QlMT7K8Id/B7ou/wo03XVnTt/dMHwYjJQVjknwn5hTBgWHz/pnho2A8fvgLrw1Co/BgsCUZOhQmXBaEwfGyiqzw0uzcFRz1rl8Dm1wGHYWNbw+LYM3pcuJvZSncvjLosnvekNrPLgB8BycAT7n6vmS0AStx9sZl9H5hB0M+wC7jR3deZ2dnAz4EmglNxf+Tuj3f2WQoIiYuGumDH1bIzj3h0tMOv3QPe1PF7ZgyGzGGQOTTYsWcO7WR6aPCcPgh2lUJZcevj09WtnzNsbGtY5J8JR50ctJf3NNW74IPnYP0zsGEZ1FVB6gAYe37QdDTuEsganugqY6Py0+DvXLsEPnw5aK4aeCyc+LkgLEadnfgjIBIYEN1JASEx5Q7v/Bae+w5UfRJ9nbSBrTvwru7wM4cEZ8jEwv6qoFmmrBjKSmDLG7Bve7AsJROOndQaGPlnwqBjYvO5h2rXh8ERwvql8NGr4I2QfRSMvzQ4Sig4F1IzElNbd6nZDe//JWiG2rAMGmqC/yfGXxaExZjPJuw7UECIHIpt78CfvgabXwt2soXXwICcdjv8oT3vF7o7VGxpDYyyYtj2dtCpCjAov21gHHN6fHZKTU3w8Vth09FS2B62DOedFIbC5cH32sOaWrpN3b4gJNYugfefDZoj07Jh3MXB0cW4iyF9YLeVo4AQ6YrqXfDivVDyRBAAF3wXJn25d+/IGvbDJ++2bZraszlYlpQKR5/ati9j6OjD61Ctrw2aUdY/A+v/HBx1WTIcd3bwK3n8dBg2JqZ/Wp/QUAebXg7CYt0zsK8cktNh7HnBkcUJl8a9yU0BIdKZpkZ48//BsgVB/8GZ18J53wxCoi+q/BS2lrQeaWxdCfXVwbIBOW37Mkac0fGv2X074YO/hP0JL0D9vuCX8PEXBEcJ4y7qnZ3nidLUCFtWwNo/BoFRsTkI2dHTYMLngz6awSNi/rEKCJGObCmGpXcEbfmjzobL7g9+VfcnjQ1QvrZt09SO98OFFjQNNQdG7gTY8nrQp7D5taCTfOAxrU1HBX8HKekJ/XP6BPegeXDtkuCxY30wf0Rh6xlRMTrDSwEh0l7Vdnh+Pqx6KtjBXXwPnPLFXnu+eszV7A6OLJoDo6y47Wm4R50SNh1dGvQn6HuLr/L3YV0YFh+/FczLO6k1LI465bD/GyggRJo11sMbj8Ly70N9DXzmJjjn3yA9O9GV9WxNTcFVw9vXBJ3bQ0cnuqL+a8/miGstwqO4UZ+Ba/58WG/XWUAk/iRcke5S+hL86etBc8rxF8L0+yBnXKKr6h2SkoLvSt9X4g0ZBVNvDB5V5cGZYs1nqsWYAkL6vooyePZbsOZpGHIczFoUNI2oWUR6u+xcmDwnbm+vgJC+q74WXvsJvPJQcBh+3reCcX1SMxNdmUivoICQvun9Z4PmpN0fwokz4JJ7g0NzEekyBYT0LTs3wp+/AR88G4x6+uX/Ccb5EZFDpoCQvqFuH7zyQ3j1J8GVqBffA1Ouh5S0RFcm0mspIPoLd9hfGYw8Wr0rfN7dbjp8bmoMzqs+diIcMxGGH99zh5twh9X/E4zBv3crnDYLLvpen7y7l0h3U0D0Ro31B+7U2z/X7Gk3b3dwN6yONA9BPWBYsNMteRwaaoNladlw9GnB+e/NoZEzLnajkh6u7Wth6b/BpleCq5+veAJGTU1sTSJ9iAKip2hqCi562ftx5zv+6t1QV9nx+ySnte7oM4cFO/LI6WjPGUMOHJe+sSG4vP/jVcEl/9tWwZtPwopHguWpA4Kd8jETw9A4Pbj7V3eMb19bAcvvgxU/h4xBcPlDMHlu4gNLpI/RldQ9QVMTLP1qMIpopMhf9Qc8t7vXQPOytKz4nd/f1BiM0bPt7TA4VgVDY9fvC5anZMLRp7QNjdwJsRsWu6kJ3l4Ez38X9u2Awn+G87+tAeFEjoCG2ujJIsPh7H+FSf/U8a/6nqipEXZuODA0mo9yktNbQ6O5iSr3xEPvPN76ZnCPhrJiyJ8Clz0QvJeIHBEFRE/lDs98NWjvn/YVuHB+37i6t6kpuD3mtlXBwGLb3g4e+/cGy5PTgoHGmvszjp0YTEcbBXTfTlj2vWA47qxcuGgBnHZlz+00F+llEnlP6unAjwnuSf2Yu9/Xbvlc4AFgazjrp+7+WLhsDnBXOP8ed3+ys8/qdQHRJhxuhQu/1zfCoSNNTcFFa9tWRRxpvN06QmhSKuSd2Boax0yEj9+EF+4J7lt81g1w7teDPgcRiZmEBISZJQPvAxcBZUAxMNvd10SsMxcodPeb2207DCgBCgEHVgKT3X13R5/XqwLCPbgHQfFjcPYtwa/ivhwOHXGH3ZsiQiPsDK+J+M9ccC5cej/kTUhYmSJ9WaJGc50CbHD30rCIImAmsKbTrQKXAM+5+65w2+eA6cCiONXafdyDUzOLHwv6HPprOEDwdw8rCB4nfyGY5x4MZ7xtVXB67djz++/3I5Jg8QyIEcCWiOky4Kwo633RzM4hONq4zd23dLDtAffaM7N5wDyAUaN6wTg77kFHa/Gj8Jmb4aK7tfNrzwyGHhc8RCShEt3TtwQY7e6nAc8BnfYztOfuC9290N0Lc3Nz41JgzLgHg8e9sTAIh4vvUTiISI8Wz4DYCoyMmM6ntTMaAHff6e77w8nHgMld3bZXcYc/3wlv/Bym3qRwEJFeIZ4BUQyMM7MCM0sDZgGLI1cws2MiJmcAa8PXzwIXm9lQMxsKXBzO633cg9FFV/wnTP0/wbDTCgcR6QXi1gfh7g1mdjPBjj0ZeMLdV5vZAqDE3RcDt5jZDKAB2AXMDbfdZWZ3E4QMwILmDutexR2e/WYwPMVZN8Il/65wEJFeQxfKxYt7cJvL1x8OwmH69xUOItLjdHaaa6I7qfsm92D46dcfDi7wUjiISC+kgIi15nB47afBDWum36dwEJFeSQERS+7w3Ldbw+HSHygcRKTXUkDESnM4vPoTmDJP4SAivZ4CIhbc4bnvBOFw5nXB2EEKBxHp5RQQR8o9uIHNq/8BZ14b3KdA4SAifYAC4ki4w/Pz4W8/hsJ/gcseVDiISJ+hgDhc7sGNbP72Iyi8RuEgIn2OAuJwuMOyBfDX/wuT/xku+6HucCYifY72aofKHV64G/76EEyeC5c/pHAQkT5Je7ZD4R7cAvOVH8IZc+Dy/6twEJE+S3u3rnKHF++FVx6EM/4JPvcjhYOI9Gnaw3WFO7z47/DyA2E4/FjhICJ9nvZyXbH8+/Dy/TDpywoHEek3tKc7mBe/Dy/9ACZdDZ//D4WDiPQb2tt1Zvl98NJ9MPFq+PxPFA4i0q9oj9eR5fcFTUsTr4YZCgcR6X/iutczs+lmtt7MNpjZnZ2s90UzczMrDKdHm1mNma0KH/8ZzzoPsPwHYTj8o8JBRPqtuN2T2sySgYeBi4AyoNjMFrv7mnbrDQRuBVa0e4uN7j4xXvV16KX7Yfm/w+lXKRxEpF+L595vCrDB3UvdvQ4oAmZGWe9u4AdAbRxr6ZqXHgiudTh9Nsz8KSQlJ7oiEZGEiWdAjAC2REyXhfNamNkZwEh3fybK9gVm9paZvWRmfxftA8xsnpmVmFlJeXn5kVX78gPw4j1w2iyY+bDCQUT6vYS1n5hZEvAQ8NUoi7cBo9x9EnA78GszG9R+JXdf6O6F7l6Ym5t7+MW8/GAwhMZps+B//0zhICJCfANiKzAyYjo/nNdsIHAKsNzMNgFTgcVmVuju+919J4C7rwQ2AifEpcry94OrpE+7UuEgIhIhbp3UQDEwzswKCIJhFnBV80J3rwBymqfNbDlwh7uXmFkusMvdG81sDDAOKI1LlbknwDV/hhGTFQ4iIhHiFhDu3mBmNwPPAsnAE+6+2swWACXuvriTzc8BFphZPdAE3ODuu+JVKyOnxO2tRUR6K3P3RNcQE4WFhV5SUpLoMkREehUzW+nuhdGW6SR/ERGJSgEhIiJRKSBERCQqBYSIiESlgBARkagUECIiEpUCQkREolJAiIhIVAoIERGJSgEhIiJRKSBERCQqBYSIiESlgBARkagUECIiEpUCQkREolJAiIhIVAoIERGJKq4BYWbTzWy9mW0wszs7We+LZuZmVhgx7xvhduvN7JJ41ikiIgeK2z2pzSwZeBi4CCgDis1ssbuvabfeQOBWYEXEvJOAWcDJwLHA82Z2grs3xqteERFpK55HEFOADe5e6u51QBEwM8p6dwM/AGoj5s0Eitx9v7t/CGwI309ERLpJPANiBLAlYrosnNfCzM4ARrr7M4e6rYiIxFfCOqnNLAl4CPjqEbzHPDMrMbOS8vLy2BUnIiJxDYitwMiI6fxwXrOBwCnAcjPbBEwFFocd1QfbFgB3X+juhe5emJubG+PyRUT6t3gGRDEwzswKzCyNoNN5cfNCd69w9xx3H+3uo4HXgRnuXhKuN8vM0s2sABgHvBHHWkVEpJ0Oz2Iys58A3tFyd7+lszd29wYzuxl4FkgGnnD31Wa2AChx98WdbLvazH4LrAEagJt0BpOISPcy9+gZYGZzwpfTgJOA34TTXwLWuPsN8S+v6woLC72kpCTRZYiI9CpmttLdC6Mt6/AIwt2fDDe+Efhf7t4QTv8n8Eo8ChURkZ6jK30QQ4FBEdPZ4TwREenDunIl9X3AW2b2ImDAOcD8eBYlIiKJ12lAhNcqrAfOCh8AX3f3T+JdmIiIJFanAeHuTWb2sLtPAv6/bqpJRER6gK70QSwLR1u1uFcjIiI9RlcC4nrgd8B+M9trZpVmtjfOdYmISIIdtJPa3Qd2RyEiItKzdOl+EGY2lGC4i4zmee7+cryKEhGRxDtoQJjZtQQ39MkHVhEMqvcacH58SxMRkUTqSh/ErcCZwEfufh4wCdgT16pERCThuhIQte5eC2Bm6e6+Dhgf37JERCTRutIHUWZmQ4CngefMbDfwUXzLEhGRROvKWUxfCF/OD4fbGAz8Oa5ViYhIwh20icnMpprZQAB3fwlYTtAPISIifVhX+iAeAaoipqvCeSIi0od1JSDMI+4q5O5NdPH6CRER6b26EhClZnaLmaWGj1uB0ngXJiIiidWVgLgBOBvYCpQRDPs9rytvbmbTzWy9mW0wszujLL/BzN41s1Vm9lczOymcP9rMasL5q8K72ImISDfqyllM24FZh/rGZpYMPAxcRBAsxWa22N3XRKz2a3f/z3D9GcBDwPRw2UZ3n3ionysiIrHRlbOYngyvg2ieHmpmT3ThvacAG9y91N3rgCJgZuQK7h45KmwW4IiISI/QlSam09y9ZWgNd99N105zHQFsiZguC+e1YWY3mdlG4H7glohFBWb2lpm9ZGZ/F+0DzGyemZWYWUl5eXkXShIRka7qSkAkhaO5AmBmw4jhWUzu/rC7jwW+DtwVzt4GjArvZHc78GszGxRl24XuXujuhbm5ubEqSURE6NqO/ofAa2b2O8CAK4B7u7DdVmBkxHR+OK8jRYTXV7j7fmB/+HpleIRxAlDShc8VEZEYOOgRhLv/P+CLwKfAJ8Dfu/svu/DexcA4MyswszSCju7FkSuY2biIycuBD8L5uWEnN2Y2huBeFDq1VkSkG3WpqcjdV5tZOeENg8xslLtvPsg2DWZ2M/AskAw8Eb7PAqDE3RcDN5vZhUA9sBuYE25+DrDAzOqBJuAGd991GH+fiIgcJou4SDr6CsHppz8EjgW2A8cBa9395PiX13WFhYVeUqIWKBGRQ2FmK929MNqyrnRS301wF7n33b0AuAB4PYb1iYhID9SVgKh3950EZzMlufuLQNS0ERGRvqMrfRB7zCwbeAV4ysy2A/viW5aIiCRaV44gZgDVBPem/jOwAfhcPIsSEZHE6/AIwswqOXDoCwufvxNem/Atd18Wr+JERCRxOgwIdx/Y0bLwGoVTgKfCZxER6WO60sR0AHdvdPe3gZ/EuB4REekhDisgmrn7z2NViIiI9CxHFBAiItJ3KSBERCQqBYSIiESlgBARkagUECIiEpUCQkREolJAiIhIVAoIERGJSgEhIiJRxTUgzGy6ma03sw1mdmeU5TeY2btmtsrM/mpmJ0Us+0a43XozuySedYqIyIHiFhDhgH4PA5cCJwGzIwMg9Gt3P9XdJwL3Aw+F254EzAJOBqYDPwvfT0REukk8jyCmABvcvdTd64AiYGbkCu6+N2Iyi9bhxWcCRe6+390/JLgHxZQ41ioiIu105Y5yh2sEsCViugw4q/1KZnYTcDuQBpwfsW3kfa/Lwnntt50HzAMYNWpUTIoWEZFAwjup3f1hdx8LfB246xC3Xejuhe5emJubG58CRUT6qXgGxFZgZMR0fjivI0XA/z7MbUVEJMbiGRDFwDgzKzCzNIJO58WRK5jZuIjJy4EPwteLgVlmlm5mBcA44I041ioiIu3ErQ/C3RvM7GbgWSAZeMLdV5vZAqDE3RcDN5vZhUA9sBuYE2672sx+C6wBGoCb3L0xXrWKiMiBzN0PvlYvUFhY6CUlJYkuQ0SkVzGzle5eGG1ZPM9iEhGJKXenvHI/2ypqyc5IYUhmKoMzU0lJTvj5Nn2SAkJEepz6xiY+2lnNxvIqNmyvYmN5FRvL91G6vYrK/Q0HrD8wI4UhA1IZkpkWPA9IY0hmKkMHpDK4+XVWKoPD5UMHpDEoI0XBchAKCBFJmL219WzcHuz8I8Ng885qGppam7+PHpTB2LwsvnDGCMbmZnPskEyq6xrYva+OPTX17KmuZ0916+stu6rZU1NPRU09nbWiNwfL0AFpDM4MgmXogNTgyKT59YAgWIaGwXMowdLY5NQ3NlHX2ER9QxP1jcH0/oYm6htbH3UN4Xrh/LrG1nWb5wfvETEvYv38oQO45YJxBy/oECkgRCSumpqcbXtrwyAIH9v3saG8ivLK/S3rpSYbxw3P4oS8gVx6ytGMzc1mbG42Y3KzGJiRetifvbc2DJCaenZX11HRLkyaX+8+hGAZlJHCkAFpDEhLjgiAiDAId/CNTbHv401OMlKTjdTkJNKSk0hNTuLU/MEx/xxQQIhIjNTWN/LRzuqIJqHgUVq+j+q61pMQB2akcHxeNueekMvxedlhEGQxctgAUmPc5JOUZEFz04C0Q9quscmpDINldxggFc2vq4MA2V1dR01dI6kpwY46LTmJ1JS2O+7U5CTSUpJITbbwuflhpLeZTiIt3LZ5m7SIdVMjppOTLKbfUWcUECI9WGOTs3V3DaU7qtjf0ESyGclJRlKSkWxGUhIHzEtOMpLC55ZH87otryOeo7yXWcc7od376lp2/hsimoe27Kom8gfziCGZjM3L5szRwxibm90SBjnZaZ2+f0+QHBEso8lKdDkJo4AQ6QEqa+spLd9H6Y6g+aX5l/eHO/dR19DU7fWY0SZIgtABd9p0EqelJDEmJ4tTRgxm5sQRjM3NamkWGpCm3Utvp/+CIt2kqcnZuqeG0h372Li9qk0YbI9oi09OMo4bNoAxuVl8dnwuY3KzGJObTWZqMk0etGsHz0S8dhrdaWpqtzxiXsvriHkNEeu2vE/U9wyWA+QPzWzpHxgxNLNbmzykeykgRGJs3/4GPtyxr+XUzJajgR1V1Na3Hg0MykhhbF4255wQhEBzW/yoYVmkpej0S0k8BYTIYXB3tlXUUlq+r01n7MbyKrZV1Lasl2QwctgAxuRkMW3scMbmZTMmJ4uxedkMz+r5bfHSvykgRDrQ2ORU7W9g6+6aNgFQuiPKmTnpKYzJzeIzY4a3Hg3kZXPc8AGkp+hmiNI7KSCkT2pqcqrqGqisbaCytp7K2gb21tS3TO+tbbestr7NdGVtA1Xtrtg1C87MGZPbembOmNwsjs/NJndguo4GpM9RQEiP4+5U1zWyt7aevTXRduLNO/m2082v99bUU1XX0OmFThBcmDUoI5WBGSkMDJ9zcrJaXjcvO2pQBsfnZVOQk0VGqo4GpP9QQEhcuAfNMxXhVakVNfXsbfO67bL2yxsOcgVqSpK17NgHZaYwMD2VUcMGROzcI5a1C4HmnX96SpJ+9Yt0QgEhHXJ3Kvc3UFF94A482qNNANQ2dDrMQJLB4HAkzsGZqQzKTCV/aOYB81pCoN1zRqp27iLxpoAQACqq63npg3JeWPspq7bsYU+4w+/sh3xykrXZmQ8ekMao4VkMzkxps6NvWR7xyE5P0Q5epIdTQPRT7s6G7VUsW7edF9ZtZ+VHu2lscoYOSGXqmOHkZKd3vIMfEDxnpSVrJy/Shykg+pHa+kZWfLiLF9Z+ygvrt7NlVw0AJx4ziBvOHcP5E45i4sghujJWRIA4B4SZTQd+THBP6sfc/b52y28HriW473Q5cI27fxQuawTeDVfd7O4z4llrX/Xp3lpeCI8S/vrBDmrqG8lITWLa2BxuOHcs543P49ghmYkuU0R6oLgFhJklAw8DFwFlQLGZLXb3NRGrvQUUunu1md0I3A9cGS6rcfeJ8aqvr2pqct7ZWsELaz9l2brtrP54LxCcv//FySO4YMJRfGbscJ2uKSIHFc8jiCnABncvBTCzImAm0BIQ7v5ixPqvA1fHsZ4+q7K2nlc+2MEL67azfP12dlTVkWRwxqihfG36eM6fkMf4owaqv0BEDkk8A2IEsCViugw4q5P1/wX4U8R0hpmVEDQ/3efuT7ffwMzmAfMARo0adcQF9yYf7tjHsrWf8uL67bzx4S7qG51BGSmcOz6PCybkce4JuQzNOrSbpIiIROoRndRmdjVQCJwbMfs4d99qZmOAF8zsXXffGLmduy8EFgIUFhbG/t5+PUhdQxPFm3a19Cd8uGMfAOPysrnmfxVw/vg8Jh83VDdhF5GYiWdAbAVGRkznh/PaMLMLgW8B57p7y6D47r41fC41s+XAJGBj++37sh1V+3lx3XZeXL+dl9/fQdX+BtKSk5g6djhzzx7N+RPyGDlsQKLLFJE+Kp4BUQyMM7MCgmCYBVwVuYKZTQJ+Dkx39+0R84cC1e6+38xygGkEHdh9mruz+uO9vLBuO8vWbeedsj24Q97AdD5/+jGcNz6PacfnkJXeIw78RKSPi9uext0bzOxm4FmC01yfcPfVZrYAKHH3xcADQDbwu7ADtfl01hOBn5tZE5BE0AexJuoH9RHFm3Zx66K3+LiiFjM4LX8It114AudPyOPkYwepg1lEup35wYa87CUKCwu9pKQk0WUcluJNu5jzxBscNSiD//PZsXx2fB65A9MTXZaI9ANmttLdC6MtU1tFgq38aBdzn3iDowdlUDRvKnmDMhJdkogIEDTfSIKs/Gg3c54oJm9QBosUDiLSwyggEuTNzbuZ88Qb5GSnsei6qRylcBCRHkYBkQBvbd7NnMffYHh2GovmTeXowQoHEel5FBDdbNWWPfzT428wLDuNonlTOWawBsoTkZ5JndTd6O0te/jy4ysYmhU0KykcRDpWX19PWVkZtbW1iS6lT8jIyCA/P5/U1NQub6OA6CbvlO3h6sdXMGRAKovmTdUQ2yIHUVZWxsCBAxk9erSuAzpC7s7OnTspKyujoKCgy9upiakbvFtWwdWPrWBwZiqLrpvKCIWDyEHV1tYyfPhwhUMMmBnDhw8/5KMxBUScvbe1gqsfX8GgzFSK5k0lf6jGThLpKoVD7BzOd6mAiKP3tlbwj4+tIDs9hUXXKRxEpHdRQMTJ6o+DI4fs9BSK5k3VqKsivczOnTuZOHEiEydO5Oijj2bEiBEt03V1dZ1uW1JSwi233HLQzzj77LNjVW5cqJM6DtZ8vJd/fGwFA1KTWXSdwkGkNxo+fDirVq0CYP78+WRnZ3PHHXe0LG9oaCAlJfoutLCwkMLCqMMbtfHqq6/Gptg4UUDEWBAOr5OZmsyieVMZNVzhIHKkvrdkNWvC+6vHyknHDuK7nz/5kLaZO3cuGRkZvPXWW0ybNo1Zs2Zx60Z9qkkAAA1cSURBVK23UltbS2ZmJr/4xS8YP348y5cv58EHH+SPf/wj8+fPZ/PmzZSWlrJ582a+8pWvtBxdZGdnU1VVxfLly5k/fz45OTm89957TJ48mV/96leYGUuXLuX2228nKyuLadOmUVpayh//+MeYfhcdUUDE0NptQTikpyRTNG8qxw3PSnRJIhJjZWVlvPrqqyQnJ7N3715eeeUVUlJSeP755/nmN7/J73//+wO2WbduHS+++CKVlZWMHz+eG2+88YDrEd566y1Wr17Nsccey7Rp0/jb3/5GYWEh119/PS+//DIFBQXMnj27u/5MQAERM+s+CZqVFA4isXeov/Tj6Utf+hLJyckAVFRUMGfOHD744APMjPr6+qjbXH755aSnp5Oenk5eXh6ffvop+fn5bdaZMmVKy7yJEyeyadMmsrOzGTNmTMu1C7Nnz2bhwoVx/OvaUid1DKz/pJKrHl1BarKxaN5URucoHET6qqys1n/f3/72tznvvPN47733WLJkSYfXGaSnt97fJTk5mYaGhsNap7spII7Q+59WctWjr5OSZCy6bioFCgeRfqOiooIRI0YA8F//9V8xf//x48dTWlrKpk2bAPjNb34T88/oTFwDwsymm9l6M9tgZndGWX67ma0xs3fMbJmZHRexbI6ZfRA+5sSzzsP1QRgOyUnBkcOY3OxElyQi3ehrX/sa3/jGN5g0aVJcfvFnZmbys5/9jOnTpzN58mQGDhzI4MGDY/45HYnbLUfNLBl4H7gIKAOKgdmR95Y2s/OAFe5ebWY3Ap919yvNbBhQAhQCDqwEJrv77o4+r7tvObpheyWzFq7ADIrmTWWswkEkptauXcuJJ56Y6DISrqqqiuzsbNydm266iXHjxnHbbbcd1ntF+047u+VoPI8gpgAb3L3U3euAImBm5Aru/qK7V4eTrwPNvTaXAM+5+64wFJ4Dpsex1kOyYXsVsxauAGDRdQoHEYmfRx99lIkTJ3LyySdTUVHB9ddf322fHc+zmEYAWyKmy4CzOln/X4A/dbLtiPYbmNk8YB7AqFGjjqTWLttYXsXsR18HnKJ5Uzk+T+EgIvFz2223HfYRw5HqEZ3UZnY1QXPSA4eynbsvdPdCdy/Mzc2NT3ERNpZXMXvh67g7i66byvF5A+P+mSIiiRLPgNgKjIyYzg/ntWFmFwLfAma4+/5D2bY7lYbh0Njk/Pq6qYw7SuEgIn1bPAOiGBhnZgVmlgbMAhZHrmBmk4CfE4TD9ohFzwIXm9lQMxsKXBzOS4gPd+xj9qOt4XCCwkFE+oG49UG4e4OZ3UywY08GnnD31Wa2AChx98UETUrZwO/Csco3u/sMd99lZncThAzAAnffFa9aO7Npxz5mL3yd+kbn19edxfijFQ4i0j/EtQ/C3Ze6+wnuPtbd7w3nfScMB9z9Qnc/yt0nho8ZEds+4e7Hh49fxLPOjny0Mzhy2N/QyFPXnsWEowclogwRSYDzzjuPZ59t23Dxox/9iBtvvDHq+p/97GdpPtX+sssuY8+ePQesM3/+fB588MFOP/fpp59mzZqWqwH4zne+w/PPP3+o5cdEj+ik7ok276xm9sLXqa1v5Klrp3LiMQoHkf5k9uzZFBUVtZlXVFTUpQHzli5dypAhQw7rc9sHxIIFC7jwwgsP672OlAbri2LzzmpmLXyN6vpGfn3tVE46VuEgklB/uhM+eTe273n0qXDpfR0uvuKKK7jrrruoq6sjLS2NTZs28fHHH7No0SJuv/12ampquOKKK/je9753wLajR4+mpKSEnJwc7r33Xp588kny8vIYOXIkkydPBoLrGxYuXEhdXR3HH388v/zlL1m1ahWLFy/mpZde4p577uH3v/89d999N5/73Oe44oorWLZsGXfccQcNDQ2ceeaZPPLII6SnpzN69GjmzJnDkiVLqK+v53e/+x0TJkw44q9IRxDtbNlVzexHX2dfXdCspHAQ6Z+GDRvGlClT+NOfgsuzioqK+Id/+AfuvfdeSkpKeOedd3jppZd45513OnyPlStXUlRUxKpVq1i6dCnFxcUty/7+7/+e4uJi3n77bU488UQef/xxzj77bGbMmMEDDzzAqlWrGDt2bMv6tbW1zJ07l9/85je8++67NDQ08Mgjj7Qsz8nJ4c033+TGG288aDNWV+kIIsKWXdXMWvg6VfsbeOraszj52O4b80REOtHJL/14am5mmjlzJkVFRTz++OP89re/ZeHChTQ0NLBt2zbWrFnDaaedFnX7V155hS984QsMGBDcOGzGjJZuVt577z3uuusu9uzZQ1VVFZdcckmntaxfv56CggJOOOEEAObMmcPDDz/MV77yFSAIHIDJkyfzhz/84Yj/dtARRIuy3cGRQ2VtPU9dexanjFA4iPR3M2fOZNmyZbz55ptUV1czbNgwHnzwQZYtW8Y777zD5Zdf3uEQ3wczd+5cfvrTn/Luu+/y3e9+97Dfp1nzcOGxHCpcAQFs3VPD7EdfZ29NPU9dO1XhICJAcEvQ8847j2uuuYbZs2ezd+9esrKyGDx4MJ9++mlL81NHzjnnHJ5++mlqamqorKxkyZIlLcsqKys55phjqK+v56mnnmqZP3DgQCorKw94r/Hjx7Np0yY2bNgAwC9/+UvOPffcGP2l0fX7gNhWUcOsha+xp7qeX117FqfmKxxEpNXs2bN5++23mT17NqeffjqTJk1iwoQJXHXVVUybNq3Tbc844wyuvPJKTj/9dC699FLOPPPMlmV33303Z511FtOmTWvToTxr1iweeOABJk2axMaNG1vmZ2Rk8Itf/IIvfelLnHrqqSQlJXHDDTfE/g+OELfhvrvb4Q73XbW/gVsXvcUtF4zj9JGHd1qaiMSehvuOvUMd7rvfd1Jnp6fw+NwzD76iiEg/0++bmEREJDoFhIj0WH2lCbwnOJzvUgEhIj1SRkYGO3fuVEjEgLuzc+dOMjIyDmm7ft8HISI9U35+PmVlZZSXlye6lD4hIyOD/Pz8g68YQQEhIj1SamoqBQUFiS6jX1MTk4iIRKWAEBGRqBQQIiISVZ+5ktrMyoGPjuAtcoAdMSqnt9N30Za+j7b0fbTqC9/Fce6eG21BnwmII2VmJR1dbt7f6LtoS99HW/o+WvX170JNTCIiEpUCQkREolJAtFqY6AJ6EH0Xben7aEvfR6s+/V2oD0JERKLSEYSIiESlgBARkaj6fUCY2XQzW29mG8zszkTXk0hmNtLMXjSzNWa22sxuTXRNiWZmyWb2lpn9MdG1JJqZDTGz/zazdWa21sw+k+iaEsnMbgv/nbxnZovM7NCGSu0F+nVAmFky8DBwKXASMNvMTkpsVQnVAHzV3U8CpgI39fPvA+BWYG2ii+ghfgz82d0nAKfTj78XMxsB3AIUuvspQDIwK7FVxV6/DghgCrDB3UvdvQ4oAmYmuKaEcfdt7v5m+LqSYAcwIrFVJY6Z5QOXA48lupZEM7PBwDnA4wDuXufuexJbVcKlAJlmlgIMAD5OcD0x198DYgSwJWK6jH68Q4xkZqOBScCKxFaSUD8CvgY0JbqQHqAAKAd+ETa5PWZmWYkuKlHcfSvwILAZ2AZUuPtfEltV7PX3gJAozCwb+D3wFXffm+h6EsHMPgdsd/eVia6lh0gBzgAecfdJwD6g3/bZmdlQgtaGAuBYIMvMrk5sVbHX3wNiKzAyYjo/nNdvmVkqQTg85e5/SHQ9CTQNmGFmmwiaHs83s18ltqSEKgPK3L35iPK/CQKjv7oQ+NDdy929HvgDcHaCa4q5/h4QxcA4MyswszSCTqbFCa4pYczMCNqY17r7Q4muJ5Hc/Rvunu/uown+v3jB3fvcL8SucvdPgC1mNj6cdQGwJoElJdpmYKqZDQj/3VxAH+y079e3HHX3BjO7GXiW4CyEJ9x9dYLLSqRpwJeBd81sVTjvm+6+NIE1Sc/xr8BT4Y+pUuCfE1xPwrj7CjP7b+BNgrP/3qIPDruhoTZERCSq/t7EJCIiHVBAiIhIVAoIERGJSgEhIiJRKSBERCQqBYTIITCzRjNbFfGI2dXEZjbazN6L1fuJHKl+fR2EyGGocfeJiS5CpDvoCEIkBsxsk5ndb2bvmtkbZnZ8OH+0mb1gZu+Y2TIzGxXOP8rM/sfM3g4fzcM0JJvZo+F9Bv5iZpkJ+6Ok31NAiByazHZNTFdGLKtw91OBnxKMBAvwE+BJdz8NeAr4j3D+fwAvufvpBGMaNV/BPw542N1PBvYAX4zz3yPSIV1JLXIIzKzK3bOjzN8EnO/upeGAh5+4+3Az2wEc4+714fxt7p5jZuVAvrvvj3iP0cBz7j4unP46kOru98T/LxM5kI4gRGLHO3h9KPZHvG5E/YSSQAoIkdi5MuL5tfD1q7TeivIfgVfC18uAG6HlvteDu6tIka7SrxORQ5MZMdItBPdobj7VdaiZvUNwFDA7nPevBHdh+zeCO7I1j4B6K7DQzP6F4EjhRoI7k4n0GOqDEImBsA+i0N13JLoWkVhRE5OIiESlIwgREYlKRxAiIhKVAkJERKJSQIiISFQKCBERiUoBISIiUf3//HTDL9FtyO0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtOPAqB1GkB5",
        "colab_type": "text"
      },
      "source": [
        "# Assess model performance on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TxQGreq6Vgm",
        "colab_type": "code",
        "outputId": "283aac00-a9e8-4111-c9f1-2ae984a5999e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "if (args['use_glove']):\n",
        "  model.load_state_dict(torch.load('glove-lstm-model.pt'))\n",
        "else:\n",
        "  model.load_state_dict(torch.load('bert-lstm-model.pt'))\n",
        "\n",
        "\n",
        "test_loss, test_metrics, preds_list, labels_list = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "test_jaccard = test_metrics['jaccard']\n",
        "test_micro = test_metrics['f1_micro']\n",
        "test_macro = test_metrics['f1_macro']\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Jaccard: {test_jaccard*100:.2f}% | Test F1 Micro: {test_micro*100:.2f}% | Test F1 Macro: {test_macro*100:.2f}%')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.352 | Test Jaccard: 55.00% | Test F1 Micro: 67.23% | Test F1 Macro: 50.44%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJd_FzO4o_AK",
        "colab_type": "text"
      },
      "source": [
        "# Confusion matrix & Classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXLsnO9-kFcf",
        "colab_type": "code",
        "outputId": "4293dc97-8cc7-450a-fb03-ad06d22fd221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
        "\n",
        "conf_matrix = multilabel_confusion_matrix(np.vstack(labels_list), np.vstack(preds_list).round())\n",
        "print(conf_matrix)\n",
        "\n",
        "cm = classification_report(np.vstack(labels_list), np.vstack(preds_list).round())\n",
        "print(cm)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1849  309]\n",
            "  [ 240  861]]\n",
            "\n",
            " [[2769   65]\n",
            "  [ 373   52]]\n",
            "\n",
            " [[1830  330]\n",
            "  [ 263  836]]\n",
            "\n",
            " [[2718   56]\n",
            "  [ 213  272]]\n",
            "\n",
            " [[1699  118]\n",
            "  [ 388 1054]]\n",
            "\n",
            " [[2685   58]\n",
            "  [ 328  188]]\n",
            "\n",
            " [[1802  314]\n",
            "  [ 319  824]]\n",
            "\n",
            " [[2742  142]\n",
            "  [ 270  105]]\n",
            "\n",
            " [[2024  275]\n",
            "  [ 328  632]]\n",
            "\n",
            " [[3079   10]\n",
            "  [ 160   10]]\n",
            "\n",
            " [[3097    9]\n",
            "  [ 149    4]]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.78      0.76      1101\n",
            "           1       0.44      0.12      0.19       425\n",
            "           2       0.72      0.76      0.74      1099\n",
            "           3       0.83      0.56      0.67       485\n",
            "           4       0.90      0.73      0.81      1442\n",
            "           5       0.76      0.36      0.49       516\n",
            "           6       0.72      0.72      0.72      1143\n",
            "           7       0.43      0.28      0.34       375\n",
            "           8       0.70      0.66      0.68       960\n",
            "           9       0.50      0.06      0.11       170\n",
            "          10       0.31      0.03      0.05       153\n",
            "\n",
            "   micro avg       0.74      0.61      0.67      7869\n",
            "   macro avg       0.64      0.46      0.50      7869\n",
            "weighted avg       0.72      0.61      0.65      7869\n",
            " samples avg       0.72      0.63      0.64      7869\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaJzLdwb6exr",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ6W1Xpq6aO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_emotion(model, tokenizer, tweet):\n",
        "  preds = []\n",
        "  model.eval()\n",
        "\n",
        "  if args['use_glove']:\n",
        "    tokenized = preprocessor(tweet)\n",
        "    indexed = [TEXT.vocab.stoi[token] for token in tokenized]\n",
        "  else:\n",
        "    tokens = tokenizer.tokenize(tweet)\n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    indexed = [tokenizer.cls_token_id] + tokenizer.convert_tokens_to_ids(tokens) + [tokenizer.sep_token_id]\n",
        "\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  predictions, attn_weights = model(tensor)\n",
        "  preds.append(torch.sigmoid(predictions).detach().cpu().numpy())\n",
        "\n",
        "  if args['use_glove']:\n",
        "    return preds, attn_weights, tokenized\n",
        "  else:\n",
        "    return preds, attn_weights, tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL9EtxTrG7My",
        "colab_type": "text"
      },
      "source": [
        "Lets test the model on our own input and save the attention weights and tokens for visualization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eecw3IVA6lVH",
        "colab_type": "code",
        "outputId": "a31697ae-0900-4e8a-e8a9-4967bcfa7aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "text = \"Good music I love that shit\"\n",
        "\n",
        "preds, attn_weights, tokens = predict_emotion(model, tokenizer, text)\n",
        "\n",
        "pred_values = []\n",
        "for p in preds[0]:\n",
        "  for val in p:\n",
        "    pred_values.append(val)\n",
        "\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "  print(f\"{label.upper()}: {pred_values[i]}\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANGER: 0.07508084923028946\n",
            "ANTICIPATION: 0.14726099371910095\n",
            "DISGUST: 0.07473274320363998\n",
            "FEAR: 0.04828784614801407\n",
            "JOY: 0.9298954010009766\n",
            "LOVE: 0.7744816541671753\n",
            "OPTIMISM: 0.6959763169288635\n",
            "PESSIMISM: 0.06433374434709549\n",
            "SADNESS: 0.122174933552742\n",
            "SURPRISE: 0.12550944089889526\n",
            "TRUST: 0.2653818428516388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jeDWh8KHbEG",
        "colab_type": "text"
      },
      "source": [
        "Here we format the attention weights and store the results in a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q71LaaAn6oBA",
        "colab_type": "code",
        "outputId": "779ca6fd-c251-45e1-fd26-3f6a4e36bb97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "attention_weights = []\n",
        "for aw in attn_weights[0]:\n",
        "  for v in aw:\n",
        "    attention_weights.append(v.detach().cpu().numpy())\n",
        "\n",
        "if args['use_glove']:\n",
        "  attention_weights = np.array(attention_weights)\n",
        "else:\n",
        "  attention_weights = attention_weights[1:-1]\n",
        "  attention_weights = np.array(attention_weights)\n",
        "\n",
        "attention_weights"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.08046062, 0.01786843, 0.0171315 , 0.8347988 , 0.01137709,\n",
              "       0.03428334], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnrDFOGy9DLx",
        "colab_type": "code",
        "outputId": "ee464c8f-7940-4bf2-c17a-0c831d9bad54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attn_dict = {}\n",
        "for i in range(len(attention_weights)):\n",
        "  attn_dict[tokens[i]] = attention_weights[i]\n",
        "\n",
        "print(attn_dict)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'good': 0.080460615, 'music': 0.017868433, 'i': 0.0171315, 'love': 0.8347988, 'that': 0.011377086, 'shit': 0.034283344}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tomju0TvHp8z",
        "colab_type": "text"
      },
      "source": [
        "Lets return the top 3 words that the model focused on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skdcPb0g-nQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LqBqNKVCqan",
        "colab_type": "code",
        "outputId": "386e80aa-caeb-4c33-fce6-5a322e417d03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weight_counter = Counter(attn_dict)\n",
        "print(weight_counter)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'love': 0.8347988, 'good': 0.080460615, 'shit': 0.034283344, 'music': 0.017868433, 'i': 0.0171315, 'that': 0.011377086})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOynkS19gB9l",
        "colab_type": "text"
      },
      "source": [
        "# Model performance on longer text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaT0o3fUhjzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVRBt8P0H4Ur",
        "colab_type": "code",
        "outputId": "369bea8e-03b1-47c5-9d10-2d15c97ab521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "text_1 = (\n",
        "    \"I'm only 24, and have worked part time jobs since I graduated from college.\" \n",
        "    \" With everything going on, I've been furloughed from both of my part time jobs.\"\n",
        "    \" Well one offered me full time, and I was able to negotiate the salary up a full dollar per hour! And it has benefits and everything!\" \n",
        "    \" I know it's not a big deal but I'm just so excited and can't really tell anyone\"\n",
        "    \" especially as I haven't spoken to my other part time job yet. Just hoping everything works out well, and that I have money for grad school in the fall!\"\n",
        ")\n",
        "\n",
        "text_2 = (\n",
        "    \"I worked my ass off to graduate with my Bachelor's in 3 years.\"\n",
        "    \"My family hasn't said a word to me about it. No 'Congrats'! or 'I'm proud of you!'.\"\n",
        "    \"And it's not like they don't know. I live with them. I got my cap & gown in the mail last week and one my\"\n",
        "    \" professors snet me a graduation card. They were there for all of it. Still, not a single word about it.\"\n",
        "    \" I know this is a weird time, but I don't think that's an excuse to ignore your daughter's life achievements.\"\n",
        "    \" I feel so under-appreciated. I just want them to tell me they're proud. What kind of parent doesn't do that?\"\n",
        "    \" I'm 20 years old with a Bachelor of Science in Information Technology. I deserve a pat on the back.\"\n",
        "    \" This really sucks.\"\n",
        ")\n",
        "\n",
        "preds, attn_weights, tokens = predict_emotion(model, tokenizer, text_2)\n",
        "\n",
        "pred_values = []\n",
        "for p in preds[0]:\n",
        "  for val in p:\n",
        "    pred_values.append(val)\n",
        "\n",
        "# print(os.linesep.join([\"I'm only 24, and have worked part time jobs since I graduated from college.\", \n",
        "#                        \"With everything going on, I've been furloughed from both of my part time jobs.\",\n",
        "#                        \"Well one offered me full time, and I was able to negotiate the salary up a full dollar per hour!\", \n",
        "#                        \"And it has benefits and everything! I know it's not a big deal but I'm just so excited and\", \n",
        "#                        \"can't really tell anyone, especially as I haven't spoken to my other part time job yet.\", \n",
        "#                        \"Just hoping everything works out well, and that I have money for grad school in the fall!\"]))\n",
        "\n",
        "print(os.linesep.join([\"I worked my ass off to graduate with my Bachelor's in 3 years.\", \n",
        "                      \"My family hasn't said a word to me about it. No 'Congrats'! or 'I'm proud of you!'.\",\n",
        "                      \"And it's not like they don't know. I live with them. I got my cap & gown in the mail last week and one my\",\n",
        "                      \"professors snet me a graduation card. They were there for all of it. Still, not a single word about it.\",\n",
        "                      \"I know this is a weird time, but I don't think that's an excuse to ignore your daughter's life achievements.\",\n",
        "                      \"I feel so under-appreciated. I just want them to tell me they're proud. What kind of parent doesn't do that?\",\n",
        "                      \"I'm 20 years old with a Bachelor of Science in Information Technology. I deserve a pat on the back.\",\n",
        "                      \"This really sucks.\"]))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Text length: 138 words\")\n",
        "\n",
        "print()\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "  print(f\"{label.upper()}: {pred_values[i]:.2f}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I worked my ass off to graduate with my Bachelor's in 3 years.\n",
            "My family hasn't said a word to me about it. No 'Congrats'! or 'I'm proud of you!'.\n",
            "And it's not like they don't know. I live with them. I got my cap & gown in the mail last week and one my\n",
            "professors snet me a graduation card. They were there for all of it. Still, not a single word about it.\n",
            "I know this is a weird time, but I don't think that's an excuse to ignore your daughter's life achievements.\n",
            "I feel so under-appreciated. I just want them to tell me they're proud. What kind of parent doesn't do that?\n",
            "I'm 20 years old with a Bachelor of Science in Information Technology. I deserve a pat on the back.\n",
            "This really sucks.\n",
            "\n",
            "Text length: 138 words\n",
            "\n",
            "ANGER: 0.35\n",
            "ANTICIPATION: 0.18\n",
            "DISGUST: 0.37\n",
            "FEAR: 0.20\n",
            "JOY: 0.34\n",
            "LOVE: 0.12\n",
            "OPTIMISM: 0.36\n",
            "PESSIMISM: 0.36\n",
            "SADNESS: 0.63\n",
            "SURPRISE: 0.09\n",
            "TRUST: 0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ2uiaY8b0qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}