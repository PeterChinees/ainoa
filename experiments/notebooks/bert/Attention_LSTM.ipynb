{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMUGooHIwHSXjdJUSW+1+H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/Attention_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWaTkjkKu9TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy40NOL-vFij",
        "colab_type": "code",
        "outputId": "fa846e84-c338-412b-de8a-4669eff7cb12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLFhbGO8C4gJ",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xU5Pc6mvbY0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "15f96af6-2d57-4fba-dbe5-788352a62b8a"
      },
      "source": [
        "import pickle\n",
        "import torch\n",
        "import random\n",
        "import transformers\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from pathlib import Path\n",
        "from torchtext import data\n",
        "from transformers import BertTokenizer, BertModel"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZYWV6HMDEm6",
        "colab_type": "text"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FczMGWp1vM_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    \"bert_tokenizer\": \"bert-base-uncased\",\n",
        "    \"bert_pretrained_model\": \"bert-base-uncased\",\n",
        "    \"seed\": 1234,\n",
        "    \"batch_size\": 64,\n",
        "    \"num_filters\": 100,\n",
        "    \"filter_sizes\": [3,4,5],\n",
        "    \"output_dim\": 11,\n",
        "    \"hidden_size\": 768,\n",
        "    \"num_layers\": 2,\n",
        "    \"dropout\": 0.5,\n",
        "    \"fc_dropout\": 0.5,\n",
        "    \"embed_dropout\": 0.2,\n",
        "    \"epochs\": 10\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QizRI-q1DPf1",
        "colab_type": "text"
      },
      "source": [
        "# Setup Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4nYNxu4vV9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(args['bert_tokenizer'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqDxLYBQvYc-",
        "colab_type": "code",
        "outputId": "48c2ad59-f101-4426-b441-2167d5fb8c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDPOUfFuvjvy",
        "colab_type": "code",
        "outputId": "4ed24fac-8963-42e3-a346-791bdc1e95f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBv0eC2xvss-",
        "colab_type": "code",
        "outputId": "7caeb55f-f9c4-479e-ae50-d2c4c88ebc37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes[args['bert_tokenizer']]\n",
        "\n",
        "print(max_input_length)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMBjmcymvlY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_and_cut(tweet):\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFFnMbqQDbJC",
        "colab_type": "text"
      },
      "source": [
        "# Load and Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYj3qsDpvmwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive'\n",
        "\n",
        "DATA_PATH = Path(file_path + '/datasets/SemEval')\n",
        "\n",
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = tokenize_and_cut,\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "LABEL = data.LabelField(sequential = False,\n",
        "                        use_vocab = False,\n",
        "                        pad_token= None,\n",
        "                        unk_token = None, \n",
        "                        dtype = torch.float)\n",
        "\n",
        "dataFields = {\"Tweet\": (\"Tweet\", TEXT),\n",
        "              'anger': (\"anger\", LABEL),\n",
        "              'anticipation': (\"anticipation\", LABEL),\n",
        "              'disgust': (\"disgust\", LABEL),\n",
        "              'fear': (\"fear\", LABEL),\n",
        "              'joy': (\"joy\", LABEL),\n",
        "              'love': (\"love\", LABEL),\n",
        "              'optimism': (\"optimism\", LABEL),\n",
        "              'pessimism': (\"pessimism\", LABEL),\n",
        "              'sadness': (\"sadness\", LABEL),\n",
        "              'surprise': (\"surprise\", LABEL),\n",
        "              'trust': (\"trust\", LABEL)}\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path = DATA_PATH,\n",
        "    train = 'train.csv',\n",
        "    validation = 'val.csv',\n",
        "    test = 'test.csv',\n",
        "    format = 'csv',\n",
        "    fields = dataFields\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYMezWxUvyxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    sort_key = lambda x: len(x.Tweet),\n",
        "    sort_within_batch = True,\n",
        "    batch_size = args['batch_size'],\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dgYzwnpDhrO",
        "colab_type": "text"
      },
      "source": [
        "# Batch Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZCExSovoy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLS = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
        "              'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "iaux = 0\n",
        "\n",
        "for batch in valid_iterator:\n",
        "  iaux += 1\n",
        "  aux = batch\n",
        "  aux2 = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "  if aux == 20: break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyMA1ST4DlLN",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77GLQlKxDnAx",
        "colab_type": "text"
      },
      "source": [
        "Load the pretrained bert model from the HuggingFace transformers library.\n",
        "\n",
        "https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRiJ1llOvvxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = BertModel.from_pretrained(args['bert_pretrained_model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD1MiUiwv29n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(Attention, self).__init__()\n",
        "    self.attention = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.tanh(x)\n",
        "    x = self.attention(x).squeeze(2)\n",
        "    alpha = F.softmax(x, dim=1).unsqueeze(1)\n",
        "    return alpha\n",
        "\n",
        "class AttentionBiLSTM(nn.Module):\n",
        "  def __init__(self, bert, hidden_size, num_layers, dropout, fc_dropout, \n",
        "               embed_dropout, num_classes):\n",
        "    super(AttentionBiLSTM, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size \n",
        "    self.bert = bert \n",
        "    embedding_dim = 768 \n",
        "\n",
        "    self.embed_dropout = nn.Dropout(embed_dropout)\n",
        "\n",
        "    self.bilstm = nn.LSTM(embedding_dim, \n",
        "                          hidden_size, \n",
        "                          num_layers, \n",
        "                          dropout=(0 if num_layers==1 else dropout),\n",
        "                          bidirectional=True,\n",
        "                          batch_first=True)\n",
        "    \n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    self.fc_dropout = nn.Dropout(fc_dropout)\n",
        "    \n",
        "    self.attention = Attention(hidden_size)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    with torch.no_grad():\n",
        "      x = self.bert(text)[0]\n",
        "    \n",
        "    x = self.embed_dropout(x)\n",
        "    y, _ = self.bilstm(x)\n",
        "    y = y[:,:,:self.hidden_size] + y[:,:,self.hidden_size:]\n",
        "    alpha = self.attention(y)\n",
        "    r = alpha.bmm(y).squeeze(1)\n",
        "    h = torch.tanh(r)\n",
        "    logits = self.fc(h)\n",
        "    logits = self.fc_dropout(logits)\n",
        "    return logits, alpha "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukvWtx9gxE1d",
        "colab_type": "code",
        "outputId": "710396b7-5383-4ffb-d396-5448d32b1db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = AttentionBiLSTM(\n",
        "    bert=bert,\n",
        "    hidden_size=args['hidden_size'],\n",
        "    num_layers=args['num_layers'],\n",
        "    dropout=args['dropout'],\n",
        "    fc_dropout=args['fc_dropout'],\n",
        "    embed_dropout=args['embed_dropout'],\n",
        "    num_classes=args['output_dim'],\n",
        ")\n",
        "\n",
        "model"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttentionBiLSTM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (embed_dropout): Dropout(p=0.2, inplace=False)\n",
              "  (bilstm): LSTM(768, 768, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "  (fc): Linear(in_features=768, out_features=11, bias=True)\n",
              "  (fc_dropout): Dropout(p=0.5, inplace=False)\n",
              "  (attention): Attention(\n",
              "    (attention): Linear(in_features=768, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HIm_dK8EbZ2",
        "colab_type": "text"
      },
      "source": [
        "Freeze the parameters which are a part of the Bert Transformers model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4i0FWYtxQ0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC9ZocNzEoDZ",
        "colab_type": "text"
      },
      "source": [
        "Show the trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1af7wW5xYk_",
        "colab_type": "code",
        "outputId": "6537e188-8238-4313-8117-04a1bfb84f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bilstm.weight_ih_l0\n",
            "bilstm.weight_hh_l0\n",
            "bilstm.bias_ih_l0\n",
            "bilstm.bias_hh_l0\n",
            "bilstm.weight_ih_l0_reverse\n",
            "bilstm.weight_hh_l0_reverse\n",
            "bilstm.bias_ih_l0_reverse\n",
            "bilstm.bias_hh_l0_reverse\n",
            "bilstm.weight_ih_l1\n",
            "bilstm.weight_hh_l1\n",
            "bilstm.bias_ih_l1\n",
            "bilstm.bias_hh_l1\n",
            "bilstm.weight_ih_l1_reverse\n",
            "bilstm.weight_hh_l1_reverse\n",
            "bilstm.bias_ih_l1_reverse\n",
            "bilstm.bias_hh_l1_reverse\n",
            "fc.weight\n",
            "fc.bias\n",
            "attention.attention.weight\n",
            "attention.attention.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLuzW7f4EyrX",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1CpxbIDxcb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwZIAAQmxfxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amV2jA0oE2Rx",
        "colab_type": "text"
      },
      "source": [
        "We evaluate using the ROC AUC score and the macro and micro F1's as there are more suitable for multi-label text classification problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxF1sRahxmwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YydgwAqkxolz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metricize(preds, y):\n",
        "  f1_macro = f1_score(y, preds.round(), average='macro')\n",
        "  f1_micro = f1_score(y, preds.round(), average='micro')\n",
        "  acc = roc_auc_score(y, preds)\n",
        "\n",
        "  return {\n",
        "      'f1_macro': f1_macro,\n",
        "      'f1_micro': f1_micro,\n",
        "      'acc': acc\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLL3mSPZxpkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions, _ = model(batch.Tweet)\n",
        "\n",
        "    batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "    batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "    loss = criterion(predictions, batch_labels)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "    labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  \n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoLaQBVvxrla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "      predictions, _ = model(batch.Tweet)\n",
        "\n",
        "      batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "      batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "      loss = criterion(predictions, batch_labels)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "      labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO9vUx_1xtXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqaePMLEFP7e",
        "colab_type": "text"
      },
      "source": [
        "We train the model for 10 epochs and record the training and validation loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSBSFoBOxwJn",
        "colab_type": "code",
        "outputId": "b3e37c6e-75f8-494b-e724-44e67d294687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_history = []\n",
        "valid_history = []\n",
        "\n",
        "for epoch in range(args['epochs']):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_metrics = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_metrics = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    train_history.append(train_loss)\n",
        "    valid_history.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'bert-lstm-model.pt')\n",
        "\n",
        "    train_acc = train_metrics['acc']\n",
        "    train_micro = train_metrics['f1_micro']\n",
        "    train_macro = train_metrics['f1_macro']\n",
        "\n",
        "    valid_acc = valid_metrics['acc']\n",
        "    valid_micro = valid_metrics['f1_micro']\n",
        "    valid_macro = valid_metrics['f1_macro']\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train F1 Micro: {train_micro*100:.2f}% | Train F1 Macro: {train_macro*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%  | Val. F1 Micro: {valid_micro*100:.2f}%  | Val. F1 Macro: {valid_macro*100:.2f}%')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 23s\n",
            "\tTrain Loss: 0.552 | Train Acc: 59.65% | Train F1 Micro: 28.75% | Train F1 Macro: 17.96%\n",
            "\t Val. Loss: 0.428 | Val. Acc: 79.55%  | Val. F1 Micro: 57.64%  | Val. F1 Macro: 36.05%\n",
            "Epoch: 02 | Epoch Time: 0m 23s\n",
            "\tTrain Loss: 0.525 | Train Acc: 64.17% | Train F1 Micro: 35.12% | Train F1 Macro: 23.31%\n",
            "\t Val. Loss: 0.391 | Val. Acc: 83.21%  | Val. F1 Micro: 61.74%  | Val. F1 Macro: 40.25%\n",
            "Epoch: 03 | Epoch Time: 0m 24s\n",
            "\tTrain Loss: 0.513 | Train Acc: 65.92% | Train F1 Micro: 38.23% | Train F1 Macro: 26.83%\n",
            "\t Val. Loss: 0.377 | Val. Acc: 84.64%  | Val. F1 Micro: 62.72%  | Val. F1 Macro: 41.63%\n",
            "Epoch: 04 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 0.503 | Train Acc: 67.45% | Train F1 Micro: 40.04% | Train F1 Macro: 28.74%\n",
            "\t Val. Loss: 0.377 | Val. Acc: 85.60%  | Val. F1 Micro: 64.05%  | Val. F1 Macro: 45.77%\n",
            "Epoch: 05 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 0.502 | Train Acc: 67.32% | Train F1 Micro: 40.32% | Train F1 Macro: 29.19%\n",
            "\t Val. Loss: 0.373 | Val. Acc: 85.72%  | Val. F1 Micro: 66.49%  | Val. F1 Macro: 53.06%\n",
            "Epoch: 06 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 0.496 | Train Acc: 68.60% | Train F1 Micro: 42.25% | Train F1 Macro: 31.30%\n",
            "\t Val. Loss: 0.368 | Val. Acc: 86.11%  | Val. F1 Micro: 66.16%  | Val. F1 Macro: 50.14%\n",
            "Epoch: 07 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 0.491 | Train Acc: 69.36% | Train F1 Micro: 42.37% | Train F1 Macro: 32.51%\n",
            "\t Val. Loss: 0.344 | Val. Acc: 85.54%  | Val. F1 Micro: 67.22%  | Val. F1 Macro: 49.38%\n",
            "Epoch: 08 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 0.487 | Train Acc: 69.94% | Train F1 Micro: 43.75% | Train F1 Macro: 33.66%\n",
            "\t Val. Loss: 0.355 | Val. Acc: 85.63%  | Val. F1 Micro: 66.35%  | Val. F1 Macro: 48.64%\n",
            "Epoch: 09 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 0.486 | Train Acc: 70.00% | Train F1 Micro: 44.03% | Train F1 Macro: 34.08%\n",
            "\t Val. Loss: 0.343 | Val. Acc: 85.63%  | Val. F1 Micro: 67.66%  | Val. F1 Macro: 48.62%\n",
            "Epoch: 10 | Epoch Time: 0m 25s\n",
            "\tTrain Loss: 0.479 | Train Acc: 71.02% | Train F1 Micro: 45.62% | Train F1 Macro: 36.01%\n",
            "\t Val. Loss: 0.335 | Val. Acc: 85.55%  | Val. F1 Micro: 67.44%  | Val. F1 Macro: 50.99%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqXexw71GcWj",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the training and validation loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CePfv7_0An7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgUKd4HR6Tg-",
        "colab_type": "code",
        "outputId": "71372a14-d166-4e3d-b689-877be5719c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plt.plot(train_history)\n",
        "plt.plot(valid_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training', 'Validation'])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7feffe3c6128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7xTMw80AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtOPAqB1GkB5",
        "colab_type": "text"
      },
      "source": [
        "# Assess model performance on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TxQGreq6Vgm",
        "colab_type": "code",
        "outputId": "e8797944-a6c6-4820-ea54-2d9d3119125c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_state_dict(torch.load('bert-lstm-model.pt'))\n",
        "\n",
        "test_loss, test_metrics = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "test_acc = test_metrics['acc']\n",
        "test_micro = test_metrics['f1_micro']\n",
        "test_macro = test_metrics['f1_macro']\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test F1 Micro: {test_micro*100:.2f}% | Test F1 Macro: {test_macro*100:.2f}%')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.332 | Test Acc: 85.21% | Test F1 Micro: 66.98% | Test F1 Macro: 50.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaJzLdwb6exr",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ6W1Xpq6aO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_emotion(model, tokenizer, tweet):\n",
        "  preds = []\n",
        "  model.eval()\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  predictions, attn_weights = model(tensor)\n",
        "  preds.append(torch.sigmoid(predictions).detach().cpu().numpy())\n",
        "  return preds, attn_weights, tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL9EtxTrG7My",
        "colab_type": "text"
      },
      "source": [
        "Lets test the model on our own input and save the attention weights and tokens for visualization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eecw3IVA6lVH",
        "colab_type": "code",
        "outputId": "75f0149c-e542-4638-b01b-50279026d3ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "preds, attn_weights, tokens = predict_emotion(model, tokenizer, \n",
        "                                              \"The weather is terrible. Don't want to go outside.\")\n",
        "\n",
        "vals = []\n",
        "for p in preds[0]:\n",
        "  for val in p:\n",
        "    vals.append(val)\n",
        "\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "  print(f\"{label.upper()}: {vals[i]}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANGER: 0.6881057620048523\n",
            "ANTICIPATION: 0.13292667269706726\n",
            "DISGUST: 0.70475172996521\n",
            "FEAR: 0.5581449866294861\n",
            "JOY: 0.09647569805383682\n",
            "LOVE: 0.013459617272019386\n",
            "OPTIMISM: 0.057279784232378006\n",
            "PESSIMISM: 0.2845700979232788\n",
            "SADNESS: 0.49665510654449463\n",
            "SURPRISE: 0.06954976171255112\n",
            "TRUST: 0.02041611075401306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jeDWh8KHbEG",
        "colab_type": "text"
      },
      "source": [
        "Here we format the attention weights and store the results in a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q71LaaAn6oBA",
        "colab_type": "code",
        "outputId": "e7c116b0-cb3e-40ab-c680-b2e437d72f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "aws = []\n",
        "for a in attn_weights[0]:\n",
        "  for v in a:\n",
        "    aws.append(v.detach().cpu().numpy())\n",
        "\n",
        "aws = aws[1:-1]\n",
        "aws = np.array(aws)\n",
        "aws"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02904936, 0.07804573, 0.06550483, 0.58509994, 0.02229595,\n",
              "       0.03152235, 0.01299136, 0.04167384, 0.06092928, 0.02623484,\n",
              "       0.01729294, 0.00930353, 0.00625498], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnrDFOGy9DLx",
        "colab_type": "code",
        "outputId": "601dbb45-64f8-4497-fd41-d5c608bdb4c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "attn_dict = {}\n",
        "for i in range(len(aws)):\n",
        "  attn_dict[tokens[i]] = aws[i]\n",
        "\n",
        "print(attn_dict)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'the': 0.029049356, 'weather': 0.07804573, 'is': 0.06550483, 'terrible': 0.58509994, '.': 0.0062549757, 'don': 0.031522352, \"'\": 0.012991358, 't': 0.04167384, 'want': 0.060929283, 'to': 0.026234843, 'go': 0.01729294, 'outside': 0.009303529}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tomju0TvHp8z",
        "colab_type": "text"
      },
      "source": [
        "Lets return the top 3 words that the model focused on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skdcPb0g-nQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LqBqNKVCqan",
        "colab_type": "code",
        "outputId": "91a7ce56-a79c-46c0-9824-23780ab6b586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Counter(my_dict).most_common(3)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('terrible', 0.58509994), ('weather', 0.07804573), ('is', 0.06550483)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}