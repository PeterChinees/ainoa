{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT TextCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGWZtT/S9e4q5jWPpjdOZa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da7c6280203a455b857d6f14751a3029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_39fc9e35a01e480589a104c62cfaadab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5dbdc7800f024e00a02c081178a384aa",
              "IPY_MODEL_33112ea1557c4cffa0a2a6b3eb87794e"
            ]
          }
        },
        "39fc9e35a01e480589a104c62cfaadab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5dbdc7800f024e00a02c081178a384aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3025c149fb6b45b9b9bd26982d400070",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24bc1c7a967042cc96e3c77442455d4f"
          }
        },
        "33112ea1557c4cffa0a2a6b3eb87794e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dcb3665cb0d2420ebd49bfd169b92111",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 1.22MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9cf107904d3347a7980dd5fc017853dc"
          }
        },
        "3025c149fb6b45b9b9bd26982d400070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24bc1c7a967042cc96e3c77442455d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcb3665cb0d2420ebd49bfd169b92111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9cf107904d3347a7980dd5fc017853dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/BERT_TextCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owG-IxGmt6PT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjzXVnDxtlRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms-rycQV38iF",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N2UGYjytpuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import transformers\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from pathlib import Path\n",
        "from torchtext import data\n",
        "from transformers import BertModel, BertTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3-e1jPqoJnc",
        "colab_type": "text"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0j_RCS0oLhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    \"bert_model\": \"bert-base-uncased\",\n",
        "    \"seed\": 1234,\n",
        "    \"batch_size\": 64,\n",
        "    \"num_filters\": 100,\n",
        "    \"filter_sizes\": [3,4,5],\n",
        "    \"output_dim\": 11,\n",
        "    \"dropout\": 0.5,\n",
        "    \"epochs\": 10\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTPBR-lIovsI",
        "colab_type": "text"
      },
      "source": [
        "# Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRR5RJneu1sh",
        "colab_type": "code",
        "outputId": "be4d3938-6176-41a3-c77f-7e3a1f4e0fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "da7c6280203a455b857d6f14751a3029",
            "39fc9e35a01e480589a104c62cfaadab",
            "5dbdc7800f024e00a02c081178a384aa",
            "33112ea1557c4cffa0a2a6b3eb87794e",
            "3025c149fb6b45b9b9bd26982d400070",
            "24bc1c7a967042cc96e3c77442455d4f",
            "dcb3665cb0d2420ebd49bfd169b92111",
            "9cf107904d3347a7980dd5fc017853dc"
          ]
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(args['bert_model'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da7c6280203a455b857d6f14751a3029",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeyvkR7XAqH4",
        "colab_type": "code",
        "outputId": "10405068-7dfe-4369-bb46-843269fcfe26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEEo_OG7v4IN",
        "colab_type": "code",
        "outputId": "25e87bb7-2cf7-450e-9362-f08e424498cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yUzVdafvcpC",
        "colab_type": "code",
        "outputId": "cba782e9-3aa5-42d6-de88-e8138aa1cfa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes[args['bert_model']]\n",
        "\n",
        "print(max_input_length)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFcQHuR1Rhe9",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jx93Gzou92U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_and_cut(tweet):\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdXOgr6bo_si",
        "colab_type": "text"
      },
      "source": [
        "# Load & Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwTeWoXTukDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive'\n",
        "\n",
        "DATA_PATH = Path(file_path + '/datasets/SemEval')\n",
        "\n",
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = tokenize_and_cut,\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "LABEL = data.LabelField(sequential = False,\n",
        "                        use_vocab = False,\n",
        "                        pad_token= None,\n",
        "                        unk_token = None, \n",
        "                        dtype = torch.float)\n",
        "\n",
        "dataFields = {\"Tweet\": (\"Tweet\", TEXT),\n",
        "              'anger': (\"anger\", LABEL),\n",
        "              'anticipation': (\"anticipation\", LABEL),\n",
        "              'disgust': (\"disgust\", LABEL),\n",
        "              'fear': (\"fear\", LABEL),\n",
        "              'joy': (\"joy\", LABEL),\n",
        "              'love': (\"love\", LABEL),\n",
        "              'optimism': (\"optimism\", LABEL),\n",
        "              'pessimism': (\"pessimism\", LABEL),\n",
        "              'sadness': (\"sadness\", LABEL),\n",
        "              'surprise': (\"surprise\", LABEL),\n",
        "              'trust': (\"trust\", LABEL)}\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path = DATA_PATH,\n",
        "    train = 'train.csv',\n",
        "    validation = 'val.csv',\n",
        "    test = 'test.csv',\n",
        "    format = 'csv',\n",
        "    fields = dataFields\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz15EhbHwlTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    sort_key = lambda x: len(x.Tweet),\n",
        "    sort_within_batch = True,\n",
        "    batch_size = args['batch_size'],\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf0eDnfJxEmF",
        "colab_type": "text"
      },
      "source": [
        "# Setup Batch Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J749TkJ-Hth_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLS = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
        "              'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "iaux = 0\n",
        "\n",
        "for batch in valid_iterator:\n",
        "  iaux += 1\n",
        "  aux = batch\n",
        "  aux2 = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "  if aux == 20: break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdVG6iO5xYSL",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQqcoCie6DK4",
        "colab_type": "text"
      },
      "source": [
        "Load the pretrained bert model from the HuggingFace transformers library.\n",
        "\n",
        "https://github.com/huggingface/transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Os2Jg6dxcHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = BertModel.from_pretrained(args['bert_model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_wMObU94q7p",
        "colab_type": "text"
      },
      "source": [
        "We use the pre-trained bert transformer model to produce embeddings which are then fed into the TextCNN architecture proposed by Yoon Kim at: https://arxiv.org/abs/1408.5882"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe2-uC23xxhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertCNN(nn.Module):\n",
        "  def __init__(self, bert, n_filters, filter_sizes, output_dim, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    self.bert = bert \n",
        "\n",
        "    embedding_dim = 768\n",
        "\n",
        "    self.convs = nn.ModuleList([\n",
        "                                nn.Conv2d(in_channels = 1,\n",
        "                                          out_channels = n_filters,\n",
        "                                          kernel_size = (fs, embedding_dim)) \n",
        "                                for fs in filter_sizes])\n",
        "    \n",
        "    self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    with torch.no_grad():\n",
        "      embedded = self.bert(text)[0]\n",
        "    \n",
        "    embedded = embedded.unsqueeze(1)\n",
        "    \n",
        "    conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "    \n",
        "    cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "    \n",
        "    return self.fc(cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BjxJgdC0umb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "660c47fe-ca2c-42ad-ece6-fce7bb65ebb1"
      },
      "source": [
        "model = BertCNN(bert=bert, \n",
        "                n_filters=args['num_filters'], \n",
        "                filter_sizes=args['filter_sizes'], \n",
        "                output_dim=args['output_dim'], \n",
        "                dropout=args['dropout'])\n",
        "\n",
        "model"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertCNN(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 100, kernel_size=(3, 768), stride=(1, 1))\n",
              "    (1): Conv2d(1, 100, kernel_size=(4, 768), stride=(1, 1))\n",
              "    (2): Conv2d(1, 100, kernel_size=(5, 768), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=300, out_features=11, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBEbhNPV6Ktu",
        "colab_type": "text"
      },
      "source": [
        "Next we freeze the parameters which are a part of the Bert Transformers model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJmHEDeR1IUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vMffCB91RYi",
        "colab_type": "code",
        "outputId": "c1ec9cae-0a09-45ed-e1d0-dbc4e1badd45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convs.0.weight\n",
            "convs.0.bias\n",
            "convs.1.weight\n",
            "convs.1.bias\n",
            "convs.2.weight\n",
            "convs.2.bias\n",
            "fc.weight\n",
            "fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TVLrvFb1Zch",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46iK1uys1Wmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQWnKk5m1eUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO_HU7El6xuK",
        "colab_type": "text"
      },
      "source": [
        "We evaluate using the Jaccard Index and the macro and micro F1's as there are more suitable for multi-label text classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63IKcBC31rMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score, jaccard_similarity_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBCzL0Z-1vN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metricize(preds, y):\n",
        "  f1_macro = f1_score(y, preds.round(), average='macro')\n",
        "  f1_micro = f1_score(y, preds.round(), average='micro')\n",
        "  #acc = roc_auc_score(y, preds)\n",
        "  acc = jaccard_similarity_score(y, preds.round())\n",
        "\n",
        "  return {\n",
        "      'f1_macro': f1_macro,\n",
        "      'f1_micro': f1_micro,\n",
        "      'acc': acc\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vtKoYNR1xbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    predictions = model(batch.Tweet).squeeze(1)\n",
        "\n",
        "    batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "    batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "    loss = criterion(predictions, batch_labels)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "    labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  \n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nthY6Knv14uC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "      predictions = model(batch.Tweet).squeeze(1)\n",
        "\n",
        "      batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "      batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "      loss = criterion(predictions, batch_labels)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "      labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrqsUMQY17tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mjv3g3r6-ZC",
        "colab_type": "text"
      },
      "source": [
        "We train the model for 10 epochs and record the training and validation loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJRKTout1_BJ",
        "colab_type": "code",
        "outputId": "7e5f9030-4913-45d9-ef1d-f688e9b47fee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_history = []\n",
        "valid_history = []\n",
        "\n",
        "for epoch in range(args['epochs']):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_metrics = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_metrics = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    train_history.append(train_loss)\n",
        "    valid_history.append(valid_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'bert-cnn-model.pt')\n",
        "\n",
        "    train_acc = train_metrics['acc']\n",
        "    train_micro = train_metrics['f1_micro']\n",
        "    train_macro = train_metrics['f1_macro']\n",
        "\n",
        "    valid_acc = valid_metrics['acc']\n",
        "    valid_micro = valid_metrics['f1_micro']\n",
        "    valid_macro = valid_metrics['f1_macro']\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train F1 Micro: {train_micro*100:.2f}% | Train F1 Macro: {train_macro*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%  | Val. F1 Micro: {valid_micro*100:.2f}%  | Val. F1 Macro: {valid_macro*100:.2f}%')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 16s\n",
            "\tTrain Loss: 0.427 | Train Acc: 29.60% | Train F1 Micro: 41.99% | Train F1 Macro: 24.98%\n",
            "\t Val. Loss: 0.351 | Val. Acc: 43.48%  | Val. F1 Micro: 57.98%  | Val. F1 Macro: 36.38%\n",
            "Epoch: 02 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.359 | Train Acc: 43.49% | Train F1 Micro: 57.12% | Train F1 Macro: 37.81%\n",
            "\t Val. Loss: 0.339 | Val. Acc: 45.91%  | Val. F1 Micro: 59.64%  | Val. F1 Macro: 37.62%\n",
            "Epoch: 03 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.335 | Train Acc: 47.31% | Train F1 Micro: 60.57% | Train F1 Macro: 42.07%\n",
            "\t Val. Loss: 0.332 | Val. Acc: 48.08%  | Val. F1 Micro: 61.66%  | Val. F1 Macro: 41.30%\n",
            "Epoch: 04 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.322 | Train Acc: 49.49% | Train F1 Micro: 62.71% | Train F1 Macro: 45.07%\n",
            "\t Val. Loss: 0.326 | Val. Acc: 51.25%  | Val. F1 Micro: 64.69%  | Val. F1 Macro: 45.66%\n",
            "Epoch: 05 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 0.311 | Train Acc: 51.55% | Train F1 Micro: 64.40% | Train F1 Macro: 46.98%\n",
            "\t Val. Loss: 0.320 | Val. Acc: 52.55%  | Val. F1 Micro: 65.81%  | Val. F1 Macro: 46.69%\n",
            "Epoch: 06 | Epoch Time: 0m 16s\n",
            "\tTrain Loss: 0.300 | Train Acc: 53.23% | Train F1 Micro: 66.01% | Train F1 Macro: 48.73%\n",
            "\t Val. Loss: 0.326 | Val. Acc: 51.75%  | Val. F1 Micro: 64.83%  | Val. F1 Macro: 46.47%\n",
            "Epoch: 07 | Epoch Time: 0m 16s\n",
            "\tTrain Loss: 0.289 | Train Acc: 55.16% | Train F1 Micro: 67.89% | Train F1 Macro: 51.90%\n",
            "\t Val. Loss: 0.322 | Val. Acc: 53.69%  | Val. F1 Micro: 66.67%  | Val. F1 Macro: 46.76%\n",
            "Epoch: 08 | Epoch Time: 0m 16s\n",
            "\tTrain Loss: 0.283 | Train Acc: 55.94% | Train F1 Micro: 68.50% | Train F1 Macro: 52.89%\n",
            "\t Val. Loss: 0.318 | Val. Acc: 52.89%  | Val. F1 Micro: 65.82%  | Val. F1 Macro: 46.96%\n",
            "Epoch: 09 | Epoch Time: 0m 16s\n",
            "\tTrain Loss: 0.272 | Train Acc: 57.31% | Train F1 Micro: 69.96% | Train F1 Macro: 55.18%\n",
            "\t Val. Loss: 0.320 | Val. Acc: 53.10%  | Val. F1 Micro: 66.42%  | Val. F1 Macro: 46.55%\n",
            "Epoch: 10 | Epoch Time: 0m 16s\n",
            "\tTrain Loss: 0.265 | Train Acc: 58.52% | Train F1 Micro: 70.98% | Train F1 Macro: 56.55%\n",
            "\t Val. Loss: 0.327 | Val. Acc: 52.87%  | Val. F1 Micro: 66.13%  | Val. F1 Macro: 48.90%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_Y6H4Bg_H02",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the training and validation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xApekxv62E2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYvkc4ylPU2H",
        "colab_type": "code",
        "outputId": "e97cfef6-aa4d-4d3f-cffd-bb2a59b32020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plt.plot(train_history)\n",
        "plt.plot(valid_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training', 'Validation'])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe91aa9f9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEMYYYzpkAWGMMaZD/x88ZEFJYR3TFwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR5X3c8r_W1m",
        "colab_type": "text"
      },
      "source": [
        "# Assess model performance on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI8O3g5_PY1l",
        "colab_type": "code",
        "outputId": "71405436-51d6-46d8-84e0-0416932b7425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "model.load_state_dict(torch.load('bert-cnn-model.pt'))\n",
        "\n",
        "test_loss, test_metrics = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "test_acc = test_metrics['acc']\n",
        "test_micro = test_metrics['f1_micro']\n",
        "test_macro = test_metrics['f1_macro']\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test F1 Micro: {test_micro*100:.2f}% | Test F1 Macro: {test_macro*100:.2f}%')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.316 | Test Acc: 53.31% | Test F1 Micro: 65.66% | Test F1 Macro: 46.69%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWvYzUzo73i4",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ldd6LfSYRJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_emotion(model, tokenizer, tweet):\n",
        "  preds = []\n",
        "  model.eval()\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  predictions = model(tensor)\n",
        "  preds.append(torch.sigmoid(predictions).detach().cpu().numpy())\n",
        "  return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRlr-s2DY8Df",
        "colab_type": "code",
        "outputId": "c04bcab1-422a-4b43-fef0-d8cb79e053fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "preds = predict_emotion(model, tokenizer, \"Good music, I love that shit.\")\n",
        "\n",
        "vals = []\n",
        "for p in preds[0]:\n",
        "  for val in p:\n",
        "    vals.append(val)\n",
        "\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "  print(f\"{label.upper()}: {vals[i]}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANGER: 0.049273427575826645\n",
            "ANTICIPATION: 0.1092911958694458\n",
            "DISGUST: 0.06299421936273575\n",
            "FEAR: 0.007006073836237192\n",
            "JOY: 0.9334051012992859\n",
            "LOVE: 0.5966441631317139\n",
            "OPTIMISM: 0.5715864896774292\n",
            "PESSIMISM: 0.011290102265775204\n",
            "SADNESS: 0.028145330026745796\n",
            "SURPRISE: 0.025997860357165337\n",
            "TRUST: 0.2837657332420349\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}