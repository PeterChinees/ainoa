{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1lZJpqv-38jmP7zCizHdy8mSu-IMlHlCZ",
      "authorship_tag": "ABX9TyOjoQHUJ0wEneShUkHFoSUU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/Attention_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWaTkjkKu9TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLFhbGO8C4gJ",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xU5Pc6mvbY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import random\n",
        "import re\n",
        "import transformers\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from pathlib import Path\n",
        "from torchtext import data\n",
        "from torchtext.vocab import GloVe\n",
        "from transformers import BertTokenizer, BertModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZYWV6HMDEm6",
        "colab_type": "text"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FczMGWp1vM_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    \"bert_tokenizer\": \"bert-base-uncased\",\n",
        "    \"bert_pretrained_model\": \"bert-base-uncased\",\n",
        "    \"seed\": 1234,\n",
        "    \"bert_embedding_dim\": 768,\n",
        "    \"use_glove\": False,\n",
        "    \"glove_embedding_dim\": 300,\n",
        "    \"max_vocab_size\": 20000,\n",
        "    \"batch_size\": 64,\n",
        "    \"output_dim\": 11,\n",
        "    \"hidden_size\": 768,\n",
        "    \"num_layers\": 2,\n",
        "    \"dropout\": 0.5,\n",
        "    \"fc_dropout\": 0.5,\n",
        "    \"embed_dropout\": 0.2,\n",
        "    \"weight_decay\": 1e-5,\n",
        "    \"lr\": 0.001,\n",
        "    \"epochs\": 10\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLH3fXNGcq1L",
        "colab_type": "text"
      },
      "source": [
        "# Text pre-processor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m57bXVOPcs0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessor(text):\n",
        "  text = re.sub('<[^>]*>', '', text)\n",
        "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "  text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
        "          ' '.join(emoticons).replace('-', '')) \n",
        "  return text.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s6Jmte7LiVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "586fbe77-c432-45c0-b630-9275bac38490"
      },
      "source": [
        "og_text = '#Good music I love that #shit.'\n",
        "processed = preprocessor(og_text)\n",
        "processed"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good', 'music', 'i', 'love', 'that', 'shit']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QizRI-q1DPf1",
        "colab_type": "text"
      },
      "source": [
        "# Setup Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4nYNxu4vV9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(args['bert_tokenizer'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBv0eC2xvss-",
        "colab_type": "code",
        "outputId": "4383fe6c-86c1-4c5a-8736-5ab7cbd8e52d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes[args['bert_tokenizer']]\n",
        "\n",
        "print(max_input_length)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMBjmcymvlY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(tweet):\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFFnMbqQDbJC",
        "colab_type": "text"
      },
      "source": [
        "# Load and Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYj3qsDpvmwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive'\n",
        "\n",
        "DATA_PATH = Path(file_path + '/datasets/SemEval')\n",
        "\n",
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "if args['use_glove']:\n",
        "  TEXT = data.Field(batch_first=True,\n",
        "                    tokenize=preprocessor,\n",
        "                    use_vocab=True,\n",
        "                    sequential=True)\n",
        "else:\n",
        "  TEXT = data.Field(batch_first = True,\n",
        "                use_vocab = False,\n",
        "                tokenize = tokenize,\n",
        "                preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                init_token = tokenizer.cls_token_id,\n",
        "                eos_token = tokenizer.sep_token_id,\n",
        "                pad_token = tokenizer.pad_token_id,\n",
        "                unk_token = tokenizer.unk_token_id)\n",
        "  \n",
        "LABEL = data.LabelField(sequential = False,\n",
        "                        use_vocab = False,\n",
        "                        pad_token= None,\n",
        "                        unk_token = None, \n",
        "                        dtype = torch.float)\n",
        "\n",
        "dataFields = {\"Tweet\": (\"Tweet\", TEXT),\n",
        "              'anger': (\"anger\", LABEL),\n",
        "              'anticipation': (\"anticipation\", LABEL),\n",
        "              'disgust': (\"disgust\", LABEL),\n",
        "              'fear': (\"fear\", LABEL),\n",
        "              'joy': (\"joy\", LABEL),\n",
        "              'love': (\"love\", LABEL),\n",
        "              'optimism': (\"optimism\", LABEL),\n",
        "              'pessimism': (\"pessimism\", LABEL),\n",
        "              'sadness': (\"sadness\", LABEL),\n",
        "              'surprise': (\"surprise\", LABEL),\n",
        "              'trust': (\"trust\", LABEL)}\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path = DATA_PATH,\n",
        "    train = 'train.csv',\n",
        "    validation = 'val.csv',\n",
        "    test = 'test.csv',\n",
        "    format = 'csv',\n",
        "    fields = dataFields\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYMezWxUvyxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    sort_key = lambda x: len(x.Tweet),\n",
        "    sort_within_batch = True,\n",
        "    batch_size = args['batch_size'],\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRmJtf4xPHxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if args['use_glove']:\n",
        "  TEXT.build_vocab(train_data, vectors=GloVe(name='6B', dim=300), \n",
        "                   max_size=args['max_vocab_size'])\n",
        "  print(f\"\\nUnique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dgYzwnpDhrO",
        "colab_type": "text"
      },
      "source": [
        "# Batch Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZCExSovoy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLS = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
        "              'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "iaux = 0\n",
        "\n",
        "for batch in valid_iterator:\n",
        "  iaux += 1\n",
        "  aux = batch\n",
        "  aux2 = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "  if aux == 20: break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyMA1ST4DlLN",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77GLQlKxDnAx",
        "colab_type": "text"
      },
      "source": [
        "Load the pretrained bert model from the HuggingFace transformers library.\n",
        "\n",
        "https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRiJ1llOvvxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = BertModel.from_pretrained(args['bert_pretrained_model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toQo8u76tf3I",
        "colab_type": "text"
      },
      "source": [
        "Use model architecture proposed at: https://www.aclweb.org/anthology/P16-2034/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD1MiUiwv29n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(Attention, self).__init__()\n",
        "\n",
        "    self.attention = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, H):\n",
        "    M = torch.tanh(H)\n",
        "    M = self.attention(M).squeeze(2)\n",
        "    alpha = F.softmax(M, dim=1).unsqueeze(1)\n",
        "    return alpha\n",
        "\n",
        "class AttentionBiLSTM(nn.Module):\n",
        "  def __init__(self, hidden_size, num_layers, dropout, fc_dropout, \n",
        "               emb_layer_dropout, num_classes):\n",
        "    super(AttentionBiLSTM, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    if args['use_glove']:\n",
        "      embedding_dim = args['glove_embedding_dim']\n",
        "      self.embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
        "    else:\n",
        "      self.bert = bert\n",
        "      embedding_dim = args['bert_embedding_dim']\n",
        "    \n",
        "    # embedding layer dropout\n",
        "    self.emb_layer_dropout = nn.Dropout(emb_layer_dropout)\n",
        "\n",
        "    # lstm layer\n",
        "    self.lstm = nn.LSTM(embedding_dim, \n",
        "                        hidden_size, \n",
        "                        num_layers, \n",
        "                        dropout=(0 if num_layers==1 else dropout),\n",
        "                        bidirectional=True,\n",
        "                        batch_first=True)\n",
        "    \n",
        "    # penultimate layer\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    self.fc_dropout = nn.Dropout(fc_dropout)\n",
        "    \n",
        "    self.attention = Attention(hidden_size)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    if args['use_glove']:\n",
        "      embedded = self.embedding(text)\n",
        "    else:\n",
        "      with torch.no_grad():\n",
        "        embedded = self.bert(text)[0]\n",
        "\n",
        "    embedded = self.emb_layer_dropout(embedded)\n",
        "    y, _ = self.lstm(embedded)\n",
        "    y = y[:,:,:self.hidden_size] + y[:,:,self.hidden_size:]\n",
        "    alpha = self.attention(y)\n",
        "    r = alpha.bmm(y).squeeze(1)\n",
        "    h = torch.tanh(r)\n",
        "    logits = self.fc(h)\n",
        "    logits = self.fc_dropout(logits)\n",
        "    return logits, alpha "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukvWtx9gxE1d",
        "colab_type": "code",
        "outputId": "ccd5f4eb-f89d-402a-884c-543113832311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = AttentionBiLSTM(\n",
        "    hidden_size=args['hidden_size'],\n",
        "    num_layers=args['num_layers'],\n",
        "    dropout=args['dropout'],\n",
        "    fc_dropout=args['fc_dropout'],\n",
        "    emb_layer_dropout=args['embed_dropout'],\n",
        "    num_classes=args['output_dim'],\n",
        ")\n",
        "\n",
        "model"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttentionBiLSTM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (emb_layer_dropout): Dropout(p=0.2, inplace=False)\n",
              "  (lstm): LSTM(768, 768, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "  (fc): Linear(in_features=768, out_features=11, bias=True)\n",
              "  (fc_dropout): Dropout(p=0.5, inplace=False)\n",
              "  (attention): Attention(\n",
              "    (attention): Linear(in_features=768, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HIm_dK8EbZ2",
        "colab_type": "text"
      },
      "source": [
        "Freeze the parameters which are a part of the Bert Transformers model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4i0FWYtxQ0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if args['use_glove'] is False:\n",
        "  for name, param in model.named_parameters():                \n",
        "      if name.startswith('bert'):\n",
        "          param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC9ZocNzEoDZ",
        "colab_type": "text"
      },
      "source": [
        "Show the trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1af7wW5xYk_",
        "colab_type": "code",
        "outputId": "2f2995af-7fef-4c13-8e91-2c05d9ed2a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lstm.weight_ih_l0\n",
            "lstm.weight_hh_l0\n",
            "lstm.bias_ih_l0\n",
            "lstm.bias_hh_l0\n",
            "lstm.weight_ih_l0_reverse\n",
            "lstm.weight_hh_l0_reverse\n",
            "lstm.bias_ih_l0_reverse\n",
            "lstm.bias_hh_l0_reverse\n",
            "lstm.weight_ih_l1\n",
            "lstm.weight_hh_l1\n",
            "lstm.bias_ih_l1\n",
            "lstm.bias_hh_l1\n",
            "lstm.weight_ih_l1_reverse\n",
            "lstm.weight_hh_l1_reverse\n",
            "lstm.bias_ih_l1_reverse\n",
            "lstm.bias_hh_l1_reverse\n",
            "fc.weight\n",
            "fc.bias\n",
            "attention.attention.weight\n",
            "attention.attention.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLuzW7f4EyrX",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1CpxbIDxcb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwZIAAQmxfxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), weight_decay=args['weight_decay'])\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amV2jA0oE2Rx",
        "colab_type": "text"
      },
      "source": [
        "We evaluate using the Jaccard index and the macro and micro F1's as there are more suitable for multi-label text classification problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxF1sRahxmwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score, jaccard_similarity_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YydgwAqkxolz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metricize(preds, y):\n",
        "  f1_macro = f1_score(y, preds.round(), average='macro')\n",
        "  f1_micro = f1_score(y, preds.round(), average='micro')\n",
        "  #acc = roc_auc_score(y, preds)\n",
        "  acc = jaccard_similarity_score(y, preds.round())\n",
        "\n",
        "  return {\n",
        "      'f1_macro': f1_macro,\n",
        "      'f1_micro': f1_micro,\n",
        "      'acc': acc\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLL3mSPZxpkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions, _ = model(batch.Tweet)\n",
        "\n",
        "    batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "    batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "    loss = criterion(predictions, batch_labels)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "    labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  \n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoLaQBVvxrla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "      predictions, _ = model(batch.Tweet)\n",
        "\n",
        "      batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "      batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "      loss = criterion(predictions, batch_labels)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "      labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO9vUx_1xtXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqaePMLEFP7e",
        "colab_type": "text"
      },
      "source": [
        "We train the model for 10 epochs and record the training and validation loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSBSFoBOxwJn",
        "colab_type": "code",
        "outputId": "beef7943-5b9b-443a-e6cd-9d1fce8573ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_history = []\n",
        "valid_history = []\n",
        "\n",
        "for epoch in range(args['epochs']):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_metrics = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_metrics = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    train_history.append(train_loss)\n",
        "    valid_history.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        if args['use_glove']:\n",
        "          torch.save(model.state_dict(), 'glove-lstm-model.pt')\n",
        "        else:\n",
        "          torch.save(model.state_dict(), 'bert-lstm-model.pt')\n",
        "        \n",
        "\n",
        "    train_acc = train_metrics['acc']\n",
        "    train_micro = train_metrics['f1_micro']\n",
        "    train_macro = train_metrics['f1_macro']\n",
        "\n",
        "    valid_acc = valid_metrics['acc']\n",
        "    valid_micro = valid_metrics['f1_micro']\n",
        "    valid_macro = valid_metrics['f1_macro']\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train F1 Micro: {train_micro*100:.2f}% | Train F1 Macro: {train_macro*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%  | Val. F1 Micro: {valid_micro*100:.2f}%  | Val. F1 Macro: {valid_macro*100:.2f}%')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.555 | Train Acc: 17.82% | Train F1 Micro: 26.29% | Train F1 Macro: 16.23%\n",
            "\t Val. Loss: 0.415 | Val. Acc: 43.92%  | Val. F1 Micro: 57.59%  | Val. F1 Macro: 37.94%\n",
            "Epoch: 02 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.525 | Train Acc: 24.73% | Train F1 Micro: 35.38% | Train F1 Macro: 23.66%\n",
            "\t Val. Loss: 0.391 | Val. Acc: 50.97%  | Val. F1 Micro: 62.60%  | Val. F1 Macro: 40.44%\n",
            "Epoch: 03 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.512 | Train Acc: 26.88% | Train F1 Micro: 38.90% | Train F1 Macro: 27.76%\n",
            "\t Val. Loss: 0.385 | Val. Acc: 49.44%  | Val. F1 Micro: 61.96%  | Val. F1 Macro: 43.19%\n",
            "Epoch: 04 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.510 | Train Acc: 27.47% | Train F1 Micro: 39.33% | Train F1 Macro: 27.49%\n",
            "\t Val. Loss: 0.380 | Val. Acc: 51.65%  | Val. F1 Micro: 64.85%  | Val. F1 Macro: 46.37%\n",
            "Epoch: 05 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.503 | Train Acc: 28.71% | Train F1 Micro: 40.60% | Train F1 Macro: 30.01%\n",
            "\t Val. Loss: 0.375 | Val. Acc: 54.22%  | Val. F1 Micro: 66.83%  | Val. F1 Macro: 49.84%\n",
            "Epoch: 06 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.501 | Train Acc: 29.19% | Train F1 Micro: 41.62% | Train F1 Macro: 31.06%\n",
            "\t Val. Loss: 0.390 | Val. Acc: 53.97%  | Val. F1 Micro: 66.06%  | Val. F1 Macro: 50.08%\n",
            "Epoch: 07 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.497 | Train Acc: 29.20% | Train F1 Micro: 41.58% | Train F1 Macro: 30.72%\n",
            "\t Val. Loss: 0.358 | Val. Acc: 55.01%  | Val. F1 Micro: 67.17%  | Val. F1 Macro: 48.25%\n",
            "Epoch: 08 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.495 | Train Acc: 30.06% | Train F1 Micro: 42.47% | Train F1 Macro: 31.75%\n",
            "\t Val. Loss: 0.352 | Val. Acc: 55.23%  | Val. F1 Micro: 67.61%  | Val. F1 Macro: 48.64%\n",
            "Epoch: 09 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.495 | Train Acc: 29.59% | Train F1 Micro: 41.92% | Train F1 Macro: 32.02%\n",
            "\t Val. Loss: 0.360 | Val. Acc: 54.61%  | Val. F1 Micro: 66.60%  | Val. F1 Macro: 49.12%\n",
            "Epoch: 10 | Epoch Time: 0m 12s\n",
            "\tTrain Loss: 0.490 | Train Acc: 31.00% | Train F1 Micro: 43.31% | Train F1 Macro: 33.39%\n",
            "\t Val. Loss: 0.342 | Val. Acc: 55.16%  | Val. F1 Micro: 67.09%  | Val. F1 Macro: 49.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqXexw71GcWj",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the training and validation loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CePfv7_0An7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgUKd4HR6Tg-",
        "colab_type": "code",
        "outputId": "850cb732-f7e1-435d-b14d-370f7e6e3e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plt.plot(train_history)\n",
        "plt.plot(valid_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training', 'Validation'])"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fd199461470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtOPAqB1GkB5",
        "colab_type": "text"
      },
      "source": [
        "# Assess model performance on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TxQGreq6Vgm",
        "colab_type": "code",
        "outputId": "165d122c-fdf9-4bc7-9a31-56609dc17026",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "if (args['use_glove']):\n",
        "  model.load_state_dict(torch.load('glove-lstm-model.pt'))\n",
        "else:\n",
        "  model.load_state_dict(torch.load('bert-lstm-model.pt'))\n",
        "\n",
        "\n",
        "test_loss, test_metrics = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "test_acc = test_metrics['acc']\n",
        "test_micro = test_metrics['f1_micro']\n",
        "test_macro = test_metrics['f1_macro']\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test F1 Micro: {test_micro*100:.2f}% | Test F1 Macro: {test_macro*100:.2f}%')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.343 | Test Acc: 55.49% | Test F1 Micro: 67.32% | Test F1 Macro: 48.96%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:664: FutureWarning: jaccard_similarity_score has been deprecated and replaced with jaccard_score. It will be removed in version 0.23. This implementation has surprising behavior for binary and multiclass classification tasks.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaJzLdwb6exr",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ6W1Xpq6aO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_emotion(model, tokenizer, tweet):\n",
        "  preds = []\n",
        "  model.eval()\n",
        "\n",
        "  if args['use_glove']:\n",
        "    tokenized = preprocessor(tweet)\n",
        "    indexed = [TEXT.vocab.stoi[token] for token in tokenized]\n",
        "  else:\n",
        "    tokens = tokenizer.tokenize(tweet)\n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    indexed = [tokenizer.cls_token_id] + tokenizer.convert_tokens_to_ids(tokens) + [tokenizer.sep_token_id]\n",
        "\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  predictions, attn_weights = model(tensor)\n",
        "  preds.append(torch.sigmoid(predictions).detach().cpu().numpy())\n",
        "\n",
        "  if args['use_glove']:\n",
        "    return preds, attn_weights, tokenized\n",
        "  else:\n",
        "    return preds, attn_weights, tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL9EtxTrG7My",
        "colab_type": "text"
      },
      "source": [
        "Lets test the model on our own input and save the attention weights and tokens for visualization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eecw3IVA6lVH",
        "colab_type": "code",
        "outputId": "3ee6ab88-e7a7-4038-9343-3b8a8c5a1763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "preds, attn_weights, tokens = predict_emotion(model, tokenizer, \n",
        "                                              \"Good music, I love that shit.\")\n",
        "\n",
        "vals = []\n",
        "for p in preds[0]:\n",
        "  for val in p:\n",
        "    vals.append(val)\n",
        "\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "  print(f\"{label.upper()}: {vals[i]}\")"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANGER: 0.12803779542446136\n",
            "ANTICIPATION: 0.23622599244117737\n",
            "DISGUST: 0.1200779378414154\n",
            "FEAR: 0.06617572158575058\n",
            "JOY: 0.8988523483276367\n",
            "LOVE: 0.7140619158744812\n",
            "OPTIMISM: 0.7247300148010254\n",
            "PESSIMISM: 0.06133587285876274\n",
            "SADNESS: 0.08890264481306076\n",
            "SURPRISE: 0.11193631589412689\n",
            "TRUST: 0.3529787063598633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jeDWh8KHbEG",
        "colab_type": "text"
      },
      "source": [
        "Here we format the attention weights and store the results in a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q71LaaAn6oBA",
        "colab_type": "code",
        "outputId": "643d57cd-d44c-4655-e549-6045d60b05aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "aws = []\n",
        "for a in attn_weights[0]:\n",
        "  for v in a:\n",
        "    aws.append(v.detach().cpu().numpy())\n",
        "\n",
        "if args['use_glove']:\n",
        "  aws = np.array(aws)\n",
        "else:\n",
        "  aws = aws[1:-1]\n",
        "  aws = np.array(aws)\n",
        "\n",
        "aws"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10268865, 0.02682122, 0.03941532, 0.06363216, 0.6166039 ,\n",
              "       0.04738833, 0.09188536, 0.00515515], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnrDFOGy9DLx",
        "colab_type": "code",
        "outputId": "1c964c1f-e5c6-4d1a-b063-6d1c1f052b37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "attn_dict = {}\n",
        "for i in range(len(aws)):\n",
        "  attn_dict[tokens[i]] = aws[i]\n",
        "\n",
        "print(attn_dict)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'good': 0.10268865, 'music': 0.026821222, ',': 0.03941532, 'i': 0.06363216, 'love': 0.6166039, 'that': 0.047388326, 'shit': 0.09188536, '.': 0.00515515}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tomju0TvHp8z",
        "colab_type": "text"
      },
      "source": [
        "Lets return the top 3 words that the model focused on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skdcPb0g-nQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LqBqNKVCqan",
        "colab_type": "code",
        "outputId": "77204369-2013-431d-e65f-bf09a85a8c36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Counter(attn_dict).most_common(3)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('love', 0.6166039), ('good', 0.10268865), ('shit', 0.09188536)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP2sas0HMzmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}