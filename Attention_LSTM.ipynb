{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1lZJpqv-38jmP7zCizHdy8mSu-IMlHlCZ",
      "authorship_tag": "ABX9TyNhE3y9yyen7i/xfNj+yUet",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/Attention_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWaTkjkKu9TB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLFhbGO8C4gJ",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xU5Pc6mvbY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import random\n",
        "import re\n",
        "import transformers\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from pathlib import Path\n",
        "from torchtext import data\n",
        "from torchtext.vocab import GloVe\n",
        "from transformers import BertTokenizer, BertModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZYWV6HMDEm6",
        "colab_type": "text"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FczMGWp1vM_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    \"bert_tokenizer\": \"bert-base-uncased\",\n",
        "    \"bert_pretrained_model\": \"bert-base-uncased\",\n",
        "    \"seed\": 1234,\n",
        "    \"bert_embedding_dim\": 768,\n",
        "    \"use_glove\": False,\n",
        "    \"glove_embedding_dim\": 300,\n",
        "    \"max_vocab_size\": 20000,\n",
        "    \"batch_size\": 10,\n",
        "    \"output_dim\": 11,\n",
        "    \"hidden_size\": 768,\n",
        "    \"num_layers\": 2,\n",
        "    \"dropout\": 0.3,\n",
        "    \"fc_dropout\": 0.5,\n",
        "    \"embed_dropout\": 0.3,\n",
        "    \"weight_decay\": 1e-5,\n",
        "    \"lr\": 0.001,\n",
        "    \"epochs\": 10\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLH3fXNGcq1L",
        "colab_type": "text"
      },
      "source": [
        "# Text pre-processor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m57bXVOPcs0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessor(text):\n",
        "  text = re.sub('<[^>]*>', '', text)\n",
        "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "  text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
        "          ' '.join(emoticons).replace('-', '')) \n",
        "  return text.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s6Jmte7LiVS",
        "colab_type": "code",
        "outputId": "b019eac8-d4e3-46dd-f894-76141357ceb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "og_text = '#Good music I love that #shit.'\n",
        "processed = preprocessor(og_text)\n",
        "processed"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good', 'music', 'i', 'love', 'that', 'shit']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QizRI-q1DPf1",
        "colab_type": "text"
      },
      "source": [
        "# Setup Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4nYNxu4vV9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(args['bert_tokenizer'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBv0eC2xvss-",
        "colab_type": "code",
        "outputId": "f0366b28-48e9-40b3-a18d-5aef87f441ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes[args['bert_tokenizer']]\n",
        "\n",
        "print(max_input_length)"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMBjmcymvlY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(tweet):\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFFnMbqQDbJC",
        "colab_type": "text"
      },
      "source": [
        "# Load and Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYj3qsDpvmwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive'\n",
        "\n",
        "DATA_PATH = Path(file_path + '/datasets/SemEval')\n",
        "\n",
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "if args['use_glove']:\n",
        "  TEXT = data.Field(batch_first=True,\n",
        "                    tokenize=preprocessor,\n",
        "                    use_vocab=True,\n",
        "                    sequential=True)\n",
        "else:\n",
        "  TEXT = data.Field(batch_first = True,\n",
        "                use_vocab = False,\n",
        "                tokenize = tokenize,\n",
        "                preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                init_token = tokenizer.cls_token_id,\n",
        "                eos_token = tokenizer.sep_token_id,\n",
        "                pad_token = tokenizer.pad_token_id,\n",
        "                unk_token = tokenizer.unk_token_id)\n",
        "  \n",
        "LABEL = data.LabelField(sequential = False,\n",
        "                        use_vocab = False,\n",
        "                        pad_token= None,\n",
        "                        unk_token = None, \n",
        "                        dtype = torch.float)\n",
        "\n",
        "dataFields = {\"Tweet\": (\"Tweet\", TEXT),\n",
        "              'anger': (\"anger\", LABEL),\n",
        "              'anticipation': (\"anticipation\", LABEL),\n",
        "              'disgust': (\"disgust\", LABEL),\n",
        "              'fear': (\"fear\", LABEL),\n",
        "              'joy': (\"joy\", LABEL),\n",
        "              'love': (\"love\", LABEL),\n",
        "              'optimism': (\"optimism\", LABEL),\n",
        "              'pessimism': (\"pessimism\", LABEL),\n",
        "              'sadness': (\"sadness\", LABEL),\n",
        "              'surprise': (\"surprise\", LABEL),\n",
        "              'trust': (\"trust\", LABEL)}\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path = DATA_PATH,\n",
        "    train = 'train.csv',\n",
        "    validation = 'val.csv',\n",
        "    test = 'test.csv',\n",
        "    format = 'csv',\n",
        "    fields = dataFields\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYMezWxUvyxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    sort_key = lambda x: len(x.Tweet),\n",
        "    sort_within_batch = True,\n",
        "    batch_size = args['batch_size'],\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRmJtf4xPHxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if args['use_glove']:\n",
        "  TEXT.build_vocab(train_data, vectors=GloVe(name='6B', dim=300), \n",
        "                   max_size=args['max_vocab_size'])\n",
        "  print(f\"\\nUnique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dgYzwnpDhrO",
        "colab_type": "text"
      },
      "source": [
        "# Batch Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZCExSovoy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLS = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
        "              'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "iaux = 0\n",
        "\n",
        "for batch in valid_iterator:\n",
        "  iaux += 1\n",
        "  aux = batch\n",
        "  aux2 = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "  if aux == 20: break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyMA1ST4DlLN",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77GLQlKxDnAx",
        "colab_type": "text"
      },
      "source": [
        "Load the pretrained bert model from the HuggingFace transformers library.\n",
        "\n",
        "https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRiJ1llOvvxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = BertModel.from_pretrained(args['bert_pretrained_model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toQo8u76tf3I",
        "colab_type": "text"
      },
      "source": [
        "Use model architecture proposed at: https://www.aclweb.org/anthology/P16-2034/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD1MiUiwv29n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(Attention, self).__init__()\n",
        "\n",
        "    self.attention = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, H):\n",
        "    M = torch.tanh(H)\n",
        "    M = self.attention(M).squeeze(2)\n",
        "    alpha = F.softmax(M, dim=1).unsqueeze(1)\n",
        "    return alpha\n",
        "\n",
        "class AttentionBiLSTM(nn.Module):\n",
        "  def __init__(self, hidden_size, num_layers, dropout, fc_dropout, \n",
        "               emb_layer_dropout, num_classes):\n",
        "    super(AttentionBiLSTM, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    if args['use_glove']:\n",
        "      embedding_dim = args['glove_embedding_dim']\n",
        "      self.embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
        "    else:\n",
        "      self.bert = bert\n",
        "      embedding_dim = args['bert_embedding_dim']\n",
        "    \n",
        "    # embedding layer dropout\n",
        "    self.emb_layer_dropout = nn.Dropout(emb_layer_dropout)\n",
        "\n",
        "    # lstm layer\n",
        "    self.lstm = nn.LSTM(embedding_dim, \n",
        "                        hidden_size, \n",
        "                        num_layers, \n",
        "                        dropout=(0 if num_layers==1 else dropout),\n",
        "                        bidirectional=True,\n",
        "                        batch_first=True)\n",
        "    \n",
        "    # penultimate layer\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    self.fc_dropout = nn.Dropout(fc_dropout)\n",
        "    \n",
        "    self.attention = Attention(hidden_size)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    if args['use_glove']:\n",
        "      embedded = self.embedding(text)\n",
        "    else:\n",
        "      with torch.no_grad():\n",
        "        embedded = self.bert(text)[0]\n",
        "\n",
        "    embedded = self.emb_layer_dropout(embedded)\n",
        "    y, _ = self.lstm(embedded)\n",
        "    y = y[:,:,:self.hidden_size] + y[:,:,self.hidden_size:]\n",
        "    alpha = self.attention(y)\n",
        "    r = alpha.bmm(y).squeeze(1)\n",
        "    h = torch.tanh(r)\n",
        "    logits = self.fc(h)\n",
        "    logits = self.fc_dropout(logits)\n",
        "    return logits, alpha "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukvWtx9gxE1d",
        "colab_type": "code",
        "outputId": "e7cfccbf-8e2e-4510-df0f-3ca544b25fe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = AttentionBiLSTM(\n",
        "    hidden_size=args['hidden_size'],\n",
        "    num_layers=args['num_layers'],\n",
        "    dropout=args['dropout'],\n",
        "    fc_dropout=args['fc_dropout'],\n",
        "    emb_layer_dropout=args['embed_dropout'],\n",
        "    num_classes=args['output_dim'],\n",
        ")\n",
        "\n",
        "model"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttentionBiLSTM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (emb_layer_dropout): Dropout(p=0.3, inplace=False)\n",
              "  (lstm): LSTM(768, 768, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (fc): Linear(in_features=768, out_features=11, bias=True)\n",
              "  (fc_dropout): Dropout(p=0.5, inplace=False)\n",
              "  (attention): Attention(\n",
              "    (attention): Linear(in_features=768, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HIm_dK8EbZ2",
        "colab_type": "text"
      },
      "source": [
        "Freeze the parameters which are a part of the Bert Transformers model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4i0FWYtxQ0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if args['use_glove'] is False:\n",
        "  for name, param in model.named_parameters():                \n",
        "      if name.startswith('bert'):\n",
        "          param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC9ZocNzEoDZ",
        "colab_type": "text"
      },
      "source": [
        "Show the trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1af7wW5xYk_",
        "colab_type": "code",
        "outputId": "7286e73e-22cf-4b22-a014-24b8697a96cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lstm.weight_ih_l0\n",
            "lstm.weight_hh_l0\n",
            "lstm.bias_ih_l0\n",
            "lstm.bias_hh_l0\n",
            "lstm.weight_ih_l0_reverse\n",
            "lstm.weight_hh_l0_reverse\n",
            "lstm.bias_ih_l0_reverse\n",
            "lstm.bias_hh_l0_reverse\n",
            "lstm.weight_ih_l1\n",
            "lstm.weight_hh_l1\n",
            "lstm.bias_ih_l1\n",
            "lstm.bias_hh_l1\n",
            "lstm.weight_ih_l1_reverse\n",
            "lstm.weight_hh_l1_reverse\n",
            "lstm.bias_ih_l1_reverse\n",
            "lstm.bias_hh_l1_reverse\n",
            "fc.weight\n",
            "fc.bias\n",
            "attention.attention.weight\n",
            "attention.attention.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLuzW7f4EyrX",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1CpxbIDxcb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwZIAAQmxfxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), weight_decay=args['weight_decay'])\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amV2jA0oE2Rx",
        "colab_type": "text"
      },
      "source": [
        "We evaluate using the Jaccard index and the macro and micro F1's as there are more suitable for multi-label text classification problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxF1sRahxmwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score, jaccard_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YydgwAqkxolz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metricize(preds, y):\n",
        "  f1_macro = f1_score(y, preds.round(), average='macro')\n",
        "  f1_micro = f1_score(y, preds.round(), average='micro')\n",
        "  #acc = roc_auc_score(y, preds)\n",
        "  jaccard = jaccard_score(y, preds.round(), average='samples')\n",
        "\n",
        "  return {\n",
        "      'f1_macro': f1_macro,\n",
        "      'f1_micro': f1_micro,\n",
        "      'jaccard': jaccard\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLL3mSPZxpkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions, _ = model(batch.Tweet)\n",
        "\n",
        "    batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "    batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "    loss = criterion(predictions, batch_labels)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "    labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  \n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoLaQBVvxrla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "      predictions, _ = model(batch.Tweet)\n",
        "\n",
        "      batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "      batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "      loss = criterion(predictions, batch_labels)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "      labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO9vUx_1xtXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqaePMLEFP7e",
        "colab_type": "text"
      },
      "source": [
        "We train the model for 10 epochs and record the training and validation loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSBSFoBOxwJn",
        "colab_type": "code",
        "outputId": "204afe5f-f6d2-429e-d87c-8423b7fc3016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_history = []\n",
        "valid_history = []\n",
        "\n",
        "for epoch in range(args['epochs']):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_metrics = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_metrics = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    train_history.append(train_loss)\n",
        "    valid_history.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        if args['use_glove']:\n",
        "          torch.save(model.state_dict(), 'glove-lstm-model.pt')\n",
        "        else:\n",
        "          torch.save(model.state_dict(), 'bert-lstm-model.pt')\n",
        "        \n",
        "\n",
        "    train_jaccard = train_metrics['jaccard']\n",
        "    train_micro = train_metrics['f1_micro']\n",
        "    train_macro = train_metrics['f1_macro']\n",
        "\n",
        "    valid_jaccard = valid_metrics['jaccard']\n",
        "    valid_micro = valid_metrics['f1_micro']\n",
        "    valid_macro = valid_metrics['f1_macro']\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Jaccard: {train_jaccard*100:.2f}% | Train F1 Micro: {train_micro*100:.2f}% | Train F1 Macro: {train_macro*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} | Val. Jaccard: {valid_jaccard*100:.2f}%  | Val. F1 Micro: {valid_micro*100:.2f}%  | Val. F1 Macro: {valid_macro*100:.2f}%')"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 45s\n",
            "\tTrain Loss: 0.551 | Train Jaccard: 18.16% | Train F1 Micro: 29.51% | Train F1 Macro: 17.91%\n",
            "\t Val. Loss: 0.416 | Val. Jaccard: 42.80%  | Val. F1 Micro: 57.97%  | Val. F1 Macro: 35.41%\n",
            "Epoch: 02 | Epoch Time: 1m 46s\n",
            "\tTrain Loss: 0.525 | Train Jaccard: 23.26% | Train F1 Micro: 36.11% | Train F1 Macro: 24.03%\n",
            "\t Val. Loss: 0.394 | Val. Jaccard: 48.01%  | Val. F1 Micro: 61.39%  | Val. F1 Macro: 40.22%\n",
            "Epoch: 03 | Epoch Time: 1m 46s\n",
            "\tTrain Loss: 0.516 | Train Jaccard: 24.79% | Train F1 Micro: 38.11% | Train F1 Macro: 26.56%\n",
            "\t Val. Loss: 0.364 | Val. Jaccard: 51.88%  | Val. F1 Micro: 64.10%  | Val. F1 Macro: 41.77%\n",
            "Epoch: 04 | Epoch Time: 1m 46s\n",
            "\tTrain Loss: 0.508 | Train Jaccard: 25.63% | Train F1 Micro: 39.19% | Train F1 Macro: 27.16%\n",
            "\t Val. Loss: 0.371 | Val. Jaccard: 52.81%  | Val. F1 Micro: 65.00%  | Val. F1 Macro: 44.18%\n",
            "Epoch: 05 | Epoch Time: 1m 46s\n",
            "\tTrain Loss: 0.505 | Train Jaccard: 26.99% | Train F1 Micro: 40.71% | Train F1 Macro: 29.02%\n",
            "\t Val. Loss: 0.357 | Val. Jaccard: 55.58%  | Val. F1 Micro: 67.92%  | Val. F1 Macro: 49.76%\n",
            "Epoch: 06 | Epoch Time: 1m 48s\n",
            "\tTrain Loss: 0.502 | Train Jaccard: 26.75% | Train F1 Micro: 40.58% | Train F1 Macro: 29.50%\n",
            "\t Val. Loss: 0.364 | Val. Jaccard: 53.47%  | Val. F1 Micro: 65.99%  | Val. F1 Macro: 45.64%\n",
            "Epoch: 07 | Epoch Time: 1m 48s\n",
            "\tTrain Loss: 0.501 | Train Jaccard: 26.72% | Train F1 Micro: 40.63% | Train F1 Macro: 29.91%\n",
            "\t Val. Loss: 0.344 | Val. Jaccard: 54.35%  | Val. F1 Micro: 66.67%  | Val. F1 Macro: 47.39%\n",
            "Epoch: 08 | Epoch Time: 1m 48s\n",
            "\tTrain Loss: 0.499 | Train Jaccard: 27.66% | Train F1 Micro: 41.56% | Train F1 Macro: 30.96%\n",
            "\t Val. Loss: 0.367 | Val. Jaccard: 54.11%  | Val. F1 Micro: 66.50%  | Val. F1 Macro: 48.80%\n",
            "Epoch: 09 | Epoch Time: 1m 48s\n",
            "\tTrain Loss: 0.496 | Train Jaccard: 28.03% | Train F1 Micro: 42.24% | Train F1 Macro: 31.68%\n",
            "\t Val. Loss: 0.355 | Val. Jaccard: 55.64%  | Val. F1 Micro: 67.29%  | Val. F1 Macro: 50.33%\n",
            "Epoch: 10 | Epoch Time: 1m 48s\n",
            "\tTrain Loss: 0.493 | Train Jaccard: 28.07% | Train F1 Micro: 42.35% | Train F1 Macro: 31.78%\n",
            "\t Val. Loss: 0.362 | Val. Jaccard: 53.88%  | Val. F1 Micro: 66.09%  | Val. F1 Macro: 48.77%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqXexw71GcWj",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the training and validation loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CePfv7_0An7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgUKd4HR6Tg-",
        "colab_type": "code",
        "outputId": "b48fb093-60ab-474a-d8ea-422de48322ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plt.plot(train_history)\n",
        "plt.plot(valid_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training', 'Validation'])"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff5ae6710f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtOPAqB1GkB5",
        "colab_type": "text"
      },
      "source": [
        "# Assess model performance on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TxQGreq6Vgm",
        "colab_type": "code",
        "outputId": "33f825d2-0d12-4d43-b69d-49437b63dcfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "if (args['use_glove']):\n",
        "  model.load_state_dict(torch.load('glove-lstm-model.pt'))\n",
        "else:\n",
        "  model.load_state_dict(torch.load('bert-lstm-model.pt'))\n",
        "\n",
        "\n",
        "test_loss, test_metrics = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "test_jaccard = test_metrics['jaccard']\n",
        "test_micro = test_metrics['f1_micro']\n",
        "test_macro = test_metrics['f1_macro']\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Jaccard: {test_jaccard*100:.2f}% | Test F1 Micro: {test_micro*100:.2f}% | Test F1 Macro: {test_macro*100:.2f}%')"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.345 | Test Jaccard: 54.23% | Test F1 Micro: 66.59% | Test F1 Macro: 47.71%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaJzLdwb6exr",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ6W1Xpq6aO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_emotion(model, tokenizer, tweet):\n",
        "  preds = []\n",
        "  model.eval()\n",
        "\n",
        "  if args['use_glove']:\n",
        "    tokenized = preprocessor(tweet)\n",
        "    indexed = [TEXT.vocab.stoi[token] for token in tokenized]\n",
        "  else:\n",
        "    tokens = tokenizer.tokenize(tweet)\n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    indexed = [tokenizer.cls_token_id] + tokenizer.convert_tokens_to_ids(tokens) + [tokenizer.sep_token_id]\n",
        "\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  predictions, attn_weights = model(tensor)\n",
        "  preds.append(torch.sigmoid(predictions).detach().cpu().numpy())\n",
        "\n",
        "  if args['use_glove']:\n",
        "    return preds, attn_weights, tokenized\n",
        "  else:\n",
        "    return preds, attn_weights, tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL9EtxTrG7My",
        "colab_type": "text"
      },
      "source": [
        "Lets test the model on our own input and save the attention weights and tokens for visualization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eecw3IVA6lVH",
        "colab_type": "code",
        "outputId": "a716aeae-1557-473e-8f9d-6f8d00fece81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "preds, attn_weights, tokens = predict_emotion(model, tokenizer, \n",
        "                                              \"Good music, I love that shit.\")\n",
        "\n",
        "vals = []\n",
        "for p in preds[0]:\n",
        "  for val in p:\n",
        "    vals.append(val)\n",
        "\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "  print(f\"{label.upper()}: {vals[i]}\")"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANGER: 0.25984829664230347\n",
            "ANTICIPATION: 0.1480916291475296\n",
            "DISGUST: 0.13483241200447083\n",
            "FEAR: 0.05347893759608269\n",
            "JOY: 0.9440457224845886\n",
            "LOVE: 0.7657690644264221\n",
            "OPTIMISM: 0.6690095663070679\n",
            "PESSIMISM: 0.043805450201034546\n",
            "SADNESS: 0.05613982677459717\n",
            "SURPRISE: 0.11099488288164139\n",
            "TRUST: 0.29462453722953796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jeDWh8KHbEG",
        "colab_type": "text"
      },
      "source": [
        "Here we format the attention weights and store the results in a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q71LaaAn6oBA",
        "colab_type": "code",
        "outputId": "ae863700-6d16-4ad6-ddfc-ce6b2d0e4ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "aws = []\n",
        "for a in attn_weights[0]:\n",
        "  for v in a:\n",
        "    aws.append(v.detach().cpu().numpy())\n",
        "\n",
        "if args['use_glove']:\n",
        "  aws = np.array(aws)\n",
        "else:\n",
        "  aws = aws[1:-1]\n",
        "  aws = np.array(aws)\n",
        "\n",
        "aws"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.22938426, 0.00838671, 0.0180554 , 0.01933124, 0.5326653 ,\n",
              "       0.01665986, 0.17065106, 0.00127183], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnrDFOGy9DLx",
        "colab_type": "code",
        "outputId": "4e74a01f-1a41-4f35-8e45-dbbc26ba929d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attn_dict = {}\n",
        "for i in range(len(aws)):\n",
        "  attn_dict[tokens[i]] = aws[i]\n",
        "\n",
        "print(attn_dict)"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'good': 0.22938426, 'music': 0.00838671, ',': 0.0180554, 'i': 0.019331241, 'love': 0.5326653, 'that': 0.016659861, 'shit': 0.17065106, '.': 0.0012718264}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tomju0TvHp8z",
        "colab_type": "text"
      },
      "source": [
        "Lets return the top 3 words that the model focused on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skdcPb0g-nQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LqBqNKVCqan",
        "colab_type": "code",
        "outputId": "4a11e590-e831-4573-f1f5-a87eb3b09fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Counter(attn_dict).most_common(3)"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('love', 0.5326653), ('good', 0.22938426), ('shit', 0.17065106)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 300
        }
      ]
    }
  ]
}