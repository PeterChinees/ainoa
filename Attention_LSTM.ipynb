{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1lZJpqv-38jmP7zCizHdy8mSu-IMlHlCZ",
      "authorship_tag": "ABX9TyMOKKNiYDVwtiZssh8FhsYL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "364116b64b1a406aafc880b6bf5ded93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f96ad8919dc4ec7bb4ea4e0436c9757",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_efbc90ac64114ec1a0017b6eea4f2a55",
              "IPY_MODEL_ca150fe3fc724d198cfb5151b0623c9e"
            ]
          }
        },
        "2f96ad8919dc4ec7bb4ea4e0436c9757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efbc90ac64114ec1a0017b6eea4f2a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_954dabaf144c4d4ab1930f908e08da9c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14f3f0ff740f41e5a4d10272b37e851a"
          }
        },
        "ca150fe3fc724d198cfb5151b0623c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0fe72f11f9dd489f852f2544f06267b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 600kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_369ef616db634efba4f209429d76053a"
          }
        },
        "954dabaf144c4d4ab1930f908e08da9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14f3f0ff740f41e5a4d10272b37e851a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fe72f11f9dd489f852f2544f06267b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "369ef616db634efba4f209429d76053a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96ed6886ded649ac8fbc14b949c087f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8e8117f2f9b34f1bb04ecc12f04ce178",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee6eb7f835184d4ea999f03f08409c13",
              "IPY_MODEL_6dde02ccb9df4bf8886aa1b452527fcf"
            ]
          }
        },
        "8e8117f2f9b34f1bb04ecc12f04ce178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee6eb7f835184d4ea999f03f08409c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bdd01d06298c42129065f83e23bf0f00",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb844cea159f4354a5c9ff8cd2734a76"
          }
        },
        "6dde02ccb9df4bf8886aa1b452527fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2951206768140d89ae58d9c472aaeac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:55&lt;00:00, 7.74B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59f824623e6044ce847bbd8fbee1dc0a"
          }
        },
        "bdd01d06298c42129065f83e23bf0f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb844cea159f4354a5c9ff8cd2734a76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2951206768140d89ae58d9c472aaeac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59f824623e6044ce847bbd8fbee1dc0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d30174863ddc493d8d496db9d11618cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5cf52412e2f440db83668b042205acab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2c16327170f04e1c86aeedba309dbd1f",
              "IPY_MODEL_c0f6966baf5141ce9596e2eb3e24fd71"
            ]
          }
        },
        "5cf52412e2f440db83668b042205acab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c16327170f04e1c86aeedba309dbd1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6065731c31a74b74bf1dcde0ba9660e8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca41a14d99a74bd380f9380c6d3ddd06"
          }
        },
        "c0f6966baf5141ce9596e2eb3e24fd71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c17823b7066422090c9cb23ece1e798",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 67.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f0c38295a1a437091eb065b5fbcd014"
          }
        },
        "6065731c31a74b74bf1dcde0ba9660e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca41a14d99a74bd380f9380c6d3ddd06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c17823b7066422090c9cb23ece1e798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f0c38295a1a437091eb065b5fbcd014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/Attention_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWaTkjkKu9TB",
        "colab_type": "code",
        "outputId": "ce82b502-4498-47f5-e8e7-3c95d2e4eac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/97/7db72a0beef1825f82188a4b923e62a146271ac2ced7928baa4d47ef2467/transformers-2.9.1-py3-none-any.whl (641kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 645kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 46.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=471dd23225f349e5d483451adbd52a28e67ef011f8ad44f26a8cfaa65da93d56\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.90 tokenizers-0.7.0 transformers-2.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLFhbGO8C4gJ",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xU5Pc6mvbY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import random\n",
        "import re\n",
        "import transformers\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from pathlib import Path\n",
        "from torchtext import data\n",
        "from torchtext.vocab import GloVe\n",
        "from transformers import BertTokenizer, BertModel, DistilBertTokenizer, DistilBertModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzgKR2a8UeXi",
        "colab_type": "code",
        "outputId": "d6e252f5-822a-4d9e-d7bf-23b1e0bb8902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZYWV6HMDEm6",
        "colab_type": "text"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FczMGWp1vM_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    \"bert_tokenizer\": \"bert-base-uncased\",\n",
        "    \"bert_pretrained_model\": \"bert-base-uncased\",\n",
        "    \"distilbert_tokenizer\": \"distilbert-base-uncased\",\n",
        "    \"distilbert_pretrained_model\": \"distilbert-base-uncased\",\n",
        "    \"seed\": 1234,\n",
        "    \"bert_embedding_dim\": 768,\n",
        "    \"use_glove\": False,\n",
        "    \"glove_embedding_dim\": 300,\n",
        "    \"max_vocab_size\": 20000,\n",
        "    \"batch_size\": 10,\n",
        "    \"output_dim\": 11,\n",
        "    \"hidden_size\": 256,\n",
        "    \"num_layers\": 2,\n",
        "    \"dropout\": 0.3,\n",
        "    \"fc_dropout\": 0.5,\n",
        "    \"embed_dropout\": 0.3,\n",
        "    \"weight_decay\": 1e-5,\n",
        "    \"lr\": 0.001,\n",
        "    \"epochs\": 10\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLH3fXNGcq1L",
        "colab_type": "text"
      },
      "source": [
        "# Text pre-processor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m57bXVOPcs0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessor(text):\n",
        "  text = re.sub('<[^>]*>', '', text)\n",
        "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "  text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
        "          ' '.join(emoticons).replace('-', '')) \n",
        "  return text.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s6Jmte7LiVS",
        "colab_type": "code",
        "outputId": "e6e5f405-d763-4093-d583-7ebaf33a5010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "og_text = '#Good music I love that #shit.'\n",
        "processed = preprocessor(og_text)\n",
        "processed"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['good', 'music', 'i', 'love', 'that', 'shit']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QizRI-q1DPf1",
        "colab_type": "text"
      },
      "source": [
        "# Setup Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4nYNxu4vV9X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "364116b64b1a406aafc880b6bf5ded93",
            "2f96ad8919dc4ec7bb4ea4e0436c9757",
            "efbc90ac64114ec1a0017b6eea4f2a55",
            "ca150fe3fc724d198cfb5151b0623c9e",
            "954dabaf144c4d4ab1930f908e08da9c",
            "14f3f0ff740f41e5a4d10272b37e851a",
            "0fe72f11f9dd489f852f2544f06267b4",
            "369ef616db634efba4f209429d76053a"
          ]
        },
        "outputId": "1ea1676a-0334-4dc4-dde2-fce7791114bf"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(args['bert_tokenizer'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "364116b64b1a406aafc880b6bf5ded93",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBv0eC2xvss-",
        "colab_type": "code",
        "outputId": "668f6baf-4840-4297-f291-40e2b9d64310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes[args['bert_tokenizer']]\n",
        "\n",
        "print(max_input_length)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMBjmcymvlY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(tweet):\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFFnMbqQDbJC",
        "colab_type": "text"
      },
      "source": [
        "# Load and Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYj3qsDpvmwJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive'\n",
        "\n",
        "DATA_PATH = Path(file_path + '/datasets/SemEval')\n",
        "\n",
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "if args['use_glove']:\n",
        "  TEXT = data.Field(batch_first=True,\n",
        "                    tokenize=preprocessor,\n",
        "                    use_vocab=True,\n",
        "                    sequential=True)\n",
        "else:\n",
        "  TEXT = data.Field(batch_first = True,\n",
        "                use_vocab = False,\n",
        "                tokenize = tokenize,\n",
        "                preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                init_token = tokenizer.cls_token_id,\n",
        "                eos_token = tokenizer.sep_token_id,\n",
        "                pad_token = tokenizer.pad_token_id,\n",
        "                unk_token = tokenizer.unk_token_id)\n",
        "  \n",
        "LABEL = data.LabelField(sequential = False,\n",
        "                        use_vocab = False,\n",
        "                        pad_token= None,\n",
        "                        unk_token = None, \n",
        "                        dtype = torch.float)\n",
        "\n",
        "dataFields = {\"Tweet\": (\"Tweet\", TEXT),\n",
        "              'anger': (\"anger\", LABEL),\n",
        "              'anticipation': (\"anticipation\", LABEL),\n",
        "              'disgust': (\"disgust\", LABEL),\n",
        "              'fear': (\"fear\", LABEL),\n",
        "              'joy': (\"joy\", LABEL),\n",
        "              'love': (\"love\", LABEL),\n",
        "              'optimism': (\"optimism\", LABEL),\n",
        "              'pessimism': (\"pessimism\", LABEL),\n",
        "              'sadness': (\"sadness\", LABEL),\n",
        "              'surprise': (\"surprise\", LABEL),\n",
        "              'trust': (\"trust\", LABEL)}\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path = DATA_PATH,\n",
        "    train = 'train.csv',\n",
        "    validation = 'val.csv',\n",
        "    test = 'test.csv',\n",
        "    format = 'csv',\n",
        "    fields = dataFields\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYMezWxUvyxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    sort_key = lambda x: len(x.Tweet),\n",
        "    sort_within_batch = True,\n",
        "    batch_size = args['batch_size'],\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRmJtf4xPHxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if args['use_glove']:\n",
        "  TEXT.build_vocab(train_data, vectors=GloVe(name='6B', dim=300), \n",
        "                   max_size=args['max_vocab_size'])\n",
        "  print(f\"\\nUnique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dgYzwnpDhrO",
        "colab_type": "text"
      },
      "source": [
        "# Batch Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEZCExSovoy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLS = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
        "              'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "iaux = 0\n",
        "\n",
        "for batch in valid_iterator:\n",
        "  iaux += 1\n",
        "  aux = batch\n",
        "  aux2 = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "  if aux == 20: break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyMA1ST4DlLN",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77GLQlKxDnAx",
        "colab_type": "text"
      },
      "source": [
        "Load the pretrained bert model from the HuggingFace transformers library.\n",
        "\n",
        "https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRiJ1llOvvxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "96ed6886ded649ac8fbc14b949c087f9",
            "8e8117f2f9b34f1bb04ecc12f04ce178",
            "ee6eb7f835184d4ea999f03f08409c13",
            "6dde02ccb9df4bf8886aa1b452527fcf",
            "bdd01d06298c42129065f83e23bf0f00",
            "bb844cea159f4354a5c9ff8cd2734a76",
            "e2951206768140d89ae58d9c472aaeac",
            "59f824623e6044ce847bbd8fbee1dc0a",
            "d30174863ddc493d8d496db9d11618cb",
            "5cf52412e2f440db83668b042205acab",
            "2c16327170f04e1c86aeedba309dbd1f",
            "c0f6966baf5141ce9596e2eb3e24fd71",
            "6065731c31a74b74bf1dcde0ba9660e8",
            "ca41a14d99a74bd380f9380c6d3ddd06",
            "1c17823b7066422090c9cb23ece1e798",
            "6f0c38295a1a437091eb065b5fbcd014"
          ]
        },
        "outputId": "079ab2b9-592e-4d93-a7e2-b4a253235d4a"
      },
      "source": [
        "bert = BertModel.from_pretrained(args['bert_pretrained_model'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96ed6886ded649ac8fbc14b949c087f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d30174863ddc493d8d496db9d11618cb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toQo8u76tf3I",
        "colab_type": "text"
      },
      "source": [
        "Use model architecture proposed at: https://www.aclweb.org/anthology/P16-2034/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD1MiUiwv29n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(Attention, self).__init__()\n",
        "\n",
        "    self.attention = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, H):\n",
        "    M = torch.tanh(H)\n",
        "    M = self.attention(M).squeeze(2)\n",
        "    alpha = F.softmax(M, dim=1).unsqueeze(1)\n",
        "    return alpha\n",
        "\n",
        "class AttentionBiLSTM(nn.Module):\n",
        "  def __init__(self, hidden_size, num_layers, dropout, fc_dropout, \n",
        "               emb_layer_dropout, num_classes):\n",
        "    super(AttentionBiLSTM, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    if args['use_glove']:\n",
        "      embedding_dim = args['glove_embedding_dim']\n",
        "      self.embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
        "    else:\n",
        "      self.bert = bert\n",
        "      embedding_dim = args['bert_embedding_dim']\n",
        "    \n",
        "    # embedding layer dropout\n",
        "    self.emb_layer_dropout = nn.Dropout(emb_layer_dropout)\n",
        "\n",
        "    # lstm layer\n",
        "    self.lstm = nn.LSTM(embedding_dim, \n",
        "                        hidden_size, \n",
        "                        num_layers, \n",
        "                        dropout=(0 if num_layers==1 else dropout),\n",
        "                        bidirectional=True,\n",
        "                        batch_first=True)\n",
        "    \n",
        "    # penultimate layer\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    self.fc_dropout = nn.Dropout(fc_dropout)\n",
        "    \n",
        "    self.attention = Attention(hidden_size)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    if args['use_glove']:\n",
        "      embedded = self.embedding(text)\n",
        "    else:\n",
        "      with torch.no_grad():\n",
        "        embedded = self.bert(text)[0]\n",
        "\n",
        "    embedded = self.emb_layer_dropout(embedded)\n",
        "    y, _ = self.lstm(embedded)\n",
        "    y = y[:,:,:self.hidden_size] + y[:,:,self.hidden_size:]\n",
        "    alpha = self.attention(y)\n",
        "    r = alpha.bmm(y).squeeze(1)\n",
        "    h = torch.tanh(r)\n",
        "    logits = self.fc(h)\n",
        "    logits = self.fc_dropout(logits)\n",
        "    return logits, alpha "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukvWtx9gxE1d",
        "colab_type": "code",
        "outputId": "ffdd933e-1929-441c-dea4-b47b8157252f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = AttentionBiLSTM(\n",
        "    hidden_size=args['hidden_size'],\n",
        "    num_layers=args['num_layers'],\n",
        "    dropout=args['dropout'],\n",
        "    fc_dropout=args['fc_dropout'],\n",
        "    emb_layer_dropout=args['embed_dropout'],\n",
        "    num_classes=args['output_dim'],\n",
        ")\n",
        "\n",
        "\n",
        "model"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttentionBiLSTM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (emb_layer_dropout): Dropout(p=0.3, inplace=False)\n",
              "  (lstm): LSTM(768, 256, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=11, bias=True)\n",
              "  (fc_dropout): Dropout(p=0.5, inplace=False)\n",
              "  (attention): Attention(\n",
              "    (attention): Linear(in_features=256, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HIm_dK8EbZ2",
        "colab_type": "text"
      },
      "source": [
        "Freeze the parameters which are a part of the Bert Transformers model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4i0FWYtxQ0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if args['use_glove'] is False:\n",
        "  for name, param in model.named_parameters():                \n",
        "      if name.startswith('bert'):\n",
        "          param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC9ZocNzEoDZ",
        "colab_type": "text"
      },
      "source": [
        "Show the trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1af7wW5xYk_",
        "colab_type": "code",
        "outputId": "deaa65e0-4f93-476b-e958-29de1bda81ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lstm.weight_ih_l0\n",
            "lstm.weight_hh_l0\n",
            "lstm.bias_ih_l0\n",
            "lstm.bias_hh_l0\n",
            "lstm.weight_ih_l0_reverse\n",
            "lstm.weight_hh_l0_reverse\n",
            "lstm.bias_ih_l0_reverse\n",
            "lstm.bias_hh_l0_reverse\n",
            "lstm.weight_ih_l1\n",
            "lstm.weight_hh_l1\n",
            "lstm.bias_ih_l1\n",
            "lstm.bias_hh_l1\n",
            "lstm.weight_ih_l1_reverse\n",
            "lstm.weight_hh_l1_reverse\n",
            "lstm.bias_ih_l1_reverse\n",
            "lstm.bias_hh_l1_reverse\n",
            "fc.weight\n",
            "fc.bias\n",
            "attention.attention.weight\n",
            "attention.attention.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLuzW7f4EyrX",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1CpxbIDxcb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwZIAAQmxfxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), weight_decay=args['weight_decay'])\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amV2jA0oE2Rx",
        "colab_type": "text"
      },
      "source": [
        "We evaluate using the Jaccard index and the macro and micro F1's as there are more suitable for multi-label text classification problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxF1sRahxmwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score, jaccard_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YydgwAqkxolz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metricize(preds, y):\n",
        "  f1_macro = f1_score(y, preds.round(), average='macro')\n",
        "  f1_micro = f1_score(y, preds.round(), average='micro')\n",
        "  jaccard = jaccard_score(y, preds.round(), average='samples')\n",
        "\n",
        "  return {\n",
        "      'f1_macro': f1_macro,\n",
        "      'f1_micro': f1_micro,\n",
        "      'jaccard': jaccard,\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLL3mSPZxpkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions, _ = model(batch.Tweet)\n",
        "\n",
        "    batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "    batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "    loss = criterion(predictions, batch_labels)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "    labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  \n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoLaQBVvxrla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "      predictions, _ = model(batch.Tweet)\n",
        "     \n",
        "      batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "      batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "      loss = criterion(predictions, batch_labels)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "      labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list)), preds_list, labels_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO9vUx_1xtXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqaePMLEFP7e",
        "colab_type": "text"
      },
      "source": [
        "We train the model for 10 epochs and record the training and validation loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSBSFoBOxwJn",
        "colab_type": "code",
        "outputId": "c16071e5-9dbd-48f2-b9f0-b182d16c39a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "train_acc = []\n",
        "valid_acc = []\n",
        "\n",
        "for epoch in range(args['epochs']):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_metrics = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_metrics, _, _, = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        if args['use_glove']:\n",
        "          torch.save(model.state_dict(), 'glove-lstm-model.pt')\n",
        "        else:\n",
        "          torch.save(model.state_dict(), 'bert-lstm-model.pt')\n",
        "        \n",
        "    train_jaccard = train_metrics['jaccard']\n",
        "    train_micro = train_metrics['f1_micro']\n",
        "    train_macro = train_metrics['f1_macro']\n",
        "\n",
        "    valid_jaccard = valid_metrics['jaccard']\n",
        "    valid_micro = valid_metrics['f1_micro']\n",
        "    valid_macro = valid_metrics['f1_macro']\n",
        "\n",
        "    train_acc.append(train_jaccard)\n",
        "    valid_acc.append(valid_jaccard)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Jaccard: {train_jaccard*100:.2f}% | Train F1 Micro: {train_micro*100:.2f}% | Train F1 Macro: {train_macro*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} | Val. Jaccard: {valid_jaccard*100:.2f}%  | Val. F1 Micro: {valid_micro*100:.2f}%  | Val. F1 Macro: {valid_macro*100:.2f}%')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.547 | Train Jaccard: 17.78% | Train F1 Micro: 29.09% | Train F1 Macro: 18.01%\n",
            "\t Val. Loss: 0.391 | Val. Jaccard: 47.10%  | Val. F1 Micro: 59.97%  | Val. F1 Macro: 37.22%\n",
            "Epoch: 02 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 0.520 | Train Jaccard: 24.08% | Train F1 Micro: 37.03% | Train F1 Macro: 25.01%\n",
            "\t Val. Loss: 0.388 | Val. Jaccard: 49.65%  | Val. F1 Micro: 62.32%  | Val. F1 Macro: 38.07%\n",
            "Epoch: 03 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.511 | Train Jaccard: 25.29% | Train F1 Micro: 38.56% | Train F1 Macro: 27.23%\n",
            "\t Val. Loss: 0.379 | Val. Jaccard: 52.59%  | Val. F1 Micro: 64.68%  | Val. F1 Macro: 46.02%\n",
            "Epoch: 04 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.506 | Train Jaccard: 25.75% | Train F1 Micro: 39.18% | Train F1 Macro: 27.82%\n",
            "\t Val. Loss: 0.366 | Val. Jaccard: 51.89%  | Val. F1 Micro: 64.42%  | Val. F1 Macro: 44.06%\n",
            "Epoch: 05 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.504 | Train Jaccard: 26.06% | Train F1 Micro: 39.83% | Train F1 Macro: 28.51%\n",
            "\t Val. Loss: 0.357 | Val. Jaccard: 54.89%  | Val. F1 Micro: 67.33%  | Val. F1 Macro: 49.35%\n",
            "Epoch: 06 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.502 | Train Jaccard: 27.55% | Train F1 Micro: 41.46% | Train F1 Macro: 30.46%\n",
            "\t Val. Loss: 0.367 | Val. Jaccard: 53.49%  | Val. F1 Micro: 66.29%  | Val. F1 Macro: 48.75%\n",
            "Epoch: 07 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.497 | Train Jaccard: 27.67% | Train F1 Micro: 41.69% | Train F1 Macro: 31.00%\n",
            "\t Val. Loss: 0.357 | Val. Jaccard: 54.05%  | Val. F1 Micro: 66.75%  | Val. F1 Macro: 50.53%\n",
            "Epoch: 08 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.495 | Train Jaccard: 27.45% | Train F1 Micro: 41.51% | Train F1 Macro: 30.87%\n",
            "\t Val. Loss: 0.354 | Val. Jaccard: 53.83%  | Val. F1 Micro: 66.33%  | Val. F1 Macro: 49.10%\n",
            "Epoch: 09 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.495 | Train Jaccard: 27.78% | Train F1 Micro: 41.97% | Train F1 Macro: 31.87%\n",
            "\t Val. Loss: 0.367 | Val. Jaccard: 54.42%  | Val. F1 Micro: 66.37%  | Val. F1 Macro: 49.93%\n",
            "Epoch: 10 | Epoch Time: 0m 21s\n",
            "\tTrain Loss: 0.490 | Train Jaccard: 28.83% | Train F1 Micro: 43.61% | Train F1 Macro: 33.16%\n",
            "\t Val. Loss: 0.350 | Val. Jaccard: 52.61%  | Val. F1 Micro: 64.98%  | Val. F1 Macro: 48.98%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqXexw71GcWj",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the training and validation loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CePfv7_0An7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgUKd4HR6Tg-",
        "colab_type": "code",
        "outputId": "0e5283bf-eeda-4286-d166-d433933ed93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plt.plot(train_losses)\n",
        "plt.plot(valid_losses)\n",
        "# plt.title('Attention LSTM (GloVe) Training & Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Training', 'Validation'])\n",
        "\n",
        "# plt.savefig('attn-lstm-glove', dpi=300)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0370202240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSlSdy6ALwj4",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the training and validation jaccard accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qDGgLbPL29w",
        "colab_type": "code",
        "outputId": "951f788a-ae9b-4770-e593-66439585965b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "plt.plot(train_acc)\n",
        "plt.plot(valid_acc)\n",
        "# plt.title('Attention LSTM (GloVe) Training & Validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Jaccard')\n",
        "plt.legend(['Training', 'Validation'])\n",
        "# plt.savefig('attn-lstm-acc-glove', dpi=300)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f03700fdb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtOPAqB1GkB5",
        "colab_type": "text"
      },
      "source": [
        "# Assess model performance on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TxQGreq6Vgm",
        "colab_type": "code",
        "outputId": "2b775a1f-4cf2-4205-923e-831031497bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "if (args['use_glove']):\n",
        "  model.load_state_dict(torch.load('glove-lstm-model.pt'))\n",
        "else:\n",
        "  model.load_state_dict(torch.load('bert-lstm-model.pt'))\n",
        "\n",
        "\n",
        "test_loss, test_metrics, preds_list, labels_list = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "test_jaccard = test_metrics['jaccard']\n",
        "test_micro = test_metrics['f1_micro']\n",
        "test_macro = test_metrics['f1_macro']\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Jaccard: {test_jaccard*100:.2f}% | Test F1 Micro: {test_micro*100:.2f}% | Test F1 Macro: {test_macro*100:.2f}%')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.349 | Test Jaccard: 52.61% | Test F1 Micro: 65.44% | Test F1 Macro: 48.57%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJd_FzO4o_AK",
        "colab_type": "text"
      },
      "source": [
        "# Confusion matrix & Classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXLsnO9-kFcf",
        "colab_type": "code",
        "outputId": "4e8ffcc2-c9ff-447f-a131-45b8fa315724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        }
      },
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
        "\n",
        "conf_matrix = multilabel_confusion_matrix(np.vstack(labels_list), np.vstack(preds_list).round())\n",
        "print(conf_matrix)\n",
        "\n",
        "cm = classification_report(np.vstack(labels_list), np.vstack(preds_list).round())\n",
        "print(cm)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[1995  163]\n",
            "  [ 386  715]]\n",
            "\n",
            " [[2823   11]\n",
            "  [ 417    8]]\n",
            "\n",
            " [[1849  311]\n",
            "  [ 299  800]]\n",
            "\n",
            " [[2714   60]\n",
            "  [ 200  285]]\n",
            "\n",
            " [[1697  120]\n",
            "  [ 425 1017]]\n",
            "\n",
            " [[2695   48]\n",
            "  [ 346  170]]\n",
            "\n",
            " [[1806  310]\n",
            "  [ 346  797]]\n",
            "\n",
            " [[2704  180]\n",
            "  [ 251  124]]\n",
            "\n",
            " [[2008  291]\n",
            "  [ 322  638]]\n",
            "\n",
            " [[3081    8]\n",
            "  [ 162    8]]\n",
            "\n",
            " [[3081   25]\n",
            "  [ 145    8]]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.65      0.72      1101\n",
            "           1       0.42      0.02      0.04       425\n",
            "           2       0.72      0.73      0.72      1099\n",
            "           3       0.83      0.59      0.69       485\n",
            "           4       0.89      0.71      0.79      1442\n",
            "           5       0.78      0.33      0.46       516\n",
            "           6       0.72      0.70      0.71      1143\n",
            "           7       0.41      0.33      0.37       375\n",
            "           8       0.69      0.66      0.68       960\n",
            "           9       0.50      0.05      0.09       170\n",
            "          10       0.24      0.05      0.09       153\n",
            "\n",
            "   micro avg       0.75      0.58      0.65      7869\n",
            "   macro avg       0.64      0.44      0.49      7869\n",
            "weighted avg       0.73      0.58      0.63      7869\n",
            " samples avg       0.71      0.60      0.62      7869\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaJzLdwb6exr",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ6W1Xpq6aO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_emotion(model, tokenizer, tweet):\n",
        "  preds = []\n",
        "  model.eval()\n",
        "\n",
        "  if args['use_glove']:\n",
        "    tokenized = preprocessor(tweet)\n",
        "    indexed = [TEXT.vocab.stoi[token] for token in tokenized]\n",
        "  else:\n",
        "    tokens = tokenizer.tokenize(tweet)\n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    indexed = [tokenizer.cls_token_id] + tokenizer.convert_tokens_to_ids(tokens) + [tokenizer.sep_token_id]\n",
        "\n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  predictions, attn_weights = model(tensor)\n",
        "  preds.append(torch.sigmoid(predictions).detach().cpu().numpy())\n",
        "\n",
        "  if args['use_glove']:\n",
        "    return preds, attn_weights, tokenized\n",
        "  else:\n",
        "    return preds, attn_weights, tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL9EtxTrG7My",
        "colab_type": "text"
      },
      "source": [
        "Lets test the model on our own input and save the attention weights and tokens for visualization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eecw3IVA6lVH",
        "colab_type": "code",
        "outputId": "54f6549c-3012-47d6-d334-8ac7900ae46a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "text = \"Good music I love that shit\"\n",
        "\n",
        "preds, attn_weights, tokens = predict_emotion(model, tokenizer, text)\n",
        "\n",
        "pred_values = []\n",
        "for p in preds[0]:\n",
        "  for val in p:\n",
        "    pred_values.append(val)\n",
        "\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "  print(f\"{label.upper()}: {pred_values[i]}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANGER: 0.2750973701477051\n",
            "ANTICIPATION: 0.09163666516542435\n",
            "DISGUST: 0.23599089682102203\n",
            "FEAR: 0.08520322293043137\n",
            "JOY: 0.8124440312385559\n",
            "LOVE: 0.5685871243476868\n",
            "OPTIMISM: 0.4813237190246582\n",
            "PESSIMISM: 0.07168387621641159\n",
            "SADNESS: 0.1267954409122467\n",
            "SURPRISE: 0.06157056242227554\n",
            "TRUST: 0.21020734310150146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jeDWh8KHbEG",
        "colab_type": "text"
      },
      "source": [
        "Here we format the attention weights and store the results in a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q71LaaAn6oBA",
        "colab_type": "code",
        "outputId": "cc6e4dab-3a8c-4b08-b055-1ab69f8abbdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "attention_weights = []\n",
        "for aw in attn_weights[0]:\n",
        "  for v in aw:\n",
        "    attention_weights.append(v.detach().cpu().numpy())\n",
        "\n",
        "if args['use_glove']:\n",
        "  attention_weights = np.array(attention_weights)\n",
        "else:\n",
        "  attention_weights = attention_weights[1:-1]\n",
        "  attention_weights = np.array(attention_weights)\n",
        "\n",
        "attention_weights"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.11197709, 0.03706481, 0.02968199, 0.73123264, 0.03549661,\n",
              "       0.04749265], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnrDFOGy9DLx",
        "colab_type": "code",
        "outputId": "6f416a67-7576-4fe3-9199-a86757d9dec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attn_dict = {}\n",
        "for i in range(len(attention_weights)):\n",
        "  attn_dict[tokens[i]] = attention_weights[i]\n",
        "\n",
        "print(attn_dict)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'good': 0.111977085, 'music': 0.037064806, 'i': 0.029681988, 'love': 0.73123264, 'that': 0.035496615, 'shit': 0.047492653}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tomju0TvHp8z",
        "colab_type": "text"
      },
      "source": [
        "Lets return the top 3 words that the model focused on. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skdcPb0g-nQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LqBqNKVCqan",
        "colab_type": "code",
        "outputId": "ef186a42-8bea-40c7-9711-f64eaefea0ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "weight_counter = Counter(attn_dict)\n",
        "print(weight_counter)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'love': 0.73123264, 'good': 0.111977085, 'shit': 0.047492653, 'music': 0.037064806, 'that': 0.035496615, 'i': 0.029681988})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOynkS19gB9l",
        "colab_type": "text"
      },
      "source": [
        "# Model performance on longer text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaT0o3fUhjzF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVRBt8P0H4Ur",
        "colab_type": "code",
        "outputId": "15512f3e-8959-4f13-85b6-36f74bd15a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "text_1 = (\n",
        "    \"I'm only 24, and have worked part time jobs since I graduated from college.\" \n",
        "    \" With everything going on, I've been furloughed from both of my part time jobs.\"\n",
        "    \" Well one offered me full time, and I was able to negotiate the salary up a full dollar per hour! And it has benefits and everything!\" \n",
        "    \" I know it's not a big deal but I'm just so excited and can't really tell anyone\"\n",
        "    \" especially as I haven't spoken to my other part time job yet. Just hoping everything works out well, and that I have money for grad school in the fall!\"\n",
        ")\n",
        "\n",
        "text_2 = (\n",
        "    \"I worked my ass off to graduate with my Bachelor's in 3 years.\"\n",
        "    \"My family hasn't said a word to me about it. No 'Congrats'! or 'I'm proud of you!'.\"\n",
        "    \"And it's not like they don't know. I live with them. I got my cap & gown in the mail last week and one my\"\n",
        "    \" professors snet me a graduation card. They were there for all of it. Still, not a single word about it.\"\n",
        "    \" I know this is a weird time, but I don't think that's an excuse to ignore your daughter's life achievements.\"\n",
        "    \" I feel so under-appreciated. I just want them to tell me they're proud. What kind of parent doesn't do that?\"\n",
        "    \" I'm 20 years old with a Bachelor of Science in Information Technology. I deserve a pat on the back.\"\n",
        "    \" This really sucks.\"\n",
        ")\n",
        "\n",
        "preds, attn_weights, tokens = predict_emotion(model, tokenizer, text_2)\n",
        "\n",
        "pred_values = []\n",
        "for p in preds[0]:\n",
        "  for val in p:\n",
        "    pred_values.append(val)\n",
        "\n",
        "# print(os.linesep.join([\"I'm only 24, and have worked part time jobs since I graduated from college.\", \n",
        "#                        \"With everything going on, I've been furloughed from both of my part time jobs.\",\n",
        "#                        \"Well one offered me full time, and I was able to negotiate the salary up a full dollar per hour!\", \n",
        "#                        \"And it has benefits and everything! I know it's not a big deal but I'm just so excited and\", \n",
        "#                        \"can't really tell anyone, especially as I haven't spoken to my other part time job yet.\", \n",
        "#                        \"Just hoping everything works out well, and that I have money for grad school in the fall!\"]))\n",
        "\n",
        "print(os.linesep.join([\"I worked my ass off to graduate with my Bachelor's in 3 years.\", \n",
        "                      \"My family hasn't said a word to me about it. No 'Congrats'! or 'I'm proud of you!'.\",\n",
        "                      \"And it's not like they don't know. I live with them. I got my cap & gown in the mail last week and one my\",\n",
        "                      \"professors snet me a graduation card. They were there for all of it. Still, not a single word about it.\",\n",
        "                      \"I know this is a weird time, but I don't think that's an excuse to ignore your daughter's life achievements.\",\n",
        "                      \"I feel so under-appreciated. I just want them to tell me they're proud. What kind of parent doesn't do that?\",\n",
        "                      \"I'm 20 years old with a Bachelor of Science in Information Technology. I deserve a pat on the back.\",\n",
        "                      \"This really sucks.\"]))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Text length: 138 words\")\n",
        "\n",
        "print()\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "  print(f\"{label.upper()}: {pred_values[i]:.2f}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I worked my ass off to graduate with my Bachelor's in 3 years.\n",
            "My family hasn't said a word to me about it. No 'Congrats'! or 'I'm proud of you!'.\n",
            "And it's not like they don't know. I live with them. I got my cap & gown in the mail last week and one my\n",
            "professors snet me a graduation card. They were there for all of it. Still, not a single word about it.\n",
            "I know this is a weird time, but I don't think that's an excuse to ignore your daughter's life achievements.\n",
            "I feel so under-appreciated. I just want them to tell me they're proud. What kind of parent doesn't do that?\n",
            "I'm 20 years old with a Bachelor of Science in Information Technology. I deserve a pat on the back.\n",
            "This really sucks.\n",
            "\n",
            "Text length: 138 words\n",
            "\n",
            "ANGER: 0.32\n",
            "ANTICIPATION: 0.15\n",
            "DISGUST: 0.42\n",
            "FEAR: 0.21\n",
            "JOY: 0.30\n",
            "LOVE: 0.13\n",
            "OPTIMISM: 0.37\n",
            "PESSIMISM: 0.38\n",
            "SADNESS: 0.62\n",
            "SURPRISE: 0.10\n",
            "TRUST: 0.13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ2uiaY8b0qS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}