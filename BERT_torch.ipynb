{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-torch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXOl6pMKaE+gM7UiShvef6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/BERT_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_svLHoq91gv6",
        "colab_type": "text"
      },
      "source": [
        "# Detecting Emotions from Tweets with BERT "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjqbblbR2JTC",
        "colab_type": "text"
      },
      "source": [
        "First we need to install the transformers python package to get access to the pre-trained BERT models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BSjxdQA1su-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install fast-bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_rH13oCtAfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from box import Box\n",
        "from tqdm import tqdm, trange\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import pandas as pd \n",
        "import collections \n",
        "import random\n",
        "import numpy as np\n",
        "import apex\n",
        "\n",
        "import logging\n",
        "import datetime\n",
        "\n",
        "from fast_bert.modeling import BertForMultiLabelSequenceClassification\n",
        "from fast_bert.data_cls import BertDataBunch, InputExample, InputFeatures, MultiLabelTextProcessor, convert_examples_to_features\n",
        "from fast_bert.learner_cls import BertLearner\n",
        "from fast_bert.metrics import accuracy_multilabel, accuracy_thresh, fbeta, roc_auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT1oNHtY1-LS",
        "colab_type": "code",
        "outputId": "308117d5-60a2-4ced-e024-01cfd284ee76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4y7FYGtxvPia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
        "                    level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-C-TV4ctZHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30AoP3XJtdPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_start_time = datetime.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJl-eJCYufXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/'\n",
        "\n",
        "DATA_PATH = Path(path + '/datasets/SemEval/')\n",
        "LABEL_PATH = Path(path + '/labels/')\n",
        "\n",
        "MODEL_PATH = Path(path + '/models/')\n",
        "LOG_PATH = Path(path + '/logs/')\n",
        "\n",
        "MODEL_PATH.mkdir(exist_ok=True)\n",
        "LOG_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "BERT_PRETRAINED_PATH = Path(path + '/BERT/')\n",
        "\n",
        "OUTPUT_PATH = Path(MODEL_PATH/'output')\n",
        "OUTPUT_PATH.mkdir(exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAydZmDxvZEs",
        "colab_type": "text"
      },
      "source": [
        "# GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5klrCsFrvaSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3cECmVCu0Sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_cols = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
        "              'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js_JCegoB9Dn",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbAlkfx3vlVc",
        "colab_type": "code",
        "outputId": "390d71c9-f879-46b1-be44-55239188fab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "databunch = BertDataBunch(DATA_PATH, \n",
        "                          LABEL_PATH,\n",
        "                          tokenizer='bert-base-uncased',\n",
        "                          train_file='train.csv',\n",
        "                          val_file='val.csv',\n",
        "                          test_data='test.csv',\n",
        "                          label_file='labels.csv',\n",
        "                          text_col=\"Tweet\",\n",
        "                          label_col=label_cols,\n",
        "                          batch_size_per_gpu=16,\n",
        "                          max_seq_length=128,\n",
        "                          multi_gpu=True,\n",
        "                          multi_label=True,\n",
        "                          model_type='bert')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/16/2020 22:00:38 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "01/16/2020 22:00:38 - INFO - root -   Loading features from cached file /content/drive/My Drive/datasets/SemEval/cache/cached_bert_train_multi_label_128_train.csv\n",
            "01/16/2020 22:00:38 - INFO - root -   Loading features from cached file /content/drive/My Drive/datasets/SemEval/cache/cached_bert_dev_multi_label_128_val.csv\n",
            "01/16/2020 22:00:38 - INFO - root -   Loading features from cached file /content/drive/My Drive/datasets/SemEval/cache/cached_bert_test_multi_label_128_test\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc7YDDBiPTLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff7c890f-0ea7-4d8c-e261-f2ad84be739a"
      },
      "source": [
        "databunch.train_dl.dataset[0][3]"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kJDhMBnPp1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c69c73b5-60b1-4424-99da-6b75ecc25c52"
      },
      "source": [
        "num_labels = len(databunch.labels)\n",
        "num_labels"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj1upzMtPtPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics = []\n",
        "metrics.append({'name': 'accuracy_thresh', 'function': accuracy_thresh})\n",
        "metrics.append({'name': 'roc_auc', 'function': roc_auc})\n",
        "metrics.append({'name': 'fbeta', 'function': fbeta})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUyFd9rLP4ie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "b8ae1e4c-9971-4495-a383-b762b13049fd"
      },
      "source": [
        "learner = BertLearner.from_pretrained_model(\n",
        "    databunch, \n",
        "    pretrained_path='bert-base-uncased',\n",
        "    metrics=metrics,\n",
        "    device=device,\n",
        "    logger=logger,\n",
        "    output_dir=OUTPUT_PATH,\n",
        "    finetuned_wgts_path=None,\n",
        "    warmup_steps=500,\n",
        "    multi_gpu=True,\n",
        "    is_fp16=False,\n",
        "    multi_label=True,\n",
        "    logging_steps=0)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/16/2020 22:00:45 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
            "01/16/2020 22:00:45 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 11,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "01/16/2020 22:00:45 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "bert-base-uncased\n",
            "<class 'str'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "01/16/2020 22:00:47 - INFO - transformers.modeling_utils -   Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "01/16/2020 22:00:47 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-F9yRXfQt2X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c6c09c6-c6de-424b-c5d5-c3481a61644a"
      },
      "source": [
        "num_epochs = 4\n",
        "learning_rate = 6e-5\n",
        "\n",
        "learner.fit(num_epochs, \n",
        "            learning_rate, \n",
        "            schedule_type=\"warmup_cosine\",\n",
        "            optimizer_type=\"lamb\",\n",
        "            validate=True)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/16/2020 22:00:51 - INFO - __main__ -   ***** Running training *****\n",
            "01/16/2020 22:00:51 - INFO - __main__ -     Num examples = 6838\n",
            "01/16/2020 22:00:51 - INFO - __main__ -     Num Epochs = 4\n",
            "01/16/2020 22:00:51 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "01/16/2020 22:00:51 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "01/16/2020 22:00:51 - INFO - __main__ -     Total optimization steps = 1712\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "01/16/2020 22:04:11 - INFO - __main__ -   Running evaluation\n",
            "01/16/2020 22:04:11 - INFO - __main__ -     Num examples = 886\n",
            "01/16/2020 22:04:11 - INFO - __main__ -     Batch size = 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='28' class='' max='28', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [28/28 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "01/16/2020 22:04:19 - INFO - __main__ -   eval_loss after epoch 1: 0.5360515330518995: \n",
            "01/16/2020 22:04:19 - INFO - __main__ -   eval_accuracy_thresh after epoch 1: 0.7782679796218872: \n",
            "01/16/2020 22:04:19 - INFO - __main__ -   eval_roc_auc after epoch 1: 0.7060729593375952: \n",
            "01/16/2020 22:04:19 - INFO - __main__ -   eval_fbeta after epoch 1: 0.5877101421356201: \n",
            "01/16/2020 22:04:19 - INFO - __main__ -   lr after epoch 1: 5.136e-05\n",
            "01/16/2020 22:04:19 - INFO - __main__ -   train_loss after epoch 1: 0.60032088901395\n",
            "01/16/2020 22:04:19 - INFO - __main__ -   \n",
            "\n",
            "01/16/2020 22:07:38 - INFO - __main__ -   Running evaluation\n",
            "01/16/2020 22:07:38 - INFO - __main__ -     Num examples = 886\n",
            "01/16/2020 22:07:38 - INFO - __main__ -     Batch size = 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='28' class='' max='28', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [28/28 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "01/16/2020 22:07:45 - INFO - __main__ -   eval_loss after epoch 2: 0.4469392778617995: \n",
            "01/16/2020 22:07:45 - INFO - __main__ -   eval_accuracy_thresh after epoch 2: 0.8047403693199158: \n",
            "01/16/2020 22:07:45 - INFO - __main__ -   eval_roc_auc after epoch 2: 0.8036134666285568: \n",
            "01/16/2020 22:07:45 - INFO - __main__ -   eval_fbeta after epoch 2: 0.6121078729629517: \n",
            "01/16/2020 22:07:45 - INFO - __main__ -   lr after epoch 2: 4.8108228255680444e-05\n",
            "01/16/2020 22:07:45 - INFO - __main__ -   train_loss after epoch 2: 0.4875621260883652\n",
            "01/16/2020 22:07:45 - INFO - __main__ -   \n",
            "\n",
            "01/16/2020 22:11:04 - INFO - __main__ -   Running evaluation\n",
            "01/16/2020 22:11:04 - INFO - __main__ -     Num examples = 886\n",
            "01/16/2020 22:11:04 - INFO - __main__ -     Batch size = 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='28' class='' max='28', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [28/28 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "01/16/2020 22:11:12 - INFO - __main__ -   eval_loss after epoch 3: 0.40796645092112677: \n",
            "01/16/2020 22:11:12 - INFO - __main__ -   eval_accuracy_thresh after epoch 3: 0.8391134738922119: \n",
            "01/16/2020 22:11:12 - INFO - __main__ -   eval_roc_auc after epoch 3: 0.8364070077910779: \n",
            "01/16/2020 22:11:12 - INFO - __main__ -   eval_fbeta after epoch 3: 0.6505194902420044: \n",
            "01/16/2020 22:11:12 - INFO - __main__ -   lr after epoch 3: 1.664423060378799e-05\n",
            "01/16/2020 22:11:12 - INFO - __main__ -   train_loss after epoch 3: 0.4323560443019199\n",
            "01/16/2020 22:11:12 - INFO - __main__ -   \n",
            "\n",
            "01/16/2020 22:14:31 - INFO - __main__ -   Running evaluation\n",
            "01/16/2020 22:14:31 - INFO - __main__ -     Num examples = 886\n",
            "01/16/2020 22:14:31 - INFO - __main__ -     Batch size = 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='28' class='' max='28', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [28/28 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "01/16/2020 22:14:39 - INFO - __main__ -   eval_loss after epoch 4: 0.4019217299563544: \n",
            "01/16/2020 22:14:39 - INFO - __main__ -   eval_accuracy_thresh after epoch 4: 0.8439359664916992: \n",
            "01/16/2020 22:14:39 - INFO - __main__ -   eval_roc_auc after epoch 4: 0.8416226770669722: \n",
            "01/16/2020 22:14:39 - INFO - __main__ -   eval_fbeta after epoch 4: 0.6489752531051636: \n",
            "01/16/2020 22:14:39 - INFO - __main__ -   lr after epoch 4: 0.0\n",
            "01/16/2020 22:14:39 - INFO - __main__ -   train_loss after epoch 4: 0.41246818953028347\n",
            "01/16/2020 22:14:39 - INFO - __main__ -   \n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1712, 0.4831768122336296)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t27zqW8UXC20",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e9f395ab-e386-42b0-ddf3-0bd6df9a4e64"
      },
      "source": [
        "learner.save_model()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/16/2020 22:15:04 - INFO - transformers.configuration_utils -   Configuration saved in /content/drive/My Drive/models/output/model_out/config.json\n",
            "01/16/2020 22:15:05 - INFO - transformers.modeling_utils -   Model weights saved in /content/drive/My Drive/models/output/model_out/pytorch_model.bin\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsUMQphuWCxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fast_bert.prediction import BertClassificationPredictor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weKo0o4lWGNQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "outputId": "2caa608e-d75d-4dc0-a1ba-96c8491fd47b"
      },
      "source": [
        "MODEL_PATH = OUTPUT_PATH/'model_out'\n",
        "\n",
        "predictor = BertClassificationPredictor(model_path=MODEL_PATH, \n",
        "                                        label_path=LABEL_PATH,\n",
        "                                        multi_label=True,\n",
        "                                        model_type='bert',\n",
        "                                        do_lower_case=True)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/16/2020 22:15:08 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/models/output/model_out' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming '/content/drive/My Drive/models/output/model_out' is a path or url to a directory containing tokenizer files.\n",
            "01/16/2020 22:15:08 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/models/output/model_out/vocab.txt\n",
            "01/16/2020 22:15:08 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/models/output/model_out/added_tokens.json\n",
            "01/16/2020 22:15:08 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/models/output/model_out/special_tokens_map.json\n",
            "01/16/2020 22:15:08 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/models/output/model_out/tokenizer_config.json\n",
            "01/16/2020 22:15:08 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/models/output/model_out/config.json\n",
            "01/16/2020 22:15:08 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 11,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "01/16/2020 22:15:08 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/models/output/model_out/pytorch_model.bin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/models/output/model_out\n",
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlIb8nFTWg1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a65744d-a2a3-475b-911a-a87342195369"
      },
      "source": [
        "single_pred = predictor.predict(\"I am so thankful for everything.\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/16/2020 22:16:45 - INFO - root -   Writing example 0 of 1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpMefoL5XTCE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "8de92108-2795-451a-a024-32d7e3b0f436"
      },
      "source": [
        "single_pred"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('joy', 0.613877534866333),\n",
              " ('optimism', 0.5743357539176941),\n",
              " ('sadness', 0.2809685468673706),\n",
              " ('love', 0.24984759092330933),\n",
              " ('fear', 0.24792851507663727),\n",
              " ('disgust', 0.23301798105239868),\n",
              " ('anticipation', 0.2312241792678833),\n",
              " ('anger', 0.22087150812149048),\n",
              " ('pessimism', 0.16349482536315918),\n",
              " ('trust', 0.14730584621429443),\n",
              " ('surprise', 0.1007944643497467)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hGsq39mXVzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}