{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1wbjptVje2AIFjs_Ry-rSGAqq0ptO3dmI",
      "authorship_tag": "ABX9TyOqc2fFnJ2MfSYMOiYpQh+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/Text_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owG-IxGmt6PT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms-rycQV38iF",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N2UGYjytpuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import re\n",
        "import transformers\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from pathlib import Path\n",
        "from torchtext import data\n",
        "from torchtext.vocab import GloVe\n",
        "from transformers import BertModel, BertTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3-e1jPqoJnc",
        "colab_type": "text"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0j_RCS0oLhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    \"bert_tokenizer\": \"bert-base-uncased\",\n",
        "    \"bert_model\": \"bert-base-uncased\",\n",
        "    \"seed\": 1234,\n",
        "    \"bert_embedding_dim\": 768,\n",
        "    \"use_glove\": False,\n",
        "    \"glove_embedding_dim\": 300,\n",
        "    \"max_vocab_size\": 20000,\n",
        "    \"batch_size\": 10,\n",
        "    \"num_filters\": 100,\n",
        "    \"filter_sizes\": [1, 1, 1],\n",
        "    \"output_dim\": 11,\n",
        "    \"dropout\": 0.5,\n",
        "    \"epochs\": 10\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33sYCYkYHX-S",
        "colab_type": "text"
      },
      "source": [
        "# Text pre-processor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dX9J0mqXHZxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessor(text):\n",
        "  text = re.sub('<[^>]*>', '', text)\n",
        "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
        "  text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
        "          ' '.join(emoticons).replace('-', '')) \n",
        "  return text.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTPBR-lIovsI",
        "colab_type": "text"
      },
      "source": [
        "# Setup Bert Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRR5RJneu1sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(args['bert_model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yUzVdafvcpC",
        "colab_type": "code",
        "outputId": "117ca321-be20-4f54-8a60-480445db263c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes[args['bert_model']]\n",
        "\n",
        "print(max_input_length)"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFcQHuR1Rhe9",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Jx93Gzou92U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def tokenize(tweet):\n",
        "  tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens[:max_input_length-2]\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdXOgr6bo_si",
        "colab_type": "text"
      },
      "source": [
        "# Load & Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwTeWoXTukDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive'\n",
        "\n",
        "DATA_PATH = Path(file_path + '/datasets/SemEval')\n",
        "\n",
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "if args['use_glove']:\n",
        "  TEXT = data.Field(batch_first=True,\n",
        "                    tokenize=preprocessor,\n",
        "                    use_vocab=True,\n",
        "                    sequential=True)\n",
        "\n",
        "else:\n",
        "  TEXT = data.Field(batch_first = True,\n",
        "                    use_vocab = False,\n",
        "                    tokenize = tokenize,\n",
        "                    preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                    init_token = tokenizer.cls_token_id,\n",
        "                    eos_token = tokenizer.sep_token_id,\n",
        "                    pad_token = tokenizer.pad_token_id,\n",
        "                    unk_token = tokenizer.unk_token_id)\n",
        "\n",
        "LABEL = data.LabelField(sequential = False,\n",
        "                        use_vocab = False,\n",
        "                        pad_token= None,\n",
        "                        unk_token = None, \n",
        "                        dtype = torch.float)\n",
        "\n",
        "dataFields = {\"Tweet\": (\"Tweet\", TEXT),\n",
        "              'anger': (\"anger\", LABEL),\n",
        "              'anticipation': (\"anticipation\", LABEL),\n",
        "              'disgust': (\"disgust\", LABEL),\n",
        "              'fear': (\"fear\", LABEL),\n",
        "              'joy': (\"joy\", LABEL),\n",
        "              'love': (\"love\", LABEL),\n",
        "              'optimism': (\"optimism\", LABEL),\n",
        "              'pessimism': (\"pessimism\", LABEL),\n",
        "              'sadness': (\"sadness\", LABEL),\n",
        "              'surprise': (\"surprise\", LABEL),\n",
        "              'trust': (\"trust\", LABEL)}\n",
        "\n",
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path = DATA_PATH,\n",
        "    train = 'train.csv',\n",
        "    validation = 'val.csv',\n",
        "    test = 'test.csv',\n",
        "    format = 'csv',\n",
        "    fields = dataFields\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz15EhbHwlTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    sort_key = lambda x: len(x.Tweet),\n",
        "    sort_within_batch = True,\n",
        "    batch_size = args['batch_size'],\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3yp2Fo8N7VG",
        "colab_type": "text"
      },
      "source": [
        "# Load GloVe vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDvwEZTlN62N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if args['use_glove']:\n",
        "  TEXT.build_vocab(train_data, vectors=GloVe(name='6B', dim=300), \n",
        "                   max_size=args['max_vocab_size'])\n",
        "  print(f\"\\nUnique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf0eDnfJxEmF",
        "colab_type": "text"
      },
      "source": [
        "# Setup Batch Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J749TkJ-Hth_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLS = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
        "              'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "iaux = 0\n",
        "\n",
        "for batch in valid_iterator:\n",
        "  iaux += 1\n",
        "  aux = batch\n",
        "  aux2 = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "  if aux == 20: break;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdVG6iO5xYSL",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQqcoCie6DK4",
        "colab_type": "text"
      },
      "source": [
        "Load the pretrained bert model from the HuggingFace transformers library.\n",
        "\n",
        "https://github.com/huggingface/transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Os2Jg6dxcHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = BertModel.from_pretrained(args['bert_model'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_wMObU94q7p",
        "colab_type": "text"
      },
      "source": [
        "We use the pre-trained bert transformer model to produce embeddings which are then fed into the TextCNN architecture proposed by Yoon Kim at: https://arxiv.org/abs/1408.5882"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe2-uC23xxhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextCNN(nn.Module):\n",
        "  def __init__(self, n_filters, filter_sizes, output_dim, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    if args['use_glove']:\n",
        "      embedding_dim = args['glove_embedding_dim']\n",
        "      self.embedding = nn.Embedding(len(TEXT.vocab), embedding_dim)\n",
        "    else: \n",
        "      self.bert = bert \n",
        "      embedding_dim = 768\n",
        "\n",
        "    self.convs = nn.ModuleList([\n",
        "                                nn.Conv2d(in_channels = 1,\n",
        "                                          out_channels = n_filters,\n",
        "                                          kernel_size = (fs, embedding_dim)) \n",
        "                                for fs in filter_sizes])\n",
        "    \n",
        "    self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, text):\n",
        "    if args['use_glove']:\n",
        "      embedded = self.embedding(text)\n",
        "    else:\n",
        "      with torch.no_grad():\n",
        "        embedded = self.bert(text)[0]\n",
        "    \n",
        "    embedded = embedded.unsqueeze(1)\n",
        "    \n",
        "    conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "    \n",
        "    cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "    \n",
        "    return self.fc(cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BjxJgdC0umb",
        "colab_type": "code",
        "outputId": "fd3cc24b-87cb-423b-93b7-c6748a4d010b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = TextCNN(n_filters=args['num_filters'], \n",
        "                # filter_sizes=[1,1,1] if args['use_glove'] else args['filter_sizes'],\n",
        "                filter_sizes=args['filter_sizes'],\n",
        "                output_dim=args['output_dim'], \n",
        "                dropout=args['dropout'])\n",
        "\n",
        "model"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextCNN(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv2d(1, 100, kernel_size=(1, 768), stride=(1, 1))\n",
              "    (1): Conv2d(1, 100, kernel_size=(1, 768), stride=(1, 1))\n",
              "    (2): Conv2d(1, 100, kernel_size=(1, 768), stride=(1, 1))\n",
              "  )\n",
              "  (fc): Linear(in_features=300, out_features=11, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBEbhNPV6Ktu",
        "colab_type": "text"
      },
      "source": [
        "Next we freeze the parameters which are a part of the Bert Transformers model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJmHEDeR1IUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if args['use_glove'] is False:\n",
        "  for name, param in model.named_parameters():                \n",
        "      if name.startswith('bert'):\n",
        "          param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vMffCB91RYi",
        "colab_type": "code",
        "outputId": "5ae5d96b-47a5-4bfc-e212-fe1f5fb79010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convs.0.weight\n",
            "convs.0.bias\n",
            "convs.1.weight\n",
            "convs.1.bias\n",
            "convs.2.weight\n",
            "convs.2.bias\n",
            "fc.weight\n",
            "fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TVLrvFb1Zch",
        "colab_type": "text"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46iK1uys1Wmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQWnKk5m1eUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO_HU7El6xuK",
        "colab_type": "text"
      },
      "source": [
        "We evaluate using the Jaccard Index and the macro and micro F1's as there are more suitable for multi-label text classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63IKcBC31rMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, f1_score, jaccard_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBCzL0Z-1vN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metricize(preds, y):\n",
        "  f1_macro = f1_score(y, preds.round(), average='macro')\n",
        "  f1_micro = f1_score(y, preds.round(), average='micro')\n",
        "  #acc = roc_auc_score(y, preds)\n",
        "  jaccard = jaccard_score(y, preds.round(), average='samples')\n",
        "\n",
        "  return {\n",
        "      'f1_macro': f1_macro,\n",
        "      'f1_micro': f1_micro,\n",
        "      'jaccard': jaccard\n",
        "  }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vtKoYNR1xbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    if args['use_glove']:\n",
        "      predictions = model(batch.Tweet)\n",
        "    else:\n",
        "      predictions = model(batch.Tweet).squeeze(1)\n",
        "\n",
        "    batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "    batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "    loss = criterion(predictions, batch_labels)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "    labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  \n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nthY6Knv14uC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  preds_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for batch in iterator:\n",
        "\n",
        "      if args['use_glove']:\n",
        "        predictions = model(batch.Tweet)\n",
        "      else:\n",
        "        predictions = model(batch.Tweet).squeeze(1)\n",
        "\n",
        "      batch_labels = torch.stack([getattr(batch, label) for label in LABEL_COLS])\n",
        "      batch_labels = torch.transpose(batch_labels, 0, 1)\n",
        "\n",
        "      loss = criterion(predictions, batch_labels)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      preds_list += [torch.sigmoid(predictions).detach().cpu().numpy()]\n",
        "      labels_list += [batch_labels.cpu().numpy()]\n",
        "\n",
        "  return epoch_loss / len(iterator), metricize(np.vstack(preds_list),\n",
        "                                             np.vstack(labels_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrqsUMQY17tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mjv3g3r6-ZC",
        "colab_type": "text"
      },
      "source": [
        "We train the model for 10 epochs and record the training and validation loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJRKTout1_BJ",
        "colab_type": "code",
        "outputId": "381396c7-2303-4cda-9963-4952a86dcdc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "train_history = []\n",
        "valid_history = []\n",
        "\n",
        "for epoch in range(args['epochs']):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_metrics = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_metrics = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    train_history.append(train_loss)\n",
        "    valid_history.append(valid_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        if args['use_glove']:\n",
        "          torch.save(model.state_dict(), 'glove-cnn-model.pt')\n",
        "        else:\n",
        "          torch.save(model.state_dict(), 'bert-cnn-model.pt')\n",
        "\n",
        "    train_jaccard = train_metrics['jaccard']\n",
        "    train_micro = train_metrics['f1_micro']\n",
        "    train_macro = train_metrics['f1_macro']\n",
        "\n",
        "    valid_jaccard = valid_metrics['jaccard']\n",
        "    valid_micro = valid_metrics['f1_micro']\n",
        "    valid_macro = valid_metrics['f1_macro']\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Jaccard: {train_jaccard*100:.2f}% | Train F1 Micro: {train_micro*100:.2f}% | Train F1 Macro: {train_macro*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} | Val. Jaccard: {valid_jaccard*100:.2f}%  | Val. F1 Micro: {valid_micro*100:.2f}%  | Val. F1 Macro: {valid_macro*100:.2f}%')"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.394 | Train Jaccard: 34.05% | Train F1 Micro: 48.41% | Train F1 Macro: 31.07%\n",
            "\t Val. Loss: 0.324 | Val. Jaccard: 47.59%  | Val. F1 Micro: 62.08%  | Val. F1 Macro: 42.43%\n",
            "Epoch: 02 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.339 | Train Jaccard: 46.29% | Train F1 Micro: 60.55% | Train F1 Macro: 42.44%\n",
            "\t Val. Loss: 0.319 | Val. Jaccard: 51.37%  | Val. F1 Micro: 64.94%  | Val. F1 Macro: 42.92%\n",
            "Epoch: 03 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 0.327 | Train Jaccard: 48.57% | Train F1 Micro: 62.90% | Train F1 Macro: 45.25%\n",
            "\t Val. Loss: 0.316 | Val. Jaccard: 53.19%  | Val. F1 Micro: 66.54%  | Val. F1 Macro: 45.91%\n",
            "Epoch: 04 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.319 | Train Jaccard: 49.37% | Train F1 Micro: 63.59% | Train F1 Macro: 47.06%\n",
            "\t Val. Loss: 0.315 | Val. Jaccard: 52.20%  | Val. F1 Micro: 65.48%  | Val. F1 Macro: 45.16%\n",
            "Epoch: 05 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.312 | Train Jaccard: 50.56% | Train F1 Micro: 64.52% | Train F1 Macro: 48.73%\n",
            "\t Val. Loss: 0.317 | Val. Jaccard: 55.73%  | Val. F1 Micro: 68.22%  | Val. F1 Macro: 49.01%\n",
            "Epoch: 06 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.307 | Train Jaccard: 51.87% | Train F1 Micro: 65.77% | Train F1 Macro: 49.96%\n",
            "\t Val. Loss: 0.317 | Val. Jaccard: 53.71%  | Val. F1 Micro: 66.91%  | Val. F1 Macro: 47.86%\n",
            "Epoch: 07 | Epoch Time: 0m 39s\n",
            "\tTrain Loss: 0.299 | Train Jaccard: 52.51% | Train F1 Micro: 66.43% | Train F1 Macro: 51.48%\n",
            "\t Val. Loss: 0.320 | Val. Jaccard: 53.57%  | Val. F1 Micro: 66.81%  | Val. F1 Macro: 48.40%\n",
            "Epoch: 08 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 0.295 | Train Jaccard: 53.15% | Train F1 Micro: 67.27% | Train F1 Macro: 52.97%\n",
            "\t Val. Loss: 0.331 | Val. Jaccard: 52.53%  | Val. F1 Micro: 65.81%  | Val. F1 Macro: 48.19%\n",
            "Epoch: 09 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 0.289 | Train Jaccard: 53.99% | Train F1 Micro: 67.80% | Train F1 Macro: 53.44%\n",
            "\t Val. Loss: 0.320 | Val. Jaccard: 53.33%  | Val. F1 Micro: 66.84%  | Val. F1 Macro: 51.13%\n",
            "Epoch: 10 | Epoch Time: 0m 40s\n",
            "\tTrain Loss: 0.283 | Train Jaccard: 55.16% | Train F1 Micro: 68.87% | Train F1 Macro: 55.43%\n",
            "\t Val. Loss: 0.319 | Val. Jaccard: 53.97%  | Val. F1 Micro: 66.92%  | Val. F1 Macro: 49.81%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_Y6H4Bg_H02",
        "colab_type": "text"
      },
      "source": [
        "# Visualize the training and validation loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xApekxv62E2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYvkc4ylPU2H",
        "colab_type": "code",
        "outputId": "89b44989-6a69-40ba-d002-d3b074859d5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "plt.plot(train_history)\n",
        "plt.plot(valid_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Training', 'Validation'])"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4499340908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR5X3c8r_W1m",
        "colab_type": "text"
      },
      "source": [
        "# Assess model performance on testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI8O3g5_PY1l",
        "colab_type": "code",
        "outputId": "ec42f22e-f378-454f-95b7-8c779d8691d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "model.load_state_dict(torch.load('bert-cnn-model.pt'))\n",
        "\n",
        "test_loss, test_metrics = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "test_jaccard = test_metrics['jaccard']\n",
        "test_micro = test_metrics['f1_micro']\n",
        "test_macro = test_metrics['f1_macro']\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Jaccard: {test_jaccard*100:.2f}% | Test F1 Micro: {test_micro*100:.2f}% | Test F1 Macro: {test_macro*100:.2f}%')"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.313 | Test Jaccard: 52.70% | Test F1 Micro: 65.92% | Test F1 Macro: 46.25%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Jaccard is ill-defined and being set to 0.0 in samples with no true or predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWvYzUzo73i4",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ldd6LfSYRJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_emotion(model, tokenizer, tweet):\n",
        "  preds = []\n",
        "  model.eval()\n",
        "\n",
        "  if args['use_glove']:\n",
        "    tokenized = preprocessor(tweet)\n",
        "    indexed = [TEXT.vocab.stoi[token] for token in tokenized]\n",
        "  else:\n",
        "    tokens = tokenizer.tokenize(tweet)\n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    indexed = [tokenizer.cls_token_id] + tokenizer.convert_tokens_to_ids(tokens) + [tokenizer.sep_token_id]\n",
        "    \n",
        "  tensor = torch.LongTensor(indexed).to(device)\n",
        "  tensor = tensor.unsqueeze(0)\n",
        "  predictions = model(tensor)\n",
        "  preds.append(torch.sigmoid(predictions).detach().cpu().numpy())\n",
        "  return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRlr-s2DY8Df",
        "colab_type": "code",
        "outputId": "bae2834c-9127-4bbe-c15a-e6d2a6b55163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "preds = predict_emotion(model, tokenizer, \"Good music, I love that shit.\")\n",
        "\n",
        "vals = []\n",
        "for p in preds[0]:\n",
        "  for val in p:\n",
        "    vals.append(val)\n",
        "\n",
        "for i, label in enumerate(LABEL_COLS):\n",
        "  print(f\"{label.upper()}: {vals[i]}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANGER: 0.5907741785049438\n",
            "ANTICIPATION: 0.011862020939588547\n",
            "DISGUST: 0.22723861038684845\n",
            "FEAR: 0.0067725153639912605\n",
            "JOY: 0.9571667909622192\n",
            "LOVE: 0.8796480298042297\n",
            "OPTIMISM: 0.5829552412033081\n",
            "PESSIMISM: 0.03534362092614174\n",
            "SADNESS: 0.030489809811115265\n",
            "SURPRISE: 0.011094095185399055\n",
            "TRUST: 0.05025497078895569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JAHV7ImTFdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}