{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPprxIF+Db7PgzmVqapvyXM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPaNF8qYMVKc",
        "colab_type": "text"
      },
      "source": [
        "# Detecting Emotions from Tweets with BERT on TF Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPCX_59NMUL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub \n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmonJhViNH35",
        "colab_type": "text"
      },
      "source": [
        "We need to install BERT's python package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkAhztw8NHFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJYOoR1cPyxS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "cd7fcc3b-78b0-49fa-e61a-2684180fd06e"
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ygFZICVNepL",
        "colab_type": "text"
      },
      "source": [
        "# Data\n",
        "\n",
        "Lets import the Sem-Eval dataset and format it such that it can be fed into BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llFzM4sMM99p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "556b4e74-ff4e-4da7-e91c-fc362a71084c"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehMMbaqNNrUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(filename):\n",
        "  dataset = pd.read_csv(filename, sep='\\t')\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S21gatv-N3b4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive/datasets/'\n",
        "\n",
        "train_df = load_dataset(file_path + '2018-E-c-En-train.txt')\n",
        "validation_df = load_dataset(file_path + '2018-E-c-En-dev.txt')\n",
        "test_df = load_dataset(file_path + '2018-E-c-En-test-gold.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX6gw6-GONJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ec2eaab8-2a3f-4ea3-c606-b65aa4f5d782"
      },
      "source": [
        "train_df.columns "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'Tweet', 'anger', 'anticipation', 'disgust', 'fear', 'joy',\n",
              "       'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqhEeGGwOgbJ",
        "colab_type": "text"
      },
      "source": [
        "Our input data is the 'Tweet' column and label columns the emotion categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcY8fuYpOc0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ID = 'id'\n",
        "DATA_COLUMN = 'Tweet'\n",
        "LABEL_COLUMNS = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
        "                 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbhwl4zFO7tz",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Here we transform the data into a format that BERT understands. This involves two steps. First, we modify the *InputExample* class to allow for multiple labels.\n",
        "\n",
        "- `text_a` is the text we want to classify, which in this case, is the `Request` field in our Dataframe. \n",
        "- `text_b` is used if we're training a model to understand the relationship between sentences (i.e. is `text_b` a translation of `text_a`? Is `text_b` an answer to the question asked by `text_a`?). This doesn't apply to our task, so we can leave `text_b` blank.\n",
        "- `labels` are the labels for our example, i.e. anger, disgust, fear, joy, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziSrgiMdOzXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputExample(object):\n",
        "  \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "  def __init__(self, guid, text_a, text_b=None, labels=None):\n",
        "    \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            labels: (Optional) [string]. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "    self.guid = guid\n",
        "    self.text_a = text_a\n",
        "    self.text_b = text_b\n",
        "    self.labels = labels "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIjCMuokRJ9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_InputExamples = train_df.apply(lambda x: InputExample(guid=None, \n",
        "                                                           text_a = x[DATA_COLUMN],\n",
        "                                                           text_b = None,\n",
        "                                                           labels = x[LABEL_COLUMNS]), axis=1)\n",
        "\n",
        "test_InputExamples = test_df.apply(lambda x: InputExample(guid=None, \n",
        "                                                           text_a = x[DATA_COLUMN],\n",
        "                                                           text_b = None,\n",
        "                                                           labels = x[LABEL_COLUMNS]), axis=1)\n",
        "\n",
        "validation_InputExamples = validation_df.apply(lambda x: InputExample(guid=None, \n",
        "                                                           text_a = x[DATA_COLUMN],\n",
        "                                                           text_b = None,\n",
        "                                                           labels = x[LABEL_COLUMNS]), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2BYS_-oSbXI",
        "colab_type": "text"
      },
      "source": [
        "Next, we preprocess our data so it matches the data BERT was trained on. \n",
        "\n",
        "- This is taken from the documentation at: https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb#scrollTo=IhJSe0QHNG7U\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6F1uS8mSQRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "7a96fb23-2d09-47d4-ca8f-4b87fcaabf1d"
      },
      "source": [
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpCWgjByS3ro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "0e5e25f2-0bec-43d5-e290-4fcbfdab1981"
      },
      "source": [
        "tokenizer.tokenize(\"Hello, here's an example of using the BERT tokenizer.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello',\n",
              " ',',\n",
              " 'here',\n",
              " \"'\",\n",
              " 's',\n",
              " 'an',\n",
              " 'example',\n",
              " 'of',\n",
              " 'using',\n",
              " 'the',\n",
              " 'bert',\n",
              " 'token',\n",
              " '##izer',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZLO1rjnTA-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}