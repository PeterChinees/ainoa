{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multinomial NB & Logistic Regression Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1useAkZrNN0IKXWCi3FJ3FIOH23EYBJ70",
      "authorship_tag": "ABX9TyM+6m/Z+a2oPNpg+58bX7lP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oaarnikoivu/dissertation/blob/master/Multinomial_NB_%26_Logistic_Regression_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DLmsD0XNNir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cf8566e1-a3d1-471d-e7eb-fd1eddbb9d8a"
      },
      "source": [
        "import random, re, string \n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, roc_auc_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KF0PF9BPwyB",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEbaE_aCPpNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_path = '/content/drive/My Drive'\n",
        "\n",
        "DATA_PATH = Path(file_path + '/datasets/SemEval')\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "train = pd.read_csv(DATA_PATH/'train.csv')\n",
        "val = pd.read_csv(DATA_PATH/'val.csv')\n",
        "test = pd.read_csv(DATA_PATH/'test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOaO8381P_dP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "394b7e30-717f-41cd-e301-b46d52919453"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>anger</th>\n",
              "      <th>anticipation</th>\n",
              "      <th>disgust</th>\n",
              "      <th>fear</th>\n",
              "      <th>joy</th>\n",
              "      <th>love</th>\n",
              "      <th>optimism</th>\n",
              "      <th>pessimism</th>\n",
              "      <th>sadness</th>\n",
              "      <th>surprise</th>\n",
              "      <th>trust</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2017-En-21441</td>\n",
              "      <td>“Worry is a down payment on a problem you may ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-En-31535</td>\n",
              "      <td>Whatever you decide to do make sure it makes y...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2017-En-21068</td>\n",
              "      <td>@Max_Kellerman  it also helps that the majorit...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2017-En-31436</td>\n",
              "      <td>Accept the challenges so that you can literall...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2017-En-22195</td>\n",
              "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0             ID  ... surprise  trust\n",
              "0           0  2017-En-21441  ...        0      1\n",
              "1           1  2017-En-31535  ...        0      0\n",
              "2           2  2017-En-21068  ...        0      0\n",
              "3           3  2017-En-31436  ...        0      0\n",
              "4           4  2017-En-22195  ...        0      0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS5aMz8oQG1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = train['Tweet']\n",
        "val_text = val['Tweet']\n",
        "test_text = test['Tweet']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYUYPP8wQdm_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "35cd9649-3076-4b23-cf2e-9237f9abd4a4"
      },
      "source": [
        "train_text.head()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    “Worry is a down payment on a problem you may ...\n",
              "1    Whatever you decide to do make sure it makes y...\n",
              "2    @Max_Kellerman  it also helps that the majorit...\n",
              "3    Accept the challenges so that you can literall...\n",
              "4    My roommate: it's okay that we can't spell bec...\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olk1HhUzRN7-",
        "colab_type": "text"
      },
      "source": [
        "# Tokenize and clean text using Regular Expressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVozPrbERNUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessor(text):\n",
        "    text = re.sub('<[^>]*>', '', text) # remove all html markup\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text) # findall the emoticons\n",
        "    \n",
        "    # remove the non-word chars '[\\W]+'\n",
        "    # append the emoticons to end \n",
        "    #convert all to lowercase\n",
        "    # remove nose char for consistency\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
        "            ' '.join(emoticons).replace('-', '')) \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Nl43ye9CKQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b43e1743-ed33-464f-8dfd-3f381457fa62"
      },
      "source": [
        "preprocessor(\"</a>This :) is :( a test :-)!\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'this is a test :) :( :)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbanL81aCM37",
        "colab_type": "text"
      },
      "source": [
        "## Apply the clean data preprocessor to the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRPoC7vJCQSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = train_text.apply(preprocessor)\n",
        "val_text = val_text.apply(preprocessor)\n",
        "test_text = test_text.apply(preprocessor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZwpH9FdDqb4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "20243b4f-efce-4433-fe2d-8b28c8954593"
      },
      "source": [
        "train_text.head()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     worry is a down payment on a problem you may ...\n",
              "1    whatever you decide to do make sure it makes y...\n",
              "2     max_kellerman it also helps that the majority...\n",
              "3    accept the challenges so that you can literall...\n",
              "4    my roommate it s okay that we can t spell beca...\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf8XP1cFEInF",
        "colab_type": "text"
      },
      "source": [
        "## Basic text pre-processing pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOu7rJy7ELBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop = set(stopwords.words('english'))\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "def tokenizer(text):\n",
        "  return text.split()\n",
        "\n",
        "def tokenizer_stemmer(text):\n",
        "  return [stemmer.stem(word) for word in tokenizer(text)]\n",
        "\n",
        "def stop_removal(text):\n",
        "  return [w for w in text if not w in stop]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0600C1B7SDF",
        "colab_type": "text"
      },
      "source": [
        "# Classifier training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OksdKMa_TX0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4a8b500c-8d54-40ad-cf44-fbbb8c6fe2f7"
      },
      "source": [
        "categories = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', \n",
        "              'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
        "\n",
        "# NB_pipeline = make_pipeline(\n",
        "#                         CountVectorizer(),\n",
        "#                         TfidfTransformer(),\n",
        "#                         OneVsRestClassifier(MultinomialNB(\n",
        "#                             fit_prior=True, class_prior=None)))\n",
        "\n",
        "LR_pipeline = make_pipeline(\n",
        "    CountVectorizer(),\n",
        "    TfidfTransformer(),\n",
        "    OneVsRestClassifier(LogisticRegression(random_state=1))\n",
        ")\n",
        "\n",
        "for cat in categories:\n",
        "  print(f'\\n... Processing {cat}')\n",
        "\n",
        "  LR_pipeline.fit(train_text, train[cat])\n",
        "\n",
        "  # Compute test accuracy\n",
        "  test_pred = LR_pipeline.predict(test_text)\n",
        "  print(f'Test roc auc: {roc_auc_score(test[cat], test_pred)}')\n",
        "  print(f'Test Jaccard: {jaccard_score(test[cat], test_pred)}')\n",
        "  print(f'Test Micro F1: {f1_score(test[cat], test_pred, average=\"micro\")}')\n",
        "  print(f'Test Macro F1: {f1_score(test[cat], test_pred, average=\"macro\")}')\n",
        "\n",
        "  # Compute validation accuracy\n",
        "  val_pred = LR_pipeline.predict(val_text)\n",
        "  print(f'\\nValidation roc auc: {roc_auc_score(val[cat], val_pred)}')\n",
        "  print(f'Validation Jaccard: {jaccard_score(val[cat], val_pred)}')\n",
        "  print(f'Validation Micro F1 is {f1_score(val[cat], val_pred, average=\"micro\")}')\n",
        "  print(f'Validation Macro F1: {f1_score(val[cat], val_pred, average=\"macro\")}')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "... Processing anger\n",
            "Test roc auc: 0.7004862880572806\n",
            "Test Jaccard: 0.4140687450039968\n",
            "Test Micro F1: 0.7750843817121816\n",
            "Test Macro F1: 0.7156466607887817\n",
            "\n",
            "Validation roc auc: 0.7037250159842104\n",
            "Validation Jaccard: 0.4207492795389049\n",
            "Validation Micro F1 is 0.7731376975169301\n",
            "Validation Macro F1: 0.7175690313331123\n",
            "\n",
            "... Processing anticipation\n",
            "Test roc auc: 0.5033529826891943\n",
            "Test Jaccard: 0.007042253521126761\n",
            "Test Micro F1: 0.8702055845351335\n",
            "Test Macro F1: 0.4722582393792773\n",
            "\n",
            "Validation roc auc: 0.4973753280839895\n",
            "Validation Jaccard: 0.0\n",
            "Validation Micro F1 is 0.8555304740406321\n",
            "Validation Macro F1: 0.4610705596107056\n",
            "\n",
            "... Processing disgust\n",
            "Test roc auc: 0.6809757607926398\n",
            "Test Jaccard: 0.384080370942813\n",
            "Test Micro F1: 0.7554464559680883\n",
            "Test Macro F1: 0.6931956635775072\n",
            "\n",
            "Validation roc auc: 0.6688781631310368\n",
            "Validation Jaccard: 0.3692722371967655\n",
            "Validation Micro F1 is 0.7358916478555305\n",
            "Validation Macro F1: 0.6771217482308383\n",
            "\n",
            "... Processing fear\n",
            "Test roc auc: 0.6060844810798357\n",
            "Test Jaccard: 0.2112676056338028\n",
            "Test Micro F1: 0.8797177048174286\n",
            "Test Macro F1: 0.6412881110744217\n",
            "\n",
            "Validation roc auc: 0.6146059525738671\n",
            "Validation Jaccard: 0.2248062015503876\n",
            "Validation Micro F1 is 0.8871331828442437\n",
            "Validation Macro F1: 0.6525653694728091\n",
            "\n",
            "... Processing joy\n",
            "Test roc auc: 0.7373093308153768\n",
            "Test Jaccard: 0.494140625\n",
            "Test Micro F1: 0.7615833077631176\n",
            "Test Macro F1: 0.7387227430241179\n",
            "\n",
            "Validation roc auc: 0.7220010288065845\n",
            "Validation Jaccard: 0.4671361502347418\n",
            "Validation Micro F1 is 0.7437923250564334\n",
            "Validation Macro F1: 0.7194462074978204\n",
            "\n",
            "... Processing love\n",
            "Test roc auc: 0.5866529177865009\n",
            "Test Jaccard: 0.17383177570093458\n",
            "Test Micro F1: 0.8643755753298558\n",
            "Test Macro F1: 0.6105679495636565\n",
            "\n",
            "Validation roc auc: 0.5951691986174745\n",
            "Validation Jaccard: 0.1897810218978102\n",
            "Validation Micro F1 is 0.8747178329571106\n",
            "Validation Macro F1: 0.6250157282464054\n",
            "\n",
            "... Processing optimism\n",
            "Test roc auc: 0.6453104042523985\n",
            "Test Jaccard: 0.3143309580364212\n",
            "Test Micro F1: 0.734274317275238\n",
            "Test Macro F1: 0.6500252967406885\n",
            "\n",
            "Validation roc auc: 0.6580339009749484\n",
            "Validation Jaccard: 0.336283185840708\n",
            "Validation Micro F1 is 0.7460496613995485\n",
            "Validation Macro F1: 0.6663637413452896\n",
            "\n",
            "... Processing pessimism\n",
            "Test roc auc: 0.5063199260286639\n",
            "Test Jaccard: 0.013262599469496022\n",
            "Test Micro F1: 0.8858545566124578\n",
            "Test Macro F1: 0.4827760978040506\n",
            "\n",
            "Validation roc auc: 0.5043638676844784\n",
            "Validation Jaccard: 0.009900990099009901\n",
            "Validation Micro F1 is 0.8871331828442437\n",
            "Validation Macro F1: 0.4798638018081484\n",
            "\n",
            "... Processing sadness\n",
            "Test roc auc: 0.6277074724517907\n",
            "Test Jaccard: 0.26450344149459193\n",
            "Test Micro F1: 0.7704817428659098\n",
            "Test Macro F1: 0.6376925582965932\n",
            "\n",
            "Validation roc auc: 0.6078722693160756\n",
            "Validation Jaccard: 0.2277580071174377\n",
            "Validation Micro F1 is 0.7550790067720091\n",
            "Validation Macro F1: 0.6094736093761108\n",
            "\n",
            "... Processing surprise\n",
            "Test roc auc: 0.5088235294117647\n",
            "Test Jaccard: 0.01764705882352941\n",
            "Test Micro F1: 0.9487572875115066\n",
            "Test Macro F1: 0.5041810719833104\n",
            "\n",
            "Validation roc auc: 0.5142857142857142\n",
            "Validation Jaccard: 0.02857142857142857\n",
            "Validation Micro F1 is 0.9616252821670429\n",
            "Validation Macro F1: 0.5179851510496671\n",
            "\n",
            "... Processing trust\n",
            "Test roc auc: 0.5\n",
            "Test Jaccard: 0.0\n",
            "Test Micro F1: 0.953053083768027\n",
            "Test Macro F1: 0.4879811468970935\n",
            "\n",
            "Validation roc auc: 0.5\n",
            "Validation Jaccard: 0.0\n",
            "Validation Micro F1 is 0.9514672686230248\n",
            "Validation Macro F1: 0.4875650665124349\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}